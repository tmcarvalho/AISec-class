{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b5aa0f",
   "metadata": {},
   "source": [
    "# RMIA\n",
    "From privacy meter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583779a7",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c704fc",
   "metadata": {},
   "source": [
    "### Key objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea18b1",
   "metadata": {},
   "source": [
    "### Environment steup with Pipenv\n",
    "\n",
    "````\n",
    "pipenv --python 3.12\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43fbde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the forked github repo\n",
    "#!git clone https://github.com/privacytrustlab/ml_privacy_meter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tania.carvalho/Desktop/repos/AISec-class/ml_privacy_meter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tania.carvalho/.local/share/virtualenvs/AISec-class-DqnUEjF1/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Change the directory to the cloned repo\n",
    "# import sys\n",
    "# sys.path.append('/content/ml_privacy_meter')\n",
    "\n",
    "%cd ml_privacy_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4af344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pipenv install datasets==2.21.0 transformers==4.44.2 torch==2.4.1 torchvision==0.19.1 torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43901c9",
   "metadata": {},
   "source": [
    "Delete all CUDA-related lines from requirements.txt if your machine does not support it\n",
    "```\n",
    "nvidia-cublas-cu11\n",
    "nvidia-cudnn-cu11\n",
    "nvidia-...\n",
    "triton\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6003940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6596a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from audit import get_average_audit_results, audit_models, sample_auditing_dataset\n",
    "from get_signals import get_model_signals\n",
    "from models.utils import load_models, train_models, split_dataset_for_training\n",
    "from util import (\n",
    "    check_configs,\n",
    "    setup_log,\n",
    "    initialize_seeds,\n",
    "    create_directories,\n",
    "    load_dataset,\n",
    ")\n",
    "\n",
    "# Enable benchmark mode in cudnn to improve performance when input sizes are consistent\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d1e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cofigs\n",
    "configs = \"configs/heart-stat.yaml\"\n",
    "with open(configs, \"rb\") as f:\n",
    "        configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Validate configurations\n",
    "check_configs(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b168e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate configurations\n",
    "check_configs(configs)\n",
    "\n",
    "# Initialize seeds for reproducibility\n",
    "initialize_seeds(configs[\"run\"][\"random_seed\"])\n",
    "\n",
    "# Create necessary directories\n",
    "log_dir = configs[\"run\"][\"log_dir\"]\n",
    "directories = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"report_dir\": f\"{log_dir}/report\",\n",
    "    \"signal_dir\": f\"{log_dir}/signals\",\n",
    "    \"data_dir\": \"data\",\n",
    "}\n",
    "create_directories(directories)\n",
    "\n",
    "# Set up logger\n",
    "logger = setup_log(\n",
    "    directories[\"report_dir\"], \"time_analysis\", configs[\"run\"][\"time_log\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db6cba",
   "metadata": {},
   "source": [
    "### CIFAR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e6feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_time = time.time()\n",
    "# dataset, population = load_dataset(configs, directories[\"data_dir\"], logger)\n",
    "# logger.info(\"Loading dataset took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783954fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/cifar10.pkl\", \"rb\") as f:\n",
    "#     cifar10 = pickle.load(f)\n",
    "\n",
    "# with open(\"data/cifar10_population.pkl\", \"rb\") as f:\n",
    "#     cifar10_pop = pickle.load(f)\n",
    "\n",
    "# print(\"Number of images private data:\", len(cifar10))\n",
    "# print(\"Number of images population data:\", len(cifar10_pop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e0ee",
   "metadata": {},
   "source": [
    "### Train models --- change cuda:o to cpu, and use CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2354c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define experiment parameters\n",
    "# num_experiments = configs[\"run\"][\"num_experiments\"]\n",
    "# num_reference_models = configs[\"audit\"][\"num_ref_models\"]\n",
    "# num_model_pairs = max(math.ceil(num_experiments / 2.0), num_reference_models + 1) # 2 model pairs = 4 models\n",
    "\n",
    "# # train models\n",
    "# baseline_time = time.time()\n",
    "\n",
    "# # Split dataset for training two models per pair\n",
    "# data_splits, memberships = split_dataset_for_training(\n",
    "#     len(dataset), num_model_pairs\n",
    "# )\n",
    "# models_list = train_models(\n",
    "#     log_dir, dataset, data_splits, memberships, configs, logger\n",
    "# )\n",
    "# logger.info(\n",
    "#     \"Model loading/training took %0.1f seconds\", time.time() - baseline_time\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a36d2",
   "metadata": {},
   "source": [
    "### Heart-statlog data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d46c4",
   "metadata": {},
   "source": [
    "Details on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cff1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Download completed /Users/tania.carvalho/Desktop/repos/AISec-class/ml_privacy_meter/heart-statlog.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>serum_cholestoral</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>resting_electrocardiographic_results</th>\n",
       "      <th>maximum_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>number_of_major_vessels</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.494725</td>\n",
       "      <td>1</td>\n",
       "      <td>1.150395</td>\n",
       "      <td>117.978412</td>\n",
       "      <td>242.00937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.361344</td>\n",
       "      <td>0</td>\n",
       "      <td>3.089391</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.320375</td>\n",
       "      <td>0</td>\n",
       "      <td>1.887693</td>\n",
       "      <td>118.45567</td>\n",
       "      <td>218.156844</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148.458625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.520214</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>141.819366</td>\n",
       "      <td>173.382704</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141.198191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071691</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.587959</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>106.368725</td>\n",
       "      <td>222.732859</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141.659888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866638</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.805677</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>121.035286</td>\n",
       "      <td>257.257441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145.333117</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2126</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age sex     chest resting_blood_pressure serum_cholestoral  \\\n",
       "0  53.494725   1  1.150395             117.978412         242.00937   \n",
       "1  37.320375   0  1.887693              118.45567        218.156844   \n",
       "2  48.520214   1         3             141.819366        173.382704   \n",
       "3  59.587959   0         4             106.368725        222.732859   \n",
       "4  58.805677   1         3             121.035286        257.257441   \n",
       "\n",
       "  fasting_blood_sugar resting_electrocardiographic_results  \\\n",
       "0                   0                                    0   \n",
       "1                   1                                    2   \n",
       "2                   0                                    2   \n",
       "3                   0                                    2   \n",
       "4                   0                                    0   \n",
       "\n",
       "  maximum_heart_rate_achieved exercise_induced_angina   oldpeak slope  \\\n",
       "0                  133.361344                       0  3.089391     2   \n",
       "1                  148.458625                       0         0     3   \n",
       "2                  141.198191                       0  1.071691     2   \n",
       "3                  141.659888                       1  0.866638     2   \n",
       "4                  145.333117                       0    1.2126     3   \n",
       "\n",
       "  number_of_major_vessels thal    class  \n",
       "0                       1    3  present  \n",
       "1                       0    3   absent  \n",
       "2                       0    6   absent  \n",
       "3                       0    7  present  \n",
       "4                       0    7   absent  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download dataset\n",
    "url = \"https://www.openml.org/data/download/6358/BNG_heart-statlog.csv\"\n",
    "csv_path = Path(\"heart-statlog.csv\")\n",
    "\n",
    "print(\"Downloading dataset...\")\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(csv_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Download completed\", csv_path.resolve())\n",
    "\n",
    "# Parse file\n",
    "columns = []\n",
    "data_rows = []\n",
    "data_section = False\n",
    "\n",
    "with open(csv_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Extract column names from @attribute\n",
    "        if line.lower().startswith(\"@attribute\"):\n",
    "            parts = line.split()\n",
    "            col_name = parts[1]\n",
    "            columns.append(col_name)\n",
    "\n",
    "        # Start reading data\n",
    "        elif line.lower() == \"@data\":\n",
    "            data_section = True\n",
    "\n",
    "        # Collect data rows\n",
    "        elif data_section and line and not line.startswith(\"%\"):\n",
    "            # ARFF uses comma-separated values\n",
    "            row = [x.strip() for x in line.split(\",\")]\n",
    "            data_rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(data_rows, columns=columns)\n",
    "\n",
    "# Save CSV\n",
    "# df.to_csv(csv_path, index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25758c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 07:58:23,914 INFO     Save data to data/heart-statlog.pkl\n",
      "2025-11-18 07:58:23,914 INFO     Save data to data/heart-statlog.pkl\n",
      "2025-11-18 07:58:23,923 INFO     Save population data to data/heart-statlog_population.pkl\n",
      "2025-11-18 07:58:23,923 INFO     Save population data to data/heart-statlog_population.pkl\n"
     ]
    }
   ],
   "source": [
    "from dataset import TabularDataset\n",
    "# Set up logger\n",
    "logger = setup_log(\n",
    "    directories[\"report_dir\"], \"time_analysis\", configs[\"run\"][\"time_log\"]\n",
    ")\n",
    "\n",
    "path = f\"{configs[\"data\"][\"data_dir\"]}/{configs[\"data\"][\"dataset\"]}\"\n",
    "\n",
    "df[\"class\"] = df[\"class\"].apply(lambda x: 1 if x == \"present\" else 0)\n",
    "\n",
    "df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)  # sample 10% of the dataset\n",
    "\n",
    "df = df.to_numpy()\n",
    "y = df[:, -1]\n",
    "X = df[:, :-1].astype(np.float32)\n",
    "training_size = int(\n",
    "    len(y) * 0.75\n",
    ")  # Splitting to create a population dataset\n",
    "dataset = TabularDataset(X[:training_size], y[:training_size])\n",
    "population = TabularDataset(X[training_size:], y[training_size:])\n",
    "with open(f\"{path}.pkl\", \"wb\") as file:\n",
    "    pickle.dump(dataset, file)\n",
    "logger.info(f\"Save data to {path}.pkl\")\n",
    "with open(f\"{path}_population.pkl\", \"wb\") as file:\n",
    "    pickle.dump(population, file)\n",
    "logger.info(f\"Save population data to {path}_population.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb95ca",
   "metadata": {},
   "source": [
    "Update ouput shape with the tested dataset [number of features, number of classes] -- models/utils.py\n",
    "\n",
    "```\n",
    "INPUT_OUTPUT_SHAPE = {\n",
    "    \"cifar10\": [3, 10],\n",
    "    \"cifar100\": [3, 100],\n",
    "    \"purchase100\": [600, 100],\n",
    "    \"texas100\": [6169, 100],\n",
    "    \"heart-statlog\": [13, 2],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c098e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array: (100000, 13)\n",
      "Number of unique values in last column: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of array:\", df[:, :-1].shape)       # number of rows/columns\n",
    "print(\"Number of unique values in target column:\", len(np.unique(df[:, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "649496f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 07:58:23,951 INFO     Training 4 models\n",
      "2025-11-18 07:58:23,951 INFO     Training 4 models\n",
      "2025-11-18 07:58:23,957 INFO     --------------------------------------------------\n",
      "2025-11-18 07:58:23,957 INFO     --------------------------------------------------\n",
      "2025-11-18 07:58:23,960 INFO     Training model 0: Train size 37500, Test size 37500\n",
      "2025-11-18 07:58:23,960 INFO     Training model 0: Train size 37500, Test size 37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 0.6252 | Train Acc: 0.6632\n",
      "Test Loss: 0.6045 | Test Acc: 0.6806\n",
      "Epoch 1 took 16.36 seconds\n",
      "Epoch [2/100] | Train Loss: 0.5938 | Train Acc: 0.6889\n",
      "Test Loss: 0.5900 | Test Acc: 0.6902\n",
      "Epoch 2 took 0.16 seconds\n",
      "Epoch [3/100] | Train Loss: 0.5886 | Train Acc: 0.6921\n",
      "Test Loss: 0.6022 | Test Acc: 0.6884\n",
      "Epoch 3 took 0.15 seconds\n",
      "Epoch [4/100] | Train Loss: 0.5883 | Train Acc: 0.6945\n",
      "Test Loss: 0.5820 | Test Acc: 0.6959\n",
      "Epoch 4 took 0.31 seconds\n",
      "Epoch [5/100] | Train Loss: 0.5815 | Train Acc: 0.6979\n",
      "Test Loss: 0.5900 | Test Acc: 0.6931\n",
      "Epoch 5 took 0.14 seconds\n",
      "Epoch [6/100] | Train Loss: 0.5824 | Train Acc: 0.6945\n",
      "Test Loss: 0.5831 | Test Acc: 0.6903\n",
      "Epoch 6 took 0.15 seconds\n",
      "Epoch [7/100] | Train Loss: 0.5874 | Train Acc: 0.6920\n",
      "Test Loss: 0.5699 | Test Acc: 0.7057\n",
      "Epoch 7 took 0.18 seconds\n",
      "Epoch [8/100] | Train Loss: 0.5834 | Train Acc: 0.6916\n",
      "Test Loss: 0.5768 | Test Acc: 0.6952\n",
      "Epoch 8 took 0.16 seconds\n",
      "Epoch [9/100] | Train Loss: 0.5842 | Train Acc: 0.6938\n",
      "Test Loss: 0.6030 | Test Acc: 0.6513\n",
      "Epoch 9 took 0.15 seconds\n",
      "Epoch [10/100] | Train Loss: 0.5833 | Train Acc: 0.6935\n",
      "Test Loss: 0.5713 | Test Acc: 0.7081\n",
      "Epoch 10 took 0.15 seconds\n",
      "Epoch [11/100] | Train Loss: 0.5778 | Train Acc: 0.7003\n",
      "Test Loss: 0.5961 | Test Acc: 0.6823\n",
      "Epoch 11 took 0.14 seconds\n",
      "Epoch [12/100] | Train Loss: 0.5762 | Train Acc: 0.6979\n",
      "Test Loss: 0.5612 | Test Acc: 0.7117\n",
      "Epoch 12 took 0.13 seconds\n",
      "Epoch [13/100] | Train Loss: 0.5751 | Train Acc: 0.7007\n",
      "Test Loss: 0.5652 | Test Acc: 0.7065\n",
      "Epoch 13 took 0.14 seconds\n",
      "Epoch [14/100] | Train Loss: 0.5700 | Train Acc: 0.7034\n",
      "Test Loss: 0.5734 | Test Acc: 0.6999\n",
      "Epoch 14 took 0.13 seconds\n",
      "Epoch [15/100] | Train Loss: 0.5725 | Train Acc: 0.7022\n",
      "Test Loss: 0.5928 | Test Acc: 0.6794\n",
      "Epoch 15 took 0.13 seconds\n",
      "Epoch [16/100] | Train Loss: 0.5727 | Train Acc: 0.7037\n",
      "Test Loss: 0.5584 | Test Acc: 0.7136\n",
      "Epoch 16 took 0.14 seconds\n",
      "Epoch [17/100] | Train Loss: 0.5717 | Train Acc: 0.7026\n",
      "Test Loss: 0.6111 | Test Acc: 0.6824\n",
      "Epoch 17 took 0.16 seconds\n",
      "Epoch [18/100] | Train Loss: 0.5717 | Train Acc: 0.7025\n",
      "Test Loss: 0.5579 | Test Acc: 0.7186\n",
      "Epoch 18 took 0.16 seconds\n",
      "Epoch [19/100] | Train Loss: 0.5650 | Train Acc: 0.7054\n",
      "Test Loss: 0.5622 | Test Acc: 0.7129\n",
      "Epoch 19 took 0.18 seconds\n",
      "Epoch [20/100] | Train Loss: 0.5698 | Train Acc: 0.7066\n",
      "Test Loss: 0.5583 | Test Acc: 0.7054\n",
      "Epoch 20 took 0.14 seconds\n",
      "Epoch [21/100] | Train Loss: 0.5686 | Train Acc: 0.7057\n",
      "Test Loss: 0.5459 | Test Acc: 0.7347\n",
      "Epoch 21 took 0.15 seconds\n",
      "Epoch [22/100] | Train Loss: 0.5708 | Train Acc: 0.7035\n",
      "Test Loss: 0.6077 | Test Acc: 0.6678\n",
      "Epoch 22 took 0.13 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5685 | Train Acc: 0.7043\n",
      "Test Loss: 0.5483 | Test Acc: 0.7371\n",
      "Epoch 23 took 0.13 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5673 | Train Acc: 0.7083\n",
      "Test Loss: 0.5877 | Test Acc: 0.6808\n",
      "Epoch 24 took 0.18 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5655 | Train Acc: 0.7092\n",
      "Test Loss: 0.5450 | Test Acc: 0.7284\n",
      "Epoch 25 took 0.20 seconds\n",
      "Epoch [26/100] | Train Loss: 0.5683 | Train Acc: 0.7063\n",
      "Test Loss: 0.5447 | Test Acc: 0.7329\n",
      "Epoch 26 took 0.25 seconds\n",
      "Epoch [27/100] | Train Loss: 0.5591 | Train Acc: 0.7145\n",
      "Test Loss: 0.5305 | Test Acc: 0.7524\n",
      "Epoch 27 took 0.17 seconds\n",
      "Epoch [28/100] | Train Loss: 0.5640 | Train Acc: 0.7065\n",
      "Test Loss: 0.5449 | Test Acc: 0.7212\n",
      "Epoch 28 took 0.15 seconds\n",
      "Epoch [29/100] | Train Loss: 0.5650 | Train Acc: 0.7061\n",
      "Test Loss: 0.5410 | Test Acc: 0.7320\n",
      "Epoch 29 took 0.16 seconds\n",
      "Epoch [30/100] | Train Loss: 0.5626 | Train Acc: 0.7099\n",
      "Test Loss: 0.5218 | Test Acc: 0.7441\n",
      "Epoch 30 took 0.18 seconds\n",
      "Epoch [31/100] | Train Loss: 0.5573 | Train Acc: 0.7128\n",
      "Test Loss: 0.5400 | Test Acc: 0.7393\n",
      "Epoch 31 took 0.22 seconds\n",
      "Epoch [32/100] | Train Loss: 0.5665 | Train Acc: 0.7063\n",
      "Test Loss: 0.5916 | Test Acc: 0.6962\n",
      "Epoch 32 took 0.16 seconds\n",
      "Epoch [33/100] | Train Loss: 0.5518 | Train Acc: 0.7210\n",
      "Test Loss: 0.6537 | Test Acc: 0.6307\n",
      "Epoch 33 took 0.17 seconds\n",
      "Epoch [34/100] | Train Loss: 0.5585 | Train Acc: 0.7097\n",
      "Test Loss: 0.5699 | Test Acc: 0.7149\n",
      "Epoch 34 took 0.22 seconds\n",
      "Epoch [35/100] | Train Loss: 0.5536 | Train Acc: 0.7185\n",
      "Test Loss: 0.5228 | Test Acc: 0.7453\n",
      "Epoch 35 took 0.16 seconds\n",
      "Epoch [36/100] | Train Loss: 0.5512 | Train Acc: 0.7164\n",
      "Test Loss: 0.5360 | Test Acc: 0.7299\n",
      "Epoch 36 took 0.14 seconds\n",
      "Epoch [37/100] | Train Loss: 0.5576 | Train Acc: 0.7172\n",
      "Test Loss: 0.5332 | Test Acc: 0.7510\n",
      "Epoch 37 took 0.13 seconds\n",
      "Epoch [38/100] | Train Loss: 0.5487 | Train Acc: 0.7227\n",
      "Test Loss: 0.5155 | Test Acc: 0.7538\n",
      "Epoch 38 took 0.13 seconds\n",
      "Epoch [39/100] | Train Loss: 0.5446 | Train Acc: 0.7256\n",
      "Test Loss: 0.6459 | Test Acc: 0.6621\n",
      "Epoch 39 took 0.13 seconds\n",
      "Epoch [40/100] | Train Loss: 0.5520 | Train Acc: 0.7201\n",
      "Test Loss: 0.5617 | Test Acc: 0.6998\n",
      "Epoch 40 took 0.13 seconds\n",
      "Epoch [41/100] | Train Loss: 0.5443 | Train Acc: 0.7240\n",
      "Test Loss: 0.5936 | Test Acc: 0.6926\n",
      "Epoch 41 took 0.13 seconds\n",
      "Epoch [42/100] | Train Loss: 0.5479 | Train Acc: 0.7216\n",
      "Test Loss: 0.5126 | Test Acc: 0.7548\n",
      "Epoch 42 took 0.13 seconds\n",
      "Epoch [43/100] | Train Loss: 0.5384 | Train Acc: 0.7289\n",
      "Test Loss: 0.5204 | Test Acc: 0.7463\n",
      "Epoch 43 took 0.13 seconds\n",
      "Epoch [44/100] | Train Loss: 0.5450 | Train Acc: 0.7231\n",
      "Test Loss: 0.5056 | Test Acc: 0.7665\n",
      "Epoch 44 took 0.13 seconds\n",
      "Epoch [45/100] | Train Loss: 0.5398 | Train Acc: 0.7282\n",
      "Test Loss: 0.5411 | Test Acc: 0.7214\n",
      "Epoch 45 took 0.16 seconds\n",
      "Epoch [46/100] | Train Loss: 0.5368 | Train Acc: 0.7310\n",
      "Test Loss: 0.5498 | Test Acc: 0.7183\n",
      "Epoch 46 took 0.13 seconds\n",
      "Epoch [47/100] | Train Loss: 0.5357 | Train Acc: 0.7314\n",
      "Test Loss: 0.4933 | Test Acc: 0.7707\n",
      "Epoch 47 took 0.21 seconds\n",
      "Epoch [48/100] | Train Loss: 0.5255 | Train Acc: 0.7368\n",
      "Test Loss: 0.4826 | Test Acc: 0.7694\n",
      "Epoch 48 took 0.21 seconds\n",
      "Epoch [49/100] | Train Loss: 0.5311 | Train Acc: 0.7316\n",
      "Test Loss: 0.4972 | Test Acc: 0.7634\n",
      "Epoch 49 took 0.13 seconds\n",
      "Epoch [50/100] | Train Loss: 0.5267 | Train Acc: 0.7382\n",
      "Test Loss: 0.5774 | Test Acc: 0.6985\n",
      "Epoch 50 took 0.13 seconds\n",
      "Epoch [51/100] | Train Loss: 0.5304 | Train Acc: 0.7340\n",
      "Test Loss: 0.4864 | Test Acc: 0.7581\n",
      "Epoch 51 took 0.13 seconds\n",
      "Epoch [52/100] | Train Loss: 0.5251 | Train Acc: 0.7351\n",
      "Test Loss: 0.5861 | Test Acc: 0.6914\n",
      "Epoch 52 took 0.13 seconds\n",
      "Epoch [53/100] | Train Loss: 0.5327 | Train Acc: 0.7320\n",
      "Test Loss: 0.5541 | Test Acc: 0.6953\n",
      "Epoch 53 took 0.13 seconds\n",
      "Epoch [54/100] | Train Loss: 0.5296 | Train Acc: 0.7370\n",
      "Test Loss: 0.4674 | Test Acc: 0.7863\n",
      "Epoch 54 took 0.13 seconds\n",
      "Epoch [55/100] | Train Loss: 0.5189 | Train Acc: 0.7426\n",
      "Test Loss: 0.4711 | Test Acc: 0.7776\n",
      "Epoch 55 took 0.13 seconds\n",
      "Epoch [56/100] | Train Loss: 0.5220 | Train Acc: 0.7377\n",
      "Test Loss: 0.5107 | Test Acc: 0.7600\n",
      "Epoch 56 took 0.13 seconds\n",
      "Epoch [57/100] | Train Loss: 0.5243 | Train Acc: 0.7417\n",
      "Test Loss: 0.5163 | Test Acc: 0.7394\n",
      "Epoch 57 took 0.13 seconds\n",
      "Epoch [58/100] | Train Loss: 0.5256 | Train Acc: 0.7413\n",
      "Test Loss: 0.4749 | Test Acc: 0.7714\n",
      "Epoch 58 took 0.13 seconds\n",
      "Epoch [59/100] | Train Loss: 0.5194 | Train Acc: 0.7455\n",
      "Test Loss: 0.4679 | Test Acc: 0.7847\n",
      "Epoch 59 took 0.13 seconds\n",
      "Epoch [60/100] | Train Loss: 0.5214 | Train Acc: 0.7414\n",
      "Test Loss: 0.5242 | Test Acc: 0.7408\n",
      "Epoch 60 took 0.16 seconds\n",
      "Epoch [61/100] | Train Loss: 0.5303 | Train Acc: 0.7365\n",
      "Test Loss: 0.4746 | Test Acc: 0.7758\n",
      "Epoch 61 took 0.13 seconds\n",
      "Epoch [62/100] | Train Loss: 0.5221 | Train Acc: 0.7420\n",
      "Test Loss: 0.4923 | Test Acc: 0.7535\n",
      "Epoch 62 took 0.13 seconds\n",
      "Epoch [63/100] | Train Loss: 0.5104 | Train Acc: 0.7501\n",
      "Test Loss: 0.5140 | Test Acc: 0.7301\n",
      "Epoch 63 took 0.13 seconds\n",
      "Epoch [64/100] | Train Loss: 0.5123 | Train Acc: 0.7441\n",
      "Test Loss: 0.4968 | Test Acc: 0.7641\n",
      "Epoch 64 took 0.14 seconds\n",
      "Epoch [65/100] | Train Loss: 0.5107 | Train Acc: 0.7483\n",
      "Test Loss: 0.5864 | Test Acc: 0.6914\n",
      "Epoch 65 took 0.13 seconds\n",
      "Epoch [66/100] | Train Loss: 0.5069 | Train Acc: 0.7504\n",
      "Test Loss: 0.4864 | Test Acc: 0.7562\n",
      "Epoch 66 took 0.13 seconds\n",
      "Epoch [67/100] | Train Loss: 0.5016 | Train Acc: 0.7539\n",
      "Test Loss: 0.4710 | Test Acc: 0.7835\n",
      "Epoch 67 took 0.13 seconds\n",
      "Epoch [68/100] | Train Loss: 0.4974 | Train Acc: 0.7592\n",
      "Test Loss: 0.7575 | Test Acc: 0.6089\n",
      "Epoch 68 took 0.20 seconds\n",
      "Epoch [69/100] | Train Loss: 0.5038 | Train Acc: 0.7555\n",
      "Test Loss: 0.5016 | Test Acc: 0.7553\n",
      "Epoch 69 took 0.13 seconds\n",
      "Epoch [70/100] | Train Loss: 0.4932 | Train Acc: 0.7607\n",
      "Test Loss: 0.4711 | Test Acc: 0.7785\n",
      "Epoch 70 took 0.20 seconds\n",
      "Epoch [71/100] | Train Loss: 0.4957 | Train Acc: 0.7579\n",
      "Test Loss: 0.4247 | Test Acc: 0.8078\n",
      "Epoch 71 took 0.13 seconds\n",
      "Epoch [72/100] | Train Loss: 0.4890 | Train Acc: 0.7646\n",
      "Test Loss: 0.4919 | Test Acc: 0.7603\n",
      "Epoch 72 took 0.13 seconds\n",
      "Epoch [73/100] | Train Loss: 0.4974 | Train Acc: 0.7590\n",
      "Test Loss: 0.4566 | Test Acc: 0.7839\n",
      "Epoch 73 took 0.13 seconds\n",
      "Epoch [74/100] | Train Loss: 0.4840 | Train Acc: 0.7708\n",
      "Test Loss: 0.5552 | Test Acc: 0.7063\n",
      "Epoch 74 took 0.14 seconds\n",
      "Epoch [75/100] | Train Loss: 0.4766 | Train Acc: 0.7740\n",
      "Test Loss: 0.4315 | Test Acc: 0.8076\n",
      "Epoch 75 took 0.15 seconds\n",
      "Epoch [76/100] | Train Loss: 0.4828 | Train Acc: 0.7727\n",
      "Test Loss: 0.5457 | Test Acc: 0.7273\n",
      "Epoch 76 took 0.13 seconds\n",
      "Epoch [77/100] | Train Loss: 0.4759 | Train Acc: 0.7753\n",
      "Test Loss: 0.4302 | Test Acc: 0.8111\n",
      "Epoch 77 took 0.14 seconds\n",
      "Epoch [78/100] | Train Loss: 0.4753 | Train Acc: 0.7751\n",
      "Test Loss: 0.4647 | Test Acc: 0.7842\n",
      "Epoch 78 took 0.15 seconds\n",
      "Epoch [79/100] | Train Loss: 0.4777 | Train Acc: 0.7732\n",
      "Test Loss: 0.4489 | Test Acc: 0.7959\n",
      "Epoch 79 took 0.20 seconds\n",
      "Epoch [80/100] | Train Loss: 0.4774 | Train Acc: 0.7717\n",
      "Test Loss: 0.4231 | Test Acc: 0.8120\n",
      "Epoch 80 took 0.20 seconds\n",
      "Epoch [81/100] | Train Loss: 0.4568 | Train Acc: 0.7876\n",
      "Test Loss: 0.4643 | Test Acc: 0.7703\n",
      "Epoch 81 took 0.16 seconds\n",
      "Epoch [82/100] | Train Loss: 0.4520 | Train Acc: 0.7905\n",
      "Test Loss: 0.5912 | Test Acc: 0.6749\n",
      "Epoch 82 took 0.16 seconds\n",
      "Epoch [83/100] | Train Loss: 0.4567 | Train Acc: 0.7874\n",
      "Test Loss: 0.3932 | Test Acc: 0.8257\n",
      "Epoch 83 took 0.16 seconds\n",
      "Epoch [84/100] | Train Loss: 0.4540 | Train Acc: 0.7922\n",
      "Test Loss: 0.4232 | Test Acc: 0.8167\n",
      "Epoch 84 took 0.13 seconds\n",
      "Epoch [85/100] | Train Loss: 0.4510 | Train Acc: 0.7903\n",
      "Test Loss: 0.4276 | Test Acc: 0.8082\n",
      "Epoch 85 took 0.14 seconds\n",
      "Epoch [86/100] | Train Loss: 0.4431 | Train Acc: 0.7951\n",
      "Test Loss: 0.3956 | Test Acc: 0.8302\n",
      "Epoch 86 took 0.16 seconds\n",
      "Epoch [87/100] | Train Loss: 0.4333 | Train Acc: 0.8011\n",
      "Test Loss: 0.4275 | Test Acc: 0.8068\n",
      "Epoch 87 took 0.17 seconds\n",
      "Epoch [88/100] | Train Loss: 0.4321 | Train Acc: 0.8054\n",
      "Test Loss: 0.5420 | Test Acc: 0.7491\n",
      "Epoch 88 took 0.18 seconds\n",
      "Epoch [89/100] | Train Loss: 0.4368 | Train Acc: 0.7984\n",
      "Test Loss: 0.3838 | Test Acc: 0.8332\n",
      "Epoch 89 took 0.21 seconds\n",
      "Epoch [90/100] | Train Loss: 0.4276 | Train Acc: 0.8065\n",
      "Test Loss: 0.4104 | Test Acc: 0.8178\n",
      "Epoch 90 took 0.17 seconds\n",
      "Epoch [91/100] | Train Loss: 0.4252 | Train Acc: 0.8081\n",
      "Test Loss: 0.4220 | Test Acc: 0.8078\n",
      "Epoch 91 took 0.15 seconds\n",
      "Epoch [92/100] | Train Loss: 0.4082 | Train Acc: 0.8174\n",
      "Test Loss: 0.4691 | Test Acc: 0.7888\n",
      "Epoch 92 took 0.21 seconds\n",
      "Epoch [93/100] | Train Loss: 0.4158 | Train Acc: 0.8111\n",
      "Test Loss: 0.4266 | Test Acc: 0.8042\n",
      "Epoch 93 took 0.15 seconds\n",
      "Epoch [94/100] | Train Loss: 0.4018 | Train Acc: 0.8249\n",
      "Test Loss: 0.3895 | Test Acc: 0.8293\n",
      "Epoch 94 took 0.16 seconds\n",
      "Epoch [95/100] | Train Loss: 0.4057 | Train Acc: 0.8182\n",
      "Test Loss: 0.3996 | Test Acc: 0.8158\n",
      "Epoch 95 took 0.17 seconds\n",
      "Epoch [96/100] | Train Loss: 0.4002 | Train Acc: 0.8239\n",
      "Test Loss: 0.4168 | Test Acc: 0.8165\n",
      "Epoch 96 took 0.15 seconds\n",
      "Epoch [97/100] | Train Loss: 0.3883 | Train Acc: 0.8290\n",
      "Test Loss: 0.3754 | Test Acc: 0.8385\n",
      "Epoch 97 took 0.14 seconds\n",
      "Epoch [98/100] | Train Loss: 0.3912 | Train Acc: 0.8274\n",
      "Test Loss: 0.3684 | Test Acc: 0.8415\n",
      "Epoch 98 took 0.13 seconds\n",
      "Epoch [99/100] | Train Loss: 0.3862 | Train Acc: 0.8313\n",
      "Test Loss: 0.3957 | Test Acc: 0.8220\n",
      "Epoch 99 took 0.14 seconds\n",
      "Epoch [100/100] | Train Loss: 0.3836 | Train Acc: 0.8314\n",
      "Test Loss: 0.4110 | Test Acc: 0.8128\n",
      "Epoch 100 took 0.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 07:58:55,774 INFO     Train accuracy 0.8139733333333333, Train Loss 0.40638875413914116\n",
      "2025-11-18 07:58:55,774 INFO     Train accuracy 0.8139733333333333, Train Loss 0.40638875413914116\n",
      "2025-11-18 07:58:55,776 INFO     Test accuracy 0.8128266666666667, Test Loss 0.41102946818280384\n",
      "2025-11-18 07:58:55,776 INFO     Test accuracy 0.8128266666666667, Test Loss 0.41102946818280384\n",
      "2025-11-18 07:58:55,778 INFO     Training model 0 took 31.820865154266357 seconds\n",
      "2025-11-18 07:58:55,778 INFO     Training model 0 took 31.820865154266357 seconds\n",
      "2025-11-18 07:58:55,781 INFO     --------------------------------------------------\n",
      "2025-11-18 07:58:55,781 INFO     --------------------------------------------------\n",
      "2025-11-18 07:58:55,782 INFO     Training model 1: Train size 37500, Test size 37500\n",
      "2025-11-18 07:58:55,782 INFO     Training model 1: Train size 37500, Test size 37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 0.6460 | Train Acc: 0.6317\n",
      "Test Loss: 0.6146 | Test Acc: 0.6674\n",
      "Epoch 1 took 16.17 seconds\n",
      "Epoch [2/100] | Train Loss: 0.6082 | Train Acc: 0.6692\n",
      "Test Loss: 0.5968 | Test Acc: 0.6869\n",
      "Epoch 2 took 0.14 seconds\n",
      "Epoch [3/100] | Train Loss: 0.6022 | Train Acc: 0.6750\n",
      "Test Loss: 0.6004 | Test Acc: 0.6823\n",
      "Epoch 3 took 0.15 seconds\n",
      "Epoch [4/100] | Train Loss: 0.5998 | Train Acc: 0.6756\n",
      "Test Loss: 0.6229 | Test Acc: 0.6701\n",
      "Epoch 4 took 0.28 seconds\n",
      "Epoch [5/100] | Train Loss: 0.5982 | Train Acc: 0.6817\n",
      "Test Loss: 0.6167 | Test Acc: 0.6558\n",
      "Epoch 5 took 0.13 seconds\n",
      "Epoch [6/100] | Train Loss: 0.5984 | Train Acc: 0.6782\n",
      "Test Loss: 0.5969 | Test Acc: 0.6850\n",
      "Epoch 6 took 0.13 seconds\n",
      "Epoch [7/100] | Train Loss: 0.5937 | Train Acc: 0.6862\n",
      "Test Loss: 0.5838 | Test Acc: 0.7026\n",
      "Epoch 7 took 0.14 seconds\n",
      "Epoch [8/100] | Train Loss: 0.5934 | Train Acc: 0.6866\n",
      "Test Loss: 0.5905 | Test Acc: 0.6806\n",
      "Epoch 8 took 0.13 seconds\n",
      "Epoch [9/100] | Train Loss: 0.5919 | Train Acc: 0.6845\n",
      "Test Loss: 0.6097 | Test Acc: 0.6715\n",
      "Epoch 9 took 0.14 seconds\n",
      "Epoch [10/100] | Train Loss: 0.5915 | Train Acc: 0.6865\n",
      "Test Loss: 0.5803 | Test Acc: 0.6984\n",
      "Epoch 10 took 0.13 seconds\n",
      "Epoch [11/100] | Train Loss: 0.5929 | Train Acc: 0.6877\n",
      "Test Loss: 0.5935 | Test Acc: 0.6930\n",
      "Epoch 11 took 0.17 seconds\n",
      "Epoch [12/100] | Train Loss: 0.5914 | Train Acc: 0.6847\n",
      "Test Loss: 0.5710 | Test Acc: 0.7113\n",
      "Epoch 12 took 0.21 seconds\n",
      "Epoch [13/100] | Train Loss: 0.5957 | Train Acc: 0.6802\n",
      "Test Loss: 0.5792 | Test Acc: 0.6914\n",
      "Epoch 13 took 0.15 seconds\n",
      "Epoch [14/100] | Train Loss: 0.5923 | Train Acc: 0.6841\n",
      "Test Loss: 0.5669 | Test Acc: 0.7161\n",
      "Epoch 14 took 0.20 seconds\n",
      "Epoch [15/100] | Train Loss: 0.5873 | Train Acc: 0.6885\n",
      "Test Loss: 0.5906 | Test Acc: 0.6817\n",
      "Epoch 15 took 0.14 seconds\n",
      "Epoch [16/100] | Train Loss: 0.5846 | Train Acc: 0.6874\n",
      "Test Loss: 0.6393 | Test Acc: 0.6315\n",
      "Epoch 16 took 0.13 seconds\n",
      "Epoch [17/100] | Train Loss: 0.5845 | Train Acc: 0.6911\n",
      "Test Loss: 0.6608 | Test Acc: 0.5694\n",
      "Epoch 17 took 0.14 seconds\n",
      "Epoch [18/100] | Train Loss: 0.5840 | Train Acc: 0.6903\n",
      "Test Loss: 0.6885 | Test Acc: 0.6317\n",
      "Epoch 18 took 0.15 seconds\n",
      "Epoch [19/100] | Train Loss: 0.5840 | Train Acc: 0.6900\n",
      "Test Loss: 0.5660 | Test Acc: 0.7108\n",
      "Epoch 19 took 0.15 seconds\n",
      "Epoch [20/100] | Train Loss: 0.5819 | Train Acc: 0.6931\n",
      "Test Loss: 0.5519 | Test Acc: 0.7256\n",
      "Epoch 20 took 0.18 seconds\n",
      "Epoch [21/100] | Train Loss: 0.5814 | Train Acc: 0.6934\n",
      "Test Loss: 0.5891 | Test Acc: 0.6927\n",
      "Epoch 21 took 0.15 seconds\n",
      "Epoch [22/100] | Train Loss: 0.5851 | Train Acc: 0.6933\n",
      "Test Loss: 0.6310 | Test Acc: 0.6346\n",
      "Epoch 22 took 0.14 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5834 | Train Acc: 0.6953\n",
      "Test Loss: 0.5775 | Test Acc: 0.6989\n",
      "Epoch 23 took 0.16 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5774 | Train Acc: 0.6977\n",
      "Test Loss: 0.5564 | Test Acc: 0.7133\n",
      "Epoch 24 took 0.17 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5838 | Train Acc: 0.6921\n",
      "Test Loss: 0.5707 | Test Acc: 0.6910\n",
      "Epoch 25 took 0.24 seconds\n",
      "Epoch [26/100] | Train Loss: 0.5851 | Train Acc: 0.6937\n",
      "Test Loss: 0.5705 | Test Acc: 0.6926\n",
      "Epoch 26 took 0.23 seconds\n",
      "Epoch [27/100] | Train Loss: 0.5809 | Train Acc: 0.6947\n",
      "Test Loss: 0.6009 | Test Acc: 0.6979\n",
      "Epoch 27 took 0.16 seconds\n",
      "Epoch [28/100] | Train Loss: 0.5777 | Train Acc: 0.6997\n",
      "Test Loss: 0.6207 | Test Acc: 0.6182\n",
      "Epoch 28 took 0.14 seconds\n",
      "Epoch [29/100] | Train Loss: 0.5742 | Train Acc: 0.6969\n",
      "Test Loss: 0.5431 | Test Acc: 0.7390\n",
      "Epoch 29 took 0.14 seconds\n",
      "Epoch [30/100] | Train Loss: 0.5777 | Train Acc: 0.6931\n",
      "Test Loss: 0.6428 | Test Acc: 0.6550\n",
      "Epoch 30 took 0.15 seconds\n",
      "Epoch [31/100] | Train Loss: 0.5748 | Train Acc: 0.6986\n",
      "Test Loss: 0.6971 | Test Acc: 0.6077\n",
      "Epoch 31 took 0.15 seconds\n",
      "Epoch [32/100] | Train Loss: 0.5645 | Train Acc: 0.7082\n",
      "Test Loss: 0.5247 | Test Acc: 0.7538\n",
      "Epoch 32 took 0.16 seconds\n",
      "Epoch [33/100] | Train Loss: 0.5710 | Train Acc: 0.6982\n",
      "Test Loss: 0.5451 | Test Acc: 0.7249\n",
      "Epoch 33 took 0.15 seconds\n",
      "Epoch [34/100] | Train Loss: 0.5691 | Train Acc: 0.7035\n",
      "Test Loss: 0.5801 | Test Acc: 0.6751\n",
      "Epoch 34 took 0.14 seconds\n",
      "Epoch [35/100] | Train Loss: 0.5711 | Train Acc: 0.7001\n",
      "Test Loss: 0.5421 | Test Acc: 0.7446\n",
      "Epoch 35 took 0.15 seconds\n",
      "Epoch [36/100] | Train Loss: 0.5784 | Train Acc: 0.7009\n",
      "Test Loss: 0.5445 | Test Acc: 0.7342\n",
      "Epoch 36 took 0.17 seconds\n",
      "Epoch [37/100] | Train Loss: 0.5784 | Train Acc: 0.7019\n",
      "Test Loss: 0.7080 | Test Acc: 0.5354\n",
      "Epoch 37 took 0.18 seconds\n",
      "Epoch [38/100] | Train Loss: 0.5765 | Train Acc: 0.6967\n",
      "Test Loss: 0.5453 | Test Acc: 0.7136\n",
      "Epoch 38 took 0.15 seconds\n",
      "Epoch [39/100] | Train Loss: 0.5758 | Train Acc: 0.6947\n",
      "Test Loss: 0.5385 | Test Acc: 0.7395\n",
      "Epoch 39 took 0.14 seconds\n",
      "Epoch [40/100] | Train Loss: 0.5776 | Train Acc: 0.6985\n",
      "Test Loss: 0.5468 | Test Acc: 0.7326\n",
      "Epoch 40 took 0.14 seconds\n",
      "Epoch [41/100] | Train Loss: 0.5730 | Train Acc: 0.7005\n",
      "Test Loss: 0.5481 | Test Acc: 0.7203\n",
      "Epoch 41 took 0.14 seconds\n",
      "Epoch [42/100] | Train Loss: 0.5753 | Train Acc: 0.6985\n",
      "Test Loss: 0.5418 | Test Acc: 0.7299\n",
      "Epoch 42 took 0.14 seconds\n",
      "Epoch [43/100] | Train Loss: 0.5723 | Train Acc: 0.7034\n",
      "Test Loss: 0.5597 | Test Acc: 0.7103\n",
      "Epoch 43 took 0.14 seconds\n",
      "Epoch [44/100] | Train Loss: 0.5704 | Train Acc: 0.7055\n",
      "Test Loss: 0.6558 | Test Acc: 0.6530\n",
      "Epoch 44 took 0.13 seconds\n",
      "Epoch [45/100] | Train Loss: 0.5583 | Train Acc: 0.7182\n",
      "Test Loss: 0.5426 | Test Acc: 0.7223\n",
      "Epoch 45 took 0.14 seconds\n",
      "Epoch [46/100] | Train Loss: 0.5651 | Train Acc: 0.7079\n",
      "Test Loss: 0.5277 | Test Acc: 0.7584\n",
      "Epoch 46 took 0.13 seconds\n",
      "Epoch [47/100] | Train Loss: 0.5679 | Train Acc: 0.7072\n",
      "Test Loss: 0.5745 | Test Acc: 0.6871\n",
      "Epoch 47 took 0.21 seconds\n",
      "Epoch [48/100] | Train Loss: 0.5598 | Train Acc: 0.7137\n",
      "Test Loss: 0.5529 | Test Acc: 0.7292\n",
      "Epoch 48 took 0.21 seconds\n",
      "Epoch [49/100] | Train Loss: 0.5667 | Train Acc: 0.7085\n",
      "Test Loss: 0.5729 | Test Acc: 0.6963\n",
      "Epoch 49 took 0.14 seconds\n",
      "Epoch [50/100] | Train Loss: 0.5607 | Train Acc: 0.7131\n",
      "Test Loss: 0.5155 | Test Acc: 0.7572\n",
      "Epoch 50 took 0.13 seconds\n",
      "Epoch [51/100] | Train Loss: 0.5551 | Train Acc: 0.7199\n",
      "Test Loss: 0.5543 | Test Acc: 0.7384\n",
      "Epoch 51 took 0.16 seconds\n",
      "Epoch [52/100] | Train Loss: 0.5628 | Train Acc: 0.7103\n",
      "Test Loss: 0.6194 | Test Acc: 0.6322\n",
      "Epoch 52 took 0.14 seconds\n",
      "Epoch [53/100] | Train Loss: 0.5584 | Train Acc: 0.7140\n",
      "Test Loss: 0.6250 | Test Acc: 0.6760\n",
      "Epoch 53 took 0.14 seconds\n",
      "Epoch [54/100] | Train Loss: 0.5591 | Train Acc: 0.7138\n",
      "Test Loss: 0.5257 | Test Acc: 0.7584\n",
      "Epoch 54 took 0.14 seconds\n",
      "Epoch [55/100] | Train Loss: 0.5530 | Train Acc: 0.7148\n",
      "Test Loss: 0.6319 | Test Acc: 0.6423\n",
      "Epoch 55 took 0.14 seconds\n",
      "Epoch [56/100] | Train Loss: 0.5523 | Train Acc: 0.7190\n",
      "Test Loss: 0.5135 | Test Acc: 0.7560\n",
      "Epoch 56 took 0.13 seconds\n",
      "Epoch [57/100] | Train Loss: 0.5657 | Train Acc: 0.7097\n",
      "Test Loss: 0.6063 | Test Acc: 0.6765\n",
      "Epoch 57 took 0.14 seconds\n",
      "Epoch [58/100] | Train Loss: 0.5536 | Train Acc: 0.7206\n",
      "Test Loss: 0.5669 | Test Acc: 0.6925\n",
      "Epoch 58 took 0.13 seconds\n",
      "Epoch [59/100] | Train Loss: 0.5464 | Train Acc: 0.7194\n",
      "Test Loss: 0.5121 | Test Acc: 0.7406\n",
      "Epoch 59 took 0.13 seconds\n",
      "Epoch [60/100] | Train Loss: 0.5445 | Train Acc: 0.7255\n",
      "Test Loss: 0.5725 | Test Acc: 0.6947\n",
      "Epoch 60 took 0.13 seconds\n",
      "Epoch [61/100] | Train Loss: 0.5443 | Train Acc: 0.7287\n",
      "Test Loss: 0.4879 | Test Acc: 0.7760\n",
      "Epoch 61 took 0.14 seconds\n",
      "Epoch [62/100] | Train Loss: 0.5486 | Train Acc: 0.7224\n",
      "Test Loss: 0.5498 | Test Acc: 0.7070\n",
      "Epoch 62 took 0.13 seconds\n",
      "Epoch [63/100] | Train Loss: 0.5451 | Train Acc: 0.7275\n",
      "Test Loss: 0.5199 | Test Acc: 0.7660\n",
      "Epoch 63 took 0.14 seconds\n",
      "Epoch [64/100] | Train Loss: 0.5465 | Train Acc: 0.7277\n",
      "Test Loss: 0.4943 | Test Acc: 0.7679\n",
      "Epoch 64 took 0.13 seconds\n",
      "Epoch [65/100] | Train Loss: 0.5418 | Train Acc: 0.7297\n",
      "Test Loss: 0.5419 | Test Acc: 0.7399\n",
      "Epoch 65 took 0.14 seconds\n",
      "Epoch [66/100] | Train Loss: 0.5460 | Train Acc: 0.7260\n",
      "Test Loss: 0.4985 | Test Acc: 0.7814\n",
      "Epoch 66 took 0.14 seconds\n",
      "Epoch [67/100] | Train Loss: 0.5446 | Train Acc: 0.7216\n",
      "Test Loss: 0.5006 | Test Acc: 0.7775\n",
      "Epoch 67 took 0.16 seconds\n",
      "Epoch [68/100] | Train Loss: 0.5458 | Train Acc: 0.7260\n",
      "Test Loss: 0.5182 | Test Acc: 0.7543\n",
      "Epoch 68 took 0.21 seconds\n",
      "Epoch [69/100] | Train Loss: 0.5412 | Train Acc: 0.7286\n",
      "Test Loss: 0.5190 | Test Acc: 0.7319\n",
      "Epoch 69 took 0.13 seconds\n",
      "Epoch [70/100] | Train Loss: 0.5479 | Train Acc: 0.7268\n",
      "Test Loss: 0.5204 | Test Acc: 0.7350\n",
      "Epoch 70 took 0.24 seconds\n",
      "Epoch [71/100] | Train Loss: 0.5382 | Train Acc: 0.7317\n",
      "Test Loss: 0.6104 | Test Acc: 0.6959\n",
      "Epoch 71 took 0.14 seconds\n",
      "Epoch [72/100] | Train Loss: 0.5386 | Train Acc: 0.7323\n",
      "Test Loss: 0.6174 | Test Acc: 0.6474\n",
      "Epoch 72 took 0.13 seconds\n",
      "Epoch [73/100] | Train Loss: 0.5428 | Train Acc: 0.7294\n",
      "Test Loss: 0.5883 | Test Acc: 0.6843\n",
      "Epoch 73 took 0.14 seconds\n",
      "Epoch [74/100] | Train Loss: 0.5318 | Train Acc: 0.7368\n",
      "Test Loss: 0.5257 | Test Acc: 0.7448\n",
      "Epoch 74 took 0.13 seconds\n",
      "Epoch [75/100] | Train Loss: 0.5377 | Train Acc: 0.7373\n",
      "Test Loss: 0.6192 | Test Acc: 0.6182\n",
      "Epoch 75 took 0.14 seconds\n",
      "Epoch [76/100] | Train Loss: 0.5420 | Train Acc: 0.7279\n",
      "Test Loss: 0.5152 | Test Acc: 0.7518\n",
      "Epoch 76 took 0.13 seconds\n",
      "Epoch [77/100] | Train Loss: 0.5500 | Train Acc: 0.7230\n",
      "Test Loss: 0.6599 | Test Acc: 0.6582\n",
      "Epoch 77 took 0.14 seconds\n",
      "Epoch [78/100] | Train Loss: 0.5573 | Train Acc: 0.7155\n",
      "Test Loss: 0.5437 | Test Acc: 0.7290\n",
      "Epoch 78 took 0.13 seconds\n",
      "Epoch [79/100] | Train Loss: 0.5465 | Train Acc: 0.7271\n",
      "Test Loss: 0.5465 | Test Acc: 0.7291\n",
      "Epoch 79 took 0.14 seconds\n",
      "Epoch [80/100] | Train Loss: 0.5498 | Train Acc: 0.7237\n",
      "Test Loss: 0.5827 | Test Acc: 0.6811\n",
      "Epoch 80 took 0.13 seconds\n",
      "Epoch [81/100] | Train Loss: 0.5435 | Train Acc: 0.7274\n",
      "Test Loss: 0.5081 | Test Acc: 0.7500\n",
      "Epoch 81 took 0.17 seconds\n",
      "Epoch [82/100] | Train Loss: 0.5499 | Train Acc: 0.7242\n",
      "Test Loss: 0.5358 | Test Acc: 0.7197\n",
      "Epoch 82 took 0.13 seconds\n",
      "Epoch [83/100] | Train Loss: 0.5485 | Train Acc: 0.7250\n",
      "Test Loss: 0.5253 | Test Acc: 0.7607\n",
      "Epoch 83 took 0.14 seconds\n",
      "Epoch [84/100] | Train Loss: 0.5471 | Train Acc: 0.7261\n",
      "Test Loss: 0.5968 | Test Acc: 0.6886\n",
      "Epoch 84 took 0.13 seconds\n",
      "Epoch [85/100] | Train Loss: 0.5415 | Train Acc: 0.7317\n",
      "Test Loss: 0.4964 | Test Acc: 0.7625\n",
      "Epoch 85 took 0.14 seconds\n",
      "Epoch [86/100] | Train Loss: 0.5368 | Train Acc: 0.7348\n",
      "Test Loss: 0.5989 | Test Acc: 0.7174\n",
      "Epoch 86 took 0.13 seconds\n",
      "Epoch [87/100] | Train Loss: 0.5332 | Train Acc: 0.7377\n",
      "Test Loss: 0.5197 | Test Acc: 0.7691\n",
      "Epoch 87 took 0.14 seconds\n",
      "Epoch [88/100] | Train Loss: 0.5304 | Train Acc: 0.7409\n",
      "Test Loss: 0.5667 | Test Acc: 0.6914\n",
      "Epoch 88 took 0.13 seconds\n",
      "Epoch [89/100] | Train Loss: 0.5273 | Train Acc: 0.7403\n",
      "Test Loss: 0.5482 | Test Acc: 0.7363\n",
      "Epoch 89 took 0.20 seconds\n",
      "Epoch [90/100] | Train Loss: 0.5245 | Train Acc: 0.7397\n",
      "Test Loss: 0.5262 | Test Acc: 0.7339\n",
      "Epoch 90 took 0.14 seconds\n",
      "Epoch [91/100] | Train Loss: 0.5150 | Train Acc: 0.7462\n",
      "Test Loss: 0.4906 | Test Acc: 0.7633\n",
      "Epoch 91 took 0.13 seconds\n",
      "Epoch [92/100] | Train Loss: 0.5189 | Train Acc: 0.7454\n",
      "Test Loss: 0.4711 | Test Acc: 0.7795\n",
      "Epoch 92 took 0.21 seconds\n",
      "Epoch [93/100] | Train Loss: 0.5165 | Train Acc: 0.7486\n",
      "Test Loss: 0.4962 | Test Acc: 0.7535\n",
      "Epoch 93 took 0.13 seconds\n",
      "Epoch [94/100] | Train Loss: 0.5178 | Train Acc: 0.7471\n",
      "Test Loss: 0.5421 | Test Acc: 0.7089\n",
      "Epoch 94 took 0.13 seconds\n",
      "Epoch [95/100] | Train Loss: 0.5137 | Train Acc: 0.7501\n",
      "Test Loss: 0.5472 | Test Acc: 0.7272\n",
      "Epoch 95 took 0.16 seconds\n",
      "Epoch [96/100] | Train Loss: 0.4985 | Train Acc: 0.7613\n",
      "Test Loss: 0.5835 | Test Acc: 0.6382\n",
      "Epoch 96 took 0.14 seconds\n",
      "Epoch [97/100] | Train Loss: 0.4930 | Train Acc: 0.7642\n",
      "Test Loss: 0.5363 | Test Acc: 0.7345\n",
      "Epoch 97 took 0.13 seconds\n",
      "Epoch [98/100] | Train Loss: 0.5093 | Train Acc: 0.7553\n",
      "Test Loss: 0.7052 | Test Acc: 0.5915\n",
      "Epoch 98 took 0.13 seconds\n",
      "Epoch [99/100] | Train Loss: 0.4772 | Train Acc: 0.7758\n",
      "Test Loss: 0.4834 | Test Acc: 0.7620\n",
      "Epoch 99 took 0.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:00:06,986 INFO     Train accuracy 0.72792, Train Loss 0.5028683516849466\n",
      "2025-11-18 08:00:06,986 INFO     Train accuracy 0.72792, Train Loss 0.5028683516849466\n",
      "2025-11-18 08:00:06,987 INFO     Test accuracy 0.7301333333333333, Test Loss 0.5024171599320003\n",
      "2025-11-18 08:00:06,987 INFO     Test accuracy 0.7301333333333333, Test Loss 0.5024171599320003\n",
      "2025-11-18 08:00:06,988 INFO     Training model 1 took 71.20666480064392 seconds\n",
      "2025-11-18 08:00:06,988 INFO     Training model 1 took 71.20666480064392 seconds\n",
      "2025-11-18 08:00:06,993 INFO     --------------------------------------------------\n",
      "2025-11-18 08:00:06,993 INFO     --------------------------------------------------\n",
      "2025-11-18 08:00:06,993 INFO     Training model 2: Train size 37500, Test size 37500\n",
      "2025-11-18 08:00:06,993 INFO     Training model 2: Train size 37500, Test size 37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | Train Loss: 0.4779 | Train Acc: 0.7755\n",
      "Test Loss: 0.5023 | Test Acc: 0.7301\n",
      "Epoch 100 took 0.15 seconds\n",
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 0.6776 | Train Acc: 0.6117\n",
      "Test Loss: 0.6361 | Test Acc: 0.6476\n",
      "Epoch 1 took 16.30 seconds\n",
      "Epoch [2/100] | Train Loss: 0.6109 | Train Acc: 0.6710\n",
      "Test Loss: 0.6059 | Test Acc: 0.6805\n",
      "Epoch 2 took 0.15 seconds\n",
      "Epoch [3/100] | Train Loss: 0.5977 | Train Acc: 0.6806\n",
      "Test Loss: 0.6281 | Test Acc: 0.6696\n",
      "Epoch 3 took 0.14 seconds\n",
      "Epoch [4/100] | Train Loss: 0.5922 | Train Acc: 0.6871\n",
      "Test Loss: 0.5875 | Test Acc: 0.6855\n",
      "Epoch 4 took 0.35 seconds\n",
      "Epoch [5/100] | Train Loss: 0.5920 | Train Acc: 0.6855\n",
      "Test Loss: 0.5923 | Test Acc: 0.6859\n",
      "Epoch 5 took 0.14 seconds\n",
      "Epoch [6/100] | Train Loss: 0.5928 | Train Acc: 0.6844\n",
      "Test Loss: 0.6044 | Test Acc: 0.6787\n",
      "Epoch 6 took 0.13 seconds\n",
      "Epoch [7/100] | Train Loss: 0.5893 | Train Acc: 0.6865\n",
      "Test Loss: 0.6385 | Test Acc: 0.6426\n",
      "Epoch 7 took 0.14 seconds\n",
      "Epoch [8/100] | Train Loss: 0.5859 | Train Acc: 0.6887\n",
      "Test Loss: 0.5838 | Test Acc: 0.6880\n",
      "Epoch 8 took 0.13 seconds\n",
      "Epoch [9/100] | Train Loss: 0.5858 | Train Acc: 0.6898\n",
      "Test Loss: 0.6266 | Test Acc: 0.6398\n",
      "Epoch 9 took 0.14 seconds\n",
      "Epoch [10/100] | Train Loss: 0.5819 | Train Acc: 0.6939\n",
      "Test Loss: 0.5834 | Test Acc: 0.6919\n",
      "Epoch 10 took 0.13 seconds\n",
      "Epoch [11/100] | Train Loss: 0.5817 | Train Acc: 0.6936\n",
      "Test Loss: 0.6112 | Test Acc: 0.6775\n",
      "Epoch 11 took 0.14 seconds\n",
      "Epoch [12/100] | Train Loss: 0.5780 | Train Acc: 0.6946\n",
      "Test Loss: 0.5971 | Test Acc: 0.6837\n",
      "Epoch 12 took 0.13 seconds\n",
      "Epoch [13/100] | Train Loss: 0.5802 | Train Acc: 0.6962\n",
      "Test Loss: 0.5882 | Test Acc: 0.6842\n",
      "Epoch 13 took 0.14 seconds\n",
      "Epoch [14/100] | Train Loss: 0.5806 | Train Acc: 0.6959\n",
      "Test Loss: 0.5880 | Test Acc: 0.6906\n",
      "Epoch 14 took 0.13 seconds\n",
      "Epoch [15/100] | Train Loss: 0.5763 | Train Acc: 0.6978\n",
      "Test Loss: 0.5787 | Test Acc: 0.6980\n",
      "Epoch 15 took 0.14 seconds\n",
      "Epoch [16/100] | Train Loss: 0.5796 | Train Acc: 0.6939\n",
      "Test Loss: 0.6133 | Test Acc: 0.6844\n",
      "Epoch 16 took 0.13 seconds\n",
      "Epoch [17/100] | Train Loss: 0.5770 | Train Acc: 0.6995\n",
      "Test Loss: 0.5699 | Test Acc: 0.7058\n",
      "Epoch 17 took 0.14 seconds\n",
      "Epoch [18/100] | Train Loss: 0.5747 | Train Acc: 0.7033\n",
      "Test Loss: 0.5868 | Test Acc: 0.6960\n",
      "Epoch 18 took 0.14 seconds\n",
      "Epoch [19/100] | Train Loss: 0.5753 | Train Acc: 0.6972\n",
      "Test Loss: 0.5611 | Test Acc: 0.7163\n",
      "Epoch 19 took 0.14 seconds\n",
      "Epoch [20/100] | Train Loss: 0.5722 | Train Acc: 0.6995\n",
      "Test Loss: 0.5964 | Test Acc: 0.6838\n",
      "Epoch 20 took 0.16 seconds\n",
      "Epoch [21/100] | Train Loss: 0.5724 | Train Acc: 0.7013\n",
      "Test Loss: 0.5900 | Test Acc: 0.6885\n",
      "Epoch 21 took 0.13 seconds\n",
      "Epoch [22/100] | Train Loss: 0.5746 | Train Acc: 0.7002\n",
      "Test Loss: 0.5683 | Test Acc: 0.7082\n",
      "Epoch 22 took 0.14 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5709 | Train Acc: 0.7030\n",
      "Test Loss: 0.5731 | Test Acc: 0.6985\n",
      "Epoch 23 took 0.13 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5704 | Train Acc: 0.7037\n",
      "Test Loss: 0.5777 | Test Acc: 0.6989\n",
      "Epoch 24 took 0.14 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5697 | Train Acc: 0.7049\n",
      "Test Loss: 0.5723 | Test Acc: 0.6989\n",
      "Epoch 25 took 0.20 seconds\n",
      "Epoch [26/100] | Train Loss: 0.5727 | Train Acc: 0.7033\n",
      "Test Loss: 0.5829 | Test Acc: 0.6960\n",
      "Epoch 26 took 0.21 seconds\n",
      "Epoch [27/100] | Train Loss: 0.5704 | Train Acc: 0.7047\n",
      "Test Loss: 0.5949 | Test Acc: 0.6681\n",
      "Epoch 27 took 0.14 seconds\n",
      "Epoch [28/100] | Train Loss: 0.5742 | Train Acc: 0.6990\n",
      "Test Loss: 0.5964 | Test Acc: 0.6539\n",
      "Epoch 28 took 0.15 seconds\n",
      "Epoch [29/100] | Train Loss: 0.5711 | Train Acc: 0.7040\n",
      "Test Loss: 0.5690 | Test Acc: 0.7079\n",
      "Epoch 29 took 0.16 seconds\n",
      "Epoch [30/100] | Train Loss: 0.5665 | Train Acc: 0.7075\n",
      "Test Loss: 0.5568 | Test Acc: 0.7175\n",
      "Epoch 30 took 0.14 seconds\n",
      "Epoch [31/100] | Train Loss: 0.5709 | Train Acc: 0.7035\n",
      "Test Loss: 0.5570 | Test Acc: 0.7082\n",
      "Epoch 31 took 0.16 seconds\n",
      "Epoch [32/100] | Train Loss: 0.5712 | Train Acc: 0.7016\n",
      "Test Loss: 0.5702 | Test Acc: 0.7095\n",
      "Epoch 32 took 0.15 seconds\n",
      "Epoch [33/100] | Train Loss: 0.5736 | Train Acc: 0.6948\n",
      "Test Loss: 0.5712 | Test Acc: 0.6928\n",
      "Epoch 33 took 0.18 seconds\n",
      "Epoch [34/100] | Train Loss: 0.5640 | Train Acc: 0.7075\n",
      "Test Loss: 0.5700 | Test Acc: 0.7022\n",
      "Epoch 34 took 0.17 seconds\n",
      "Epoch [35/100] | Train Loss: 0.5685 | Train Acc: 0.7041\n",
      "Test Loss: 0.5667 | Test Acc: 0.7117\n",
      "Epoch 35 took 0.15 seconds\n",
      "Epoch [36/100] | Train Loss: 0.5654 | Train Acc: 0.7090\n",
      "Test Loss: 0.5510 | Test Acc: 0.7202\n",
      "Epoch 36 took 0.16 seconds\n",
      "Epoch [37/100] | Train Loss: 0.5620 | Train Acc: 0.7102\n",
      "Test Loss: 0.5801 | Test Acc: 0.7108\n",
      "Epoch 37 took 0.14 seconds\n",
      "Epoch [38/100] | Train Loss: 0.5687 | Train Acc: 0.7049\n",
      "Test Loss: 0.5754 | Test Acc: 0.7059\n",
      "Epoch 38 took 0.14 seconds\n",
      "Epoch [39/100] | Train Loss: 0.5713 | Train Acc: 0.7061\n",
      "Test Loss: 0.6177 | Test Acc: 0.6729\n",
      "Epoch 39 took 0.14 seconds\n",
      "Epoch [40/100] | Train Loss: 0.5688 | Train Acc: 0.7098\n",
      "Test Loss: 0.6137 | Test Acc: 0.6626\n",
      "Epoch 40 took 0.14 seconds\n",
      "Epoch [41/100] | Train Loss: 0.5652 | Train Acc: 0.7082\n",
      "Test Loss: 0.5581 | Test Acc: 0.7191\n",
      "Epoch 41 took 0.14 seconds\n",
      "Epoch [42/100] | Train Loss: 0.5664 | Train Acc: 0.7056\n",
      "Test Loss: 0.6077 | Test Acc: 0.6767\n",
      "Epoch 42 took 0.13 seconds\n",
      "Epoch [43/100] | Train Loss: 0.5660 | Train Acc: 0.7056\n",
      "Test Loss: 0.5603 | Test Acc: 0.7125\n",
      "Epoch 43 took 0.14 seconds\n",
      "Epoch [44/100] | Train Loss: 0.5679 | Train Acc: 0.7062\n",
      "Test Loss: 0.6051 | Test Acc: 0.6832\n",
      "Epoch 44 took 0.13 seconds\n",
      "Epoch [45/100] | Train Loss: 0.5690 | Train Acc: 0.7076\n",
      "Test Loss: 0.6222 | Test Acc: 0.6573\n",
      "Epoch 45 took 0.18 seconds\n",
      "Epoch [46/100] | Train Loss: 0.5643 | Train Acc: 0.7115\n",
      "Test Loss: 0.5901 | Test Acc: 0.7024\n",
      "Epoch 46 took 0.14 seconds\n",
      "Epoch [47/100] | Train Loss: 0.5660 | Train Acc: 0.7087\n",
      "Test Loss: 0.5693 | Test Acc: 0.7124\n",
      "Epoch 47 took 0.24 seconds\n",
      "Epoch [48/100] | Train Loss: 0.5594 | Train Acc: 0.7128\n",
      "Test Loss: 0.5661 | Test Acc: 0.7059\n",
      "Epoch 48 took 0.21 seconds\n",
      "Epoch [49/100] | Train Loss: 0.5567 | Train Acc: 0.7150\n",
      "Test Loss: 0.5554 | Test Acc: 0.7260\n",
      "Epoch 49 took 0.14 seconds\n",
      "Epoch [50/100] | Train Loss: 0.5653 | Train Acc: 0.7076\n",
      "Test Loss: 0.5518 | Test Acc: 0.7253\n",
      "Epoch 50 took 0.14 seconds\n",
      "Epoch [51/100] | Train Loss: 0.5575 | Train Acc: 0.7118\n",
      "Test Loss: 0.5847 | Test Acc: 0.6877\n",
      "Epoch 51 took 0.13 seconds\n",
      "Epoch [52/100] | Train Loss: 0.5572 | Train Acc: 0.7169\n",
      "Test Loss: 0.5437 | Test Acc: 0.7217\n",
      "Epoch 52 took 0.14 seconds\n",
      "Epoch [53/100] | Train Loss: 0.5577 | Train Acc: 0.7123\n",
      "Test Loss: 0.5819 | Test Acc: 0.7030\n",
      "Epoch 53 took 0.13 seconds\n",
      "Epoch [54/100] | Train Loss: 0.5585 | Train Acc: 0.7158\n",
      "Test Loss: 0.5685 | Test Acc: 0.7161\n",
      "Epoch 54 took 0.14 seconds\n",
      "Epoch [55/100] | Train Loss: 0.5526 | Train Acc: 0.7187\n",
      "Test Loss: 0.5426 | Test Acc: 0.7361\n",
      "Epoch 55 took 0.13 seconds\n",
      "Epoch [56/100] | Train Loss: 0.5513 | Train Acc: 0.7204\n",
      "Test Loss: 0.5384 | Test Acc: 0.7347\n",
      "Epoch 56 took 0.14 seconds\n",
      "Epoch [57/100] | Train Loss: 0.5529 | Train Acc: 0.7176\n",
      "Test Loss: 0.5336 | Test Acc: 0.7369\n",
      "Epoch 57 took 0.14 seconds\n",
      "Epoch [58/100] | Train Loss: 0.5571 | Train Acc: 0.7162\n",
      "Test Loss: 0.5892 | Test Acc: 0.6817\n",
      "Epoch 58 took 0.14 seconds\n",
      "Epoch [59/100] | Train Loss: 0.5514 | Train Acc: 0.7184\n",
      "Test Loss: 0.5758 | Test Acc: 0.6856\n",
      "Epoch 59 took 0.14 seconds\n",
      "Epoch [60/100] | Train Loss: 0.5467 | Train Acc: 0.7257\n",
      "Test Loss: 0.5729 | Test Acc: 0.6976\n",
      "Epoch 60 took 0.14 seconds\n",
      "Epoch [61/100] | Train Loss: 0.5486 | Train Acc: 0.7227\n",
      "Test Loss: 0.8429 | Test Acc: 0.6010\n",
      "Epoch 61 took 0.14 seconds\n",
      "Epoch [62/100] | Train Loss: 0.5472 | Train Acc: 0.7233\n",
      "Test Loss: 0.6096 | Test Acc: 0.6439\n",
      "Epoch 62 took 0.17 seconds\n",
      "Epoch [63/100] | Train Loss: 0.5461 | Train Acc: 0.7259\n",
      "Test Loss: 0.5355 | Test Acc: 0.7217\n",
      "Epoch 63 took 0.14 seconds\n",
      "Epoch [64/100] | Train Loss: 0.5471 | Train Acc: 0.7222\n",
      "Test Loss: 0.5887 | Test Acc: 0.6818\n",
      "Epoch 64 took 0.14 seconds\n",
      "Epoch [65/100] | Train Loss: 0.5447 | Train Acc: 0.7262\n",
      "Test Loss: 0.5922 | Test Acc: 0.6803\n",
      "Epoch 65 took 0.14 seconds\n",
      "Epoch [66/100] | Train Loss: 0.5424 | Train Acc: 0.7235\n",
      "Test Loss: 0.5299 | Test Acc: 0.7322\n",
      "Epoch 66 took 0.14 seconds\n",
      "Epoch [67/100] | Train Loss: 0.5417 | Train Acc: 0.7246\n",
      "Test Loss: 0.5125 | Test Acc: 0.7516\n",
      "Epoch 67 took 0.14 seconds\n",
      "Epoch [68/100] | Train Loss: 0.5385 | Train Acc: 0.7310\n",
      "Test Loss: 0.6351 | Test Acc: 0.6574\n",
      "Epoch 68 took 0.25 seconds\n",
      "Epoch [69/100] | Train Loss: 0.5403 | Train Acc: 0.7285\n",
      "Test Loss: 0.5825 | Test Acc: 0.7034\n",
      "Epoch 69 took 0.14 seconds\n",
      "Epoch [70/100] | Train Loss: 0.5360 | Train Acc: 0.7324\n",
      "Test Loss: 0.5136 | Test Acc: 0.7596\n",
      "Epoch 70 took 0.21 seconds\n",
      "Epoch [71/100] | Train Loss: 0.5372 | Train Acc: 0.7318\n",
      "Test Loss: 0.5488 | Test Acc: 0.7313\n",
      "Epoch 71 took 0.14 seconds\n",
      "Epoch [72/100] | Train Loss: 0.5345 | Train Acc: 0.7330\n",
      "Test Loss: 0.5241 | Test Acc: 0.7286\n",
      "Epoch 72 took 0.14 seconds\n",
      "Epoch [73/100] | Train Loss: 0.5357 | Train Acc: 0.7342\n",
      "Test Loss: 0.5047 | Test Acc: 0.7537\n",
      "Epoch 73 took 0.13 seconds\n",
      "Epoch [74/100] | Train Loss: 0.5351 | Train Acc: 0.7327\n",
      "Test Loss: 0.5258 | Test Acc: 0.7479\n",
      "Epoch 74 took 0.14 seconds\n",
      "Epoch [75/100] | Train Loss: 0.5366 | Train Acc: 0.7269\n",
      "Test Loss: 0.5039 | Test Acc: 0.7477\n",
      "Epoch 75 took 0.13 seconds\n",
      "Epoch [76/100] | Train Loss: 0.5333 | Train Acc: 0.7316\n",
      "Test Loss: 0.5107 | Test Acc: 0.7450\n",
      "Epoch 76 took 0.16 seconds\n",
      "Epoch [77/100] | Train Loss: 0.5271 | Train Acc: 0.7350\n",
      "Test Loss: 0.5407 | Test Acc: 0.7404\n",
      "Epoch 77 took 0.14 seconds\n",
      "Epoch [78/100] | Train Loss: 0.5356 | Train Acc: 0.7274\n",
      "Test Loss: 0.5169 | Test Acc: 0.7431\n",
      "Epoch 78 took 0.14 seconds\n",
      "Epoch [79/100] | Train Loss: 0.5365 | Train Acc: 0.7307\n",
      "Test Loss: 0.5119 | Test Acc: 0.7601\n",
      "Epoch 79 took 0.14 seconds\n",
      "Epoch [80/100] | Train Loss: 0.5354 | Train Acc: 0.7310\n",
      "Test Loss: 0.5137 | Test Acc: 0.7471\n",
      "Epoch 80 took 0.14 seconds\n",
      "Epoch [81/100] | Train Loss: 0.5297 | Train Acc: 0.7345\n",
      "Test Loss: 0.5596 | Test Acc: 0.7199\n",
      "Epoch 81 took 0.14 seconds\n",
      "Epoch [82/100] | Train Loss: 0.5295 | Train Acc: 0.7363\n",
      "Test Loss: 0.4962 | Test Acc: 0.7618\n",
      "Epoch 82 took 0.14 seconds\n",
      "Epoch [83/100] | Train Loss: 0.5314 | Train Acc: 0.7354\n",
      "Test Loss: 0.5569 | Test Acc: 0.7379\n",
      "Epoch 83 took 0.13 seconds\n",
      "Epoch [84/100] | Train Loss: 0.5225 | Train Acc: 0.7432\n",
      "Test Loss: 0.6127 | Test Acc: 0.6771\n",
      "Epoch 84 took 0.14 seconds\n",
      "Epoch [85/100] | Train Loss: 0.5180 | Train Acc: 0.7435\n",
      "Test Loss: 0.6070 | Test Acc: 0.6231\n",
      "Epoch 85 took 0.13 seconds\n",
      "Epoch [86/100] | Train Loss: 0.5240 | Train Acc: 0.7400\n",
      "Test Loss: 0.5757 | Test Acc: 0.7080\n",
      "Epoch 86 took 0.14 seconds\n",
      "Epoch [87/100] | Train Loss: 0.5180 | Train Acc: 0.7406\n",
      "Test Loss: 0.6216 | Test Acc: 0.6883\n",
      "Epoch 87 took 0.13 seconds\n",
      "Epoch [88/100] | Train Loss: 0.5254 | Train Acc: 0.7413\n",
      "Test Loss: 0.5486 | Test Acc: 0.7403\n",
      "Epoch 88 took 0.14 seconds\n",
      "Epoch [89/100] | Train Loss: 0.5100 | Train Acc: 0.7476\n",
      "Test Loss: 0.5361 | Test Acc: 0.7389\n",
      "Epoch 89 took 0.20 seconds\n",
      "Epoch [90/100] | Train Loss: 0.5169 | Train Acc: 0.7402\n",
      "Test Loss: 0.4874 | Test Acc: 0.7511\n",
      "Epoch 90 took 0.13 seconds\n",
      "Epoch [91/100] | Train Loss: 0.4995 | Train Acc: 0.7552\n",
      "Test Loss: 0.4528 | Test Acc: 0.7832\n",
      "Epoch 91 took 0.16 seconds\n",
      "Epoch [92/100] | Train Loss: 0.4989 | Train Acc: 0.7539\n",
      "Test Loss: 0.5144 | Test Acc: 0.7426\n",
      "Epoch 92 took 0.21 seconds\n",
      "Epoch [93/100] | Train Loss: 0.4985 | Train Acc: 0.7546\n",
      "Test Loss: 0.5255 | Test Acc: 0.7503\n",
      "Epoch 93 took 0.13 seconds\n",
      "Epoch [94/100] | Train Loss: 0.4905 | Train Acc: 0.7657\n",
      "Test Loss: 0.4510 | Test Acc: 0.7957\n",
      "Epoch 94 took 0.14 seconds\n",
      "Epoch [95/100] | Train Loss: 0.4764 | Train Acc: 0.7735\n",
      "Test Loss: 0.4337 | Test Acc: 0.8028\n",
      "Epoch 95 took 0.13 seconds\n",
      "Epoch [96/100] | Train Loss: 0.4892 | Train Acc: 0.7648\n",
      "Test Loss: 0.4415 | Test Acc: 0.8060\n",
      "Epoch 96 took 0.14 seconds\n",
      "Epoch [97/100] | Train Loss: 0.4754 | Train Acc: 0.7741\n",
      "Test Loss: 0.4598 | Test Acc: 0.7896\n",
      "Epoch 97 took 0.13 seconds\n",
      "Epoch [98/100] | Train Loss: 0.4612 | Train Acc: 0.7847\n",
      "Test Loss: 0.4609 | Test Acc: 0.7963\n",
      "Epoch 98 took 0.14 seconds\n",
      "Epoch [99/100] | Train Loss: 0.4605 | Train Acc: 0.7843\n",
      "Test Loss: 0.5985 | Test Acc: 0.6772\n",
      "Epoch 99 took 0.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:01:18,130 INFO     Train accuracy 0.67592, Train Loss 0.5441305444759577\n",
      "2025-11-18 08:01:18,130 INFO     Train accuracy 0.67592, Train Loss 0.5441305444759577\n",
      "2025-11-18 08:01:18,131 INFO     Test accuracy 0.67376, Test Loss 0.5495240943772453\n",
      "2025-11-18 08:01:18,131 INFO     Test accuracy 0.67376, Test Loss 0.5495240943772453\n",
      "2025-11-18 08:01:18,132 INFO     Training model 2 took 71.13932776451111 seconds\n",
      "2025-11-18 08:01:18,132 INFO     Training model 2 took 71.13932776451111 seconds\n",
      "2025-11-18 08:01:18,139 INFO     --------------------------------------------------\n",
      "2025-11-18 08:01:18,139 INFO     --------------------------------------------------\n",
      "2025-11-18 08:01:18,140 INFO     Training model 3: Train size 37500, Test size 37500\n",
      "2025-11-18 08:01:18,140 INFO     Training model 3: Train size 37500, Test size 37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | Train Loss: 0.4525 | Train Acc: 0.7911\n",
      "Test Loss: 0.5495 | Test Acc: 0.6738\n",
      "Epoch 100 took 0.14 seconds\n",
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 0.6558 | Train Acc: 0.6183\n",
      "Test Loss: 0.6147 | Test Acc: 0.6691\n",
      "Epoch 1 took 15.87 seconds\n",
      "Epoch [2/100] | Train Loss: 0.6121 | Train Acc: 0.6741\n",
      "Test Loss: 0.6037 | Test Acc: 0.6685\n",
      "Epoch 2 took 0.16 seconds\n",
      "Epoch [3/100] | Train Loss: 0.6059 | Train Acc: 0.6766\n",
      "Test Loss: 0.6233 | Test Acc: 0.6414\n",
      "Epoch 3 took 0.18 seconds\n",
      "Epoch [4/100] | Train Loss: 0.6016 | Train Acc: 0.6795\n",
      "Test Loss: 0.6153 | Test Acc: 0.6641\n",
      "Epoch 4 took 0.34 seconds\n",
      "Epoch [5/100] | Train Loss: 0.5985 | Train Acc: 0.6810\n",
      "Test Loss: 0.5749 | Test Acc: 0.7051\n",
      "Epoch 5 took 0.14 seconds\n",
      "Epoch [6/100] | Train Loss: 0.5964 | Train Acc: 0.6830\n",
      "Test Loss: 0.5828 | Test Acc: 0.7016\n",
      "Epoch 6 took 0.14 seconds\n",
      "Epoch [7/100] | Train Loss: 0.5909 | Train Acc: 0.6873\n",
      "Test Loss: 0.5748 | Test Acc: 0.7012\n",
      "Epoch 7 took 0.14 seconds\n",
      "Epoch [8/100] | Train Loss: 0.5929 | Train Acc: 0.6817\n",
      "Test Loss: 0.5689 | Test Acc: 0.7058\n",
      "Epoch 8 took 0.13 seconds\n",
      "Epoch [9/100] | Train Loss: 0.5967 | Train Acc: 0.6808\n",
      "Test Loss: 0.5935 | Test Acc: 0.6991\n",
      "Epoch 9 took 0.14 seconds\n",
      "Epoch [10/100] | Train Loss: 0.5934 | Train Acc: 0.6840\n",
      "Test Loss: 0.5858 | Test Acc: 0.6939\n",
      "Epoch 10 took 0.13 seconds\n",
      "Epoch [11/100] | Train Loss: 0.5934 | Train Acc: 0.6856\n",
      "Test Loss: 0.6132 | Test Acc: 0.6630\n",
      "Epoch 11 took 0.15 seconds\n",
      "Epoch [12/100] | Train Loss: 0.5946 | Train Acc: 0.6833\n",
      "Test Loss: 0.5963 | Test Acc: 0.6909\n",
      "Epoch 12 took 0.14 seconds\n",
      "Epoch [13/100] | Train Loss: 0.5940 | Train Acc: 0.6843\n",
      "Test Loss: 0.6203 | Test Acc: 0.6338\n",
      "Epoch 13 took 0.14 seconds\n",
      "Epoch [14/100] | Train Loss: 0.5879 | Train Acc: 0.6893\n",
      "Test Loss: 0.5609 | Test Acc: 0.7124\n",
      "Epoch 14 took 0.14 seconds\n",
      "Epoch [15/100] | Train Loss: 0.5889 | Train Acc: 0.6851\n",
      "Test Loss: 0.6116 | Test Acc: 0.6506\n",
      "Epoch 15 took 0.13 seconds\n",
      "Epoch [16/100] | Train Loss: 0.5883 | Train Acc: 0.6889\n",
      "Test Loss: 0.5752 | Test Acc: 0.6997\n",
      "Epoch 16 took 0.14 seconds\n",
      "Epoch [17/100] | Train Loss: 0.5824 | Train Acc: 0.6931\n",
      "Test Loss: 0.5601 | Test Acc: 0.7151\n",
      "Epoch 17 took 0.16 seconds\n",
      "Epoch [18/100] | Train Loss: 0.5791 | Train Acc: 0.6972\n",
      "Test Loss: 0.5604 | Test Acc: 0.7194\n",
      "Epoch 18 took 0.13 seconds\n",
      "Epoch [19/100] | Train Loss: 0.5833 | Train Acc: 0.6935\n",
      "Test Loss: 0.5825 | Test Acc: 0.6820\n",
      "Epoch 19 took 0.14 seconds\n",
      "Epoch [20/100] | Train Loss: 0.5817 | Train Acc: 0.6937\n",
      "Test Loss: 0.5966 | Test Acc: 0.6732\n",
      "Epoch 20 took 0.14 seconds\n",
      "Epoch [21/100] | Train Loss: 0.5816 | Train Acc: 0.6943\n",
      "Test Loss: 0.6343 | Test Acc: 0.6417\n",
      "Epoch 21 took 0.14 seconds\n",
      "Epoch [22/100] | Train Loss: 0.5826 | Train Acc: 0.6916\n",
      "Test Loss: 0.5522 | Test Acc: 0.7134\n",
      "Epoch 22 took 0.14 seconds\n",
      "Epoch [23/100] | Train Loss: 0.5798 | Train Acc: 0.6951\n",
      "Test Loss: 0.5684 | Test Acc: 0.7021\n",
      "Epoch 23 took 0.14 seconds\n",
      "Epoch [24/100] | Train Loss: 0.5738 | Train Acc: 0.6997\n",
      "Test Loss: 0.5561 | Test Acc: 0.7050\n",
      "Epoch 24 took 0.14 seconds\n",
      "Epoch [25/100] | Train Loss: 0.5791 | Train Acc: 0.6958\n",
      "Test Loss: 0.5793 | Test Acc: 0.6996\n",
      "Epoch 25 took 0.21 seconds\n",
      "Epoch [26/100] | Train Loss: 0.5884 | Train Acc: 0.6916\n",
      "Test Loss: 0.5834 | Test Acc: 0.7033\n",
      "Epoch 26 took 0.22 seconds\n",
      "Epoch [27/100] | Train Loss: 0.5882 | Train Acc: 0.6904\n",
      "Test Loss: 0.5807 | Test Acc: 0.6895\n",
      "Epoch 27 took 0.14 seconds\n",
      "Epoch [28/100] | Train Loss: 0.5820 | Train Acc: 0.6966\n",
      "Test Loss: 0.5520 | Test Acc: 0.7317\n",
      "Epoch 28 took 0.14 seconds\n",
      "Epoch [29/100] | Train Loss: 0.5888 | Train Acc: 0.6867\n",
      "Test Loss: 0.5700 | Test Acc: 0.6968\n",
      "Epoch 29 took 0.20 seconds\n",
      "Epoch [30/100] | Train Loss: 0.5839 | Train Acc: 0.6930\n",
      "Test Loss: 0.5678 | Test Acc: 0.7148\n",
      "Epoch 30 took 0.17 seconds\n",
      "Epoch [31/100] | Train Loss: 0.5846 | Train Acc: 0.6959\n",
      "Test Loss: 0.6352 | Test Acc: 0.6470\n",
      "Epoch 31 took 0.14 seconds\n",
      "Epoch [32/100] | Train Loss: 0.5831 | Train Acc: 0.6918\n",
      "Test Loss: 0.5707 | Test Acc: 0.6934\n",
      "Epoch 32 took 0.14 seconds\n",
      "Epoch [33/100] | Train Loss: 0.5836 | Train Acc: 0.6920\n",
      "Test Loss: 0.5649 | Test Acc: 0.7067\n",
      "Epoch 33 took 0.13 seconds\n",
      "Epoch [34/100] | Train Loss: 0.5760 | Train Acc: 0.6978\n",
      "Test Loss: 0.5648 | Test Acc: 0.7115\n",
      "Epoch 34 took 0.14 seconds\n",
      "Epoch [35/100] | Train Loss: 0.5791 | Train Acc: 0.6951\n",
      "Test Loss: 0.5895 | Test Acc: 0.6805\n",
      "Epoch 35 took 0.13 seconds\n",
      "Epoch [36/100] | Train Loss: 0.5705 | Train Acc: 0.7042\n",
      "Test Loss: 0.5583 | Test Acc: 0.7096\n",
      "Epoch 36 took 0.13 seconds\n",
      "Epoch [37/100] | Train Loss: 0.5726 | Train Acc: 0.7041\n",
      "Test Loss: 0.5787 | Test Acc: 0.7136\n",
      "Epoch 37 took 0.13 seconds\n",
      "Epoch [38/100] | Train Loss: 0.5739 | Train Acc: 0.7001\n",
      "Test Loss: 0.5576 | Test Acc: 0.7075\n",
      "Epoch 38 took 0.13 seconds\n",
      "Epoch [39/100] | Train Loss: 0.5617 | Train Acc: 0.7144\n",
      "Test Loss: 0.5465 | Test Acc: 0.7183\n",
      "Epoch 39 took 0.13 seconds\n",
      "Epoch [40/100] | Train Loss: 0.5675 | Train Acc: 0.7059\n",
      "Test Loss: 0.6899 | Test Acc: 0.5707\n",
      "Epoch 40 took 0.13 seconds\n",
      "Epoch [41/100] | Train Loss: 0.5678 | Train Acc: 0.7053\n",
      "Test Loss: 0.5581 | Test Acc: 0.7105\n",
      "Epoch 41 took 0.13 seconds\n",
      "Epoch [42/100] | Train Loss: 0.5639 | Train Acc: 0.7074\n",
      "Test Loss: 0.5176 | Test Acc: 0.7558\n",
      "Epoch 42 took 0.14 seconds\n",
      "Epoch [43/100] | Train Loss: 0.5667 | Train Acc: 0.7104\n",
      "Test Loss: 0.5352 | Test Acc: 0.7641\n",
      "Epoch 43 took 0.13 seconds\n",
      "Epoch [44/100] | Train Loss: 0.5675 | Train Acc: 0.7102\n",
      "Test Loss: 0.5955 | Test Acc: 0.7010\n",
      "Epoch 44 took 0.14 seconds\n",
      "Epoch [45/100] | Train Loss: 0.5720 | Train Acc: 0.7051\n",
      "Test Loss: 0.5547 | Test Acc: 0.7103\n",
      "Epoch 45 took 0.14 seconds\n",
      "Epoch [46/100] | Train Loss: 0.5700 | Train Acc: 0.7042\n",
      "Test Loss: 0.5506 | Test Acc: 0.7243\n",
      "Epoch 46 took 0.17 seconds\n",
      "Epoch [47/100] | Train Loss: 0.5646 | Train Acc: 0.7086\n",
      "Test Loss: 0.5931 | Test Acc: 0.6806\n",
      "Epoch 47 took 0.22 seconds\n",
      "Epoch [48/100] | Train Loss: 0.5719 | Train Acc: 0.7029\n",
      "Test Loss: 0.5887 | Test Acc: 0.6508\n",
      "Epoch 48 took 0.21 seconds\n",
      "Epoch [49/100] | Train Loss: 0.5735 | Train Acc: 0.7019\n",
      "Test Loss: 0.5538 | Test Acc: 0.7130\n",
      "Epoch 49 took 0.14 seconds\n",
      "Epoch [50/100] | Train Loss: 0.5636 | Train Acc: 0.7099\n",
      "Test Loss: 0.6326 | Test Acc: 0.6463\n",
      "Epoch 50 took 0.14 seconds\n",
      "Epoch [51/100] | Train Loss: 0.5716 | Train Acc: 0.7031\n",
      "Test Loss: 0.5660 | Test Acc: 0.7157\n",
      "Epoch 51 took 0.14 seconds\n",
      "Epoch [52/100] | Train Loss: 0.5676 | Train Acc: 0.7014\n",
      "Test Loss: 0.5332 | Test Acc: 0.7490\n",
      "Epoch 52 took 0.13 seconds\n",
      "Epoch [53/100] | Train Loss: 0.5690 | Train Acc: 0.7074\n",
      "Test Loss: 0.5527 | Test Acc: 0.7162\n",
      "Epoch 53 took 0.13 seconds\n",
      "Epoch [54/100] | Train Loss: 0.5642 | Train Acc: 0.7071\n",
      "Test Loss: 0.5631 | Test Acc: 0.7181\n",
      "Epoch 54 took 0.14 seconds\n",
      "Epoch [55/100] | Train Loss: 0.5557 | Train Acc: 0.7193\n",
      "Test Loss: 0.5446 | Test Acc: 0.7313\n",
      "Epoch 55 took 0.14 seconds\n",
      "Epoch [56/100] | Train Loss: 0.5572 | Train Acc: 0.7133\n",
      "Test Loss: 0.5292 | Test Acc: 0.7314\n",
      "Epoch 56 took 0.14 seconds\n",
      "Epoch [57/100] | Train Loss: 0.5541 | Train Acc: 0.7131\n",
      "Test Loss: 0.5271 | Test Acc: 0.7442\n",
      "Epoch 57 took 0.14 seconds\n",
      "Epoch [58/100] | Train Loss: 0.5643 | Train Acc: 0.7058\n",
      "Test Loss: 0.5607 | Test Acc: 0.7080\n",
      "Epoch 58 took 0.14 seconds\n",
      "Epoch [59/100] | Train Loss: 0.5545 | Train Acc: 0.7179\n",
      "Test Loss: 0.5696 | Test Acc: 0.7282\n",
      "Epoch 59 took 0.14 seconds\n",
      "Epoch [60/100] | Train Loss: 0.5579 | Train Acc: 0.7141\n",
      "Test Loss: 0.6438 | Test Acc: 0.6718\n",
      "Epoch 60 took 0.16 seconds\n",
      "Epoch [61/100] | Train Loss: 0.5523 | Train Acc: 0.7200\n",
      "Test Loss: 0.5383 | Test Acc: 0.7242\n",
      "Epoch 61 took 0.14 seconds\n",
      "Epoch [62/100] | Train Loss: 0.5541 | Train Acc: 0.7139\n",
      "Test Loss: 0.5333 | Test Acc: 0.7436\n",
      "Epoch 62 took 0.14 seconds\n",
      "Epoch [63/100] | Train Loss: 0.5490 | Train Acc: 0.7215\n",
      "Test Loss: 0.5195 | Test Acc: 0.7461\n",
      "Epoch 63 took 0.14 seconds\n",
      "Epoch [64/100] | Train Loss: 0.5433 | Train Acc: 0.7258\n",
      "Test Loss: 0.5576 | Test Acc: 0.7225\n",
      "Epoch 64 took 0.14 seconds\n",
      "Epoch [65/100] | Train Loss: 0.5516 | Train Acc: 0.7180\n",
      "Test Loss: 0.6217 | Test Acc: 0.6187\n",
      "Epoch 65 took 0.14 seconds\n",
      "Epoch [66/100] | Train Loss: 0.5447 | Train Acc: 0.7267\n",
      "Test Loss: 0.4997 | Test Acc: 0.7574\n",
      "Epoch 66 took 0.16 seconds\n",
      "Epoch [67/100] | Train Loss: 0.5503 | Train Acc: 0.7217\n",
      "Test Loss: 0.5079 | Test Acc: 0.7519\n",
      "Epoch 67 took 0.14 seconds\n",
      "Epoch [68/100] | Train Loss: 0.5476 | Train Acc: 0.7191\n",
      "Test Loss: 0.5261 | Test Acc: 0.7343\n",
      "Epoch 68 took 0.20 seconds\n",
      "Epoch [69/100] | Train Loss: 0.5496 | Train Acc: 0.7210\n",
      "Test Loss: 0.5612 | Test Acc: 0.7109\n",
      "Epoch 69 took 0.13 seconds\n",
      "Epoch [70/100] | Train Loss: 0.5304 | Train Acc: 0.7335\n",
      "Test Loss: 0.4716 | Test Acc: 0.7824\n",
      "Epoch 70 took 0.24 seconds\n",
      "Epoch [71/100] | Train Loss: 0.5342 | Train Acc: 0.7348\n",
      "Test Loss: 0.5406 | Test Acc: 0.7208\n",
      "Epoch 71 took 0.14 seconds\n",
      "Epoch [72/100] | Train Loss: 0.5366 | Train Acc: 0.7313\n",
      "Test Loss: 0.4863 | Test Acc: 0.7818\n",
      "Epoch 72 took 0.13 seconds\n",
      "Epoch [73/100] | Train Loss: 0.5312 | Train Acc: 0.7379\n",
      "Test Loss: 0.5513 | Test Acc: 0.7107\n",
      "Epoch 73 took 0.14 seconds\n",
      "Epoch [74/100] | Train Loss: 0.5360 | Train Acc: 0.7353\n",
      "Test Loss: 0.4867 | Test Acc: 0.7798\n",
      "Epoch 74 took 0.16 seconds\n",
      "Epoch [75/100] | Train Loss: 0.5349 | Train Acc: 0.7321\n",
      "Test Loss: 0.5234 | Test Acc: 0.7455\n",
      "Epoch 75 took 0.13 seconds\n",
      "Epoch [76/100] | Train Loss: 0.5344 | Train Acc: 0.7353\n",
      "Test Loss: 0.5420 | Test Acc: 0.7250\n",
      "Epoch 76 took 0.13 seconds\n",
      "Epoch [77/100] | Train Loss: 0.5359 | Train Acc: 0.7345\n",
      "Test Loss: 0.5588 | Test Acc: 0.7055\n",
      "Epoch 77 took 0.13 seconds\n",
      "Epoch [78/100] | Train Loss: 0.5307 | Train Acc: 0.7378\n",
      "Test Loss: 0.5778 | Test Acc: 0.6697\n",
      "Epoch 78 took 0.13 seconds\n",
      "Epoch [79/100] | Train Loss: 0.5324 | Train Acc: 0.7383\n",
      "Test Loss: 0.5254 | Test Acc: 0.7395\n",
      "Epoch 79 took 0.13 seconds\n",
      "Epoch [80/100] | Train Loss: 0.5237 | Train Acc: 0.7449\n",
      "Test Loss: 0.4810 | Test Acc: 0.7737\n",
      "Epoch 80 took 0.14 seconds\n",
      "Epoch [81/100] | Train Loss: 0.5218 | Train Acc: 0.7457\n",
      "Test Loss: 0.5678 | Test Acc: 0.7073\n",
      "Epoch 81 took 0.13 seconds\n",
      "Epoch [82/100] | Train Loss: 0.5313 | Train Acc: 0.7398\n",
      "Test Loss: 0.4997 | Test Acc: 0.7718\n",
      "Epoch 82 took 0.14 seconds\n",
      "Epoch [83/100] | Train Loss: 0.5230 | Train Acc: 0.7412\n",
      "Test Loss: 0.4766 | Test Acc: 0.7766\n",
      "Epoch 83 took 0.13 seconds\n",
      "Epoch [84/100] | Train Loss: 0.5302 | Train Acc: 0.7406\n",
      "Test Loss: 0.5140 | Test Acc: 0.7592\n",
      "Epoch 84 took 0.13 seconds\n",
      "Epoch [85/100] | Train Loss: 0.5252 | Train Acc: 0.7435\n",
      "Test Loss: 0.4638 | Test Acc: 0.7946\n",
      "Epoch 85 took 0.13 seconds\n",
      "Epoch [86/100] | Train Loss: 0.5163 | Train Acc: 0.7479\n",
      "Test Loss: 0.5576 | Test Acc: 0.7088\n",
      "Epoch 86 took 0.14 seconds\n",
      "Epoch [87/100] | Train Loss: 0.5239 | Train Acc: 0.7444\n",
      "Test Loss: 0.4922 | Test Acc: 0.7617\n",
      "Epoch 87 took 0.13 seconds\n",
      "Epoch [88/100] | Train Loss: 0.5187 | Train Acc: 0.7452\n",
      "Test Loss: 0.5279 | Test Acc: 0.7395\n",
      "Epoch 88 took 0.13 seconds\n",
      "Epoch [89/100] | Train Loss: 0.5172 | Train Acc: 0.7455\n",
      "Test Loss: 0.4986 | Test Acc: 0.7652\n",
      "Epoch 89 took 0.22 seconds\n",
      "Epoch [90/100] | Train Loss: 0.5264 | Train Acc: 0.7439\n",
      "Test Loss: 0.5444 | Test Acc: 0.7237\n",
      "Epoch 90 took 0.14 seconds\n",
      "Epoch [91/100] | Train Loss: 0.5220 | Train Acc: 0.7457\n",
      "Test Loss: 0.4990 | Test Acc: 0.7557\n",
      "Epoch 91 took 0.14 seconds\n",
      "Epoch [92/100] | Train Loss: 0.5222 | Train Acc: 0.7472\n",
      "Test Loss: 0.5538 | Test Acc: 0.7213\n",
      "Epoch 92 took 0.20 seconds\n",
      "Epoch [93/100] | Train Loss: 0.5123 | Train Acc: 0.7519\n",
      "Test Loss: 0.4871 | Test Acc: 0.7736\n",
      "Epoch 93 took 0.13 seconds\n",
      "Epoch [94/100] | Train Loss: 0.5032 | Train Acc: 0.7566\n",
      "Test Loss: 0.5049 | Test Acc: 0.7673\n",
      "Epoch 94 took 0.14 seconds\n",
      "Epoch [95/100] | Train Loss: 0.4980 | Train Acc: 0.7631\n",
      "Test Loss: 0.4509 | Test Acc: 0.8027\n",
      "Epoch 95 took 0.13 seconds\n",
      "Epoch [96/100] | Train Loss: 0.4887 | Train Acc: 0.7693\n",
      "Test Loss: 0.5092 | Test Acc: 0.7465\n",
      "Epoch 96 took 0.13 seconds\n",
      "Epoch [97/100] | Train Loss: 0.4864 | Train Acc: 0.7697\n",
      "Test Loss: 0.4832 | Test Acc: 0.7691\n",
      "Epoch 97 took 0.13 seconds\n",
      "Epoch [98/100] | Train Loss: 0.4880 | Train Acc: 0.7699\n",
      "Test Loss: 0.4778 | Test Acc: 0.7728\n",
      "Epoch 98 took 0.14 seconds\n",
      "Epoch [99/100] | Train Loss: 0.4756 | Train Acc: 0.7758\n",
      "Test Loss: 0.4217 | Test Acc: 0.8106\n",
      "Epoch 99 took 0.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:02:28,775 INFO     Train accuracy 0.7630133333333333, Train Loss 0.4789587985090658\n",
      "2025-11-18 08:02:28,775 INFO     Train accuracy 0.7630133333333333, Train Loss 0.4789587985090658\n",
      "2025-11-18 08:02:28,776 INFO     Test accuracy 0.7702666666666667, Test Loss 0.4742466815474893\n",
      "2025-11-18 08:02:28,776 INFO     Test accuracy 0.7702666666666667, Test Loss 0.4742466815474893\n",
      "2025-11-18 08:02:28,777 INFO     Training model 3 took 70.63755393028259 seconds\n",
      "2025-11-18 08:02:28,777 INFO     Training model 3 took 70.63755393028259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | Train Loss: 0.4752 | Train Acc: 0.7744\n",
      "Test Loss: 0.4742 | Test Acc: 0.7703\n",
      "Epoch 100 took 0.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:03:08,802 INFO     Model loading/training took 284.9 seconds\n",
      "2025-11-18 08:03:08,802 INFO     Model loading/training took 284.9 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define experiment parameters\n",
    "num_experiments = configs[\"run\"][\"num_experiments\"]\n",
    "num_reference_models = configs[\"audit\"][\"num_ref_models\"]\n",
    "num_model_pairs = max(math.ceil(num_experiments / 2.0), num_reference_models + 1) # 2 model pairs = 4 models\n",
    "\n",
    "# train models\n",
    "baseline_time = time.time()\n",
    "\n",
    "# Split dataset for training two models per pair\n",
    "data_splits, memberships = split_dataset_for_training(\n",
    "    len(dataset), num_model_pairs\n",
    ")\n",
    "models_list = train_models(\n",
    "    log_dir, dataset, data_splits, memberships, configs, logger\n",
    ")\n",
    "logger.info(\n",
    "    \"Model loading/training took %0.1f seconds\", time.time() - baseline_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3853460",
   "metadata": {},
   "source": [
    "### Auditing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e7f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "auditing_dataset, auditing_membership = sample_auditing_dataset(\n",
    "        configs, dataset, logger, memberships\n",
    "    )\n",
    "\n",
    "# Also downsample the population set size if specified in the config\n",
    "population = Subset(\n",
    "    population,\n",
    "    np.random.choice(\n",
    "        len(population),\n",
    "        configs[\"audit\"].get(\"population_size\", len(population)),\n",
    "        replace=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69795c58",
   "metadata": {},
   "source": [
    "### Compute signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88aca9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:03:08,827 WARNING  Signals shape (750000) does not match the expected size (75000). This mismatch is likely due to a change in the training data size.\n",
      "2025-11-18 08:03:08,827 WARNING  Signals shape (750000) does not match the expected size (75000). This mismatch is likely due to a change in the training data size.\n",
      "2025-11-18 08:03:08,827 INFO     Ignoring the signals on disk and recomputing.\n",
      "2025-11-18 08:03:08,827 INFO     Ignoring the signals on disk and recomputing.\n",
      "2025-11-18 08:03:37,053 INFO     Computing signals for all models.\n",
      "2025-11-18 08:03:37,053 INFO     Computing signals for all models.\n",
      "Computing softmax: 100%|| 15/15 [00:00<00:00, 468.59it/s]\n",
      "Computing softmax: 100%|| 15/15 [00:00<00:00, 845.26it/s]\n",
      "Computing softmax: 100%|| 15/15 [00:00<00:00, 1094.99it/s]\n",
      "Computing softmax: 100%|| 15/15 [00:00<00:00, 1124.44it/s]\n",
      "2025-11-18 08:03:37,146 INFO     Signals saved to disk.\n",
      "2025-11-18 08:03:37,146 INFO     Signals saved to disk.\n",
      "2025-11-18 08:03:37,151 WARNING  Signals shape (250000) does not match the expected size (25000). This mismatch is likely due to a change in the training data size.\n",
      "2025-11-18 08:03:37,151 WARNING  Signals shape (250000) does not match the expected size (25000). This mismatch is likely due to a change in the training data size.\n",
      "2025-11-18 08:03:37,151 INFO     Ignoring the signals on disk and recomputing.\n",
      "2025-11-18 08:03:37,151 INFO     Ignoring the signals on disk and recomputing.\n",
      "2025-11-18 08:04:04,551 INFO     Computing signals for all models.\n",
      "2025-11-18 08:04:04,551 INFO     Computing signals for all models.\n",
      "Computing softmax: 100%|| 5/5 [00:00<00:00, 362.50it/s]\n",
      "Computing softmax: 100%|| 5/5 [00:00<00:00, 547.17it/s]\n",
      "Computing softmax: 100%|| 5/5 [00:00<00:00, 534.42it/s]\n",
      "Computing softmax: 100%|| 5/5 [00:00<00:00, 515.25it/s]\n",
      "2025-11-18 08:04:04,605 INFO     Signals saved to disk.\n",
      "2025-11-18 08:04:04,605 INFO     Signals saved to disk.\n",
      "2025-11-18 08:04:04,606 INFO     Preparing signals took 55.78891 seconds\n",
      "2025-11-18 08:04:04,606 INFO     Preparing signals took 55.78891 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "signals = get_model_signals(models_list, auditing_dataset, configs, logger)\n",
    "population_signals = get_model_signals(\n",
    "        models_list, population, configs, logger, is_population=True\n",
    "    )\n",
    "logger.info(\"Preparing signals took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5494b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:06:09,951 INFO     Fine-tuning offline_a using paired model 1\n",
      "2025-11-18 08:06:09,951 INFO     Fine-tuning offline_a using paired model 1\n",
      "2025-11-18 08:06:15,071 INFO     offline_a=0.00: AUC 0.5013\n",
      "2025-11-18 08:06:15,071 INFO     offline_a=0.00: AUC 0.5013\n",
      "2025-11-18 08:06:17,017 INFO     offline_a=0.10: AUC 0.5014\n",
      "2025-11-18 08:06:17,017 INFO     offline_a=0.10: AUC 0.5014\n",
      "2025-11-18 08:06:19,646 INFO     offline_a=0.20: AUC 0.5014\n",
      "2025-11-18 08:06:19,646 INFO     offline_a=0.20: AUC 0.5014\n",
      "2025-11-18 08:06:21,018 INFO     offline_a=0.30: AUC 0.5014\n",
      "2025-11-18 08:06:21,018 INFO     offline_a=0.30: AUC 0.5014\n",
      "2025-11-18 08:06:22,360 INFO     offline_a=0.40: AUC 0.5012\n",
      "2025-11-18 08:06:22,360 INFO     offline_a=0.40: AUC 0.5012\n",
      "2025-11-18 08:06:23,769 INFO     offline_a=0.50: AUC 0.5012\n",
      "2025-11-18 08:06:23,769 INFO     offline_a=0.50: AUC 0.5012\n",
      "2025-11-18 08:06:26,251 INFO     offline_a=0.60: AUC 0.5013\n",
      "2025-11-18 08:06:26,251 INFO     offline_a=0.60: AUC 0.5013\n",
      "2025-11-18 08:06:27,614 INFO     offline_a=0.70: AUC 0.5011\n",
      "2025-11-18 08:06:27,614 INFO     offline_a=0.70: AUC 0.5011\n",
      "2025-11-18 08:06:28,977 INFO     offline_a=0.80: AUC 0.5010\n",
      "2025-11-18 08:06:28,977 INFO     offline_a=0.80: AUC 0.5010\n",
      "2025-11-18 08:06:30,435 INFO     offline_a=0.90: AUC 0.5009\n",
      "2025-11-18 08:06:30,435 INFO     offline_a=0.90: AUC 0.5009\n",
      "2025-11-18 08:06:32,665 INFO     offline_a=1.00: AUC 0.5010\n",
      "2025-11-18 08:06:32,665 INFO     offline_a=1.00: AUC 0.5010\n",
      "2025-11-18 08:06:32,666 INFO     The best offline_a is 0.1\n",
      "2025-11-18 08:06:32,666 INFO     The best offline_a is 0.1\n",
      "2025-11-18 08:06:34,965 INFO     Target Model 0: AUC 0.5029, TPR@0.1%FPR of 0.0000, TPR@0.0%FPR of 0.0000\n",
      "2025-11-18 08:06:34,965 INFO     Target Model 0: AUC 0.5029, TPR@0.1%FPR of 0.0000, TPR@0.0%FPR of 0.0000\n",
      "2025-11-18 08:06:38,924 INFO     Auditing the privacy risks of target model 0 costs 29.0 seconds\n",
      "2025-11-18 08:06:38,924 INFO     Auditing the privacy risks of target model 0 costs 29.0 seconds\n",
      "2025-11-18 08:06:38,924 INFO     Total runtime: 503.18462 seconds\n",
      "2025-11-18 08:06:38,924 INFO     Total runtime: 503.18462 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform the privacy audit\n",
    "baseline_time = time.time()\n",
    "target_model_indices = list(range(num_experiments))\n",
    "mia_score_list, membership_list = audit_models(\n",
    "        f\"{directories['report_dir']}/exp\",\n",
    "        target_model_indices,\n",
    "        signals,\n",
    "        population_signals,\n",
    "        auditing_membership,\n",
    "        num_reference_models,\n",
    "        logger,\n",
    "        configs,\n",
    "    )\n",
    "\n",
    "if len(target_model_indices) > 1:\n",
    "    logger.info(\n",
    "        \"Auditing privacy risk took %0.1f seconds\", time.time() - baseline_time\n",
    "    )\n",
    "\n",
    "# Get average audit results across all experiments\n",
    "if len(target_model_indices) > 1:\n",
    "    get_average_audit_results(\n",
    "        directories[\"report_dir\"], mia_score_list, membership_list, logger\n",
    "    )\n",
    "\n",
    "logger.info(\"Total runtime: %0.5f seconds\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919230e",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e51736",
   "metadata": {},
   "source": [
    "1) Experiment with a different dataset.\n",
    "2) Implement a regularization technique as a defense strategy against MIAs.\n",
    "3) Re-evaluate MIAs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISec-class-DqnUEjF1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
