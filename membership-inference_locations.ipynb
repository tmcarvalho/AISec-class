{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b5aa0f",
   "metadata": {},
   "source": [
    "# Membership Inference Attacks (MIAs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c8779",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to evaluate and improve the privacy of machine learning models using RMIA from privacy meter tool. \n",
    "\n",
    "You will conduct hands-on audits on \"locations\" tabular dataset and CNN model.\n",
    "\n",
    "1. Download data and create a config file according data and model.\n",
    "2. Train the target model for auditing.\n",
    "3. Compute signals (confidence).\n",
    "4. Analyze the MIA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea18b1",
   "metadata": {},
   "source": [
    "### Environment steup with Pipenv\n",
    "\n",
    "````\n",
    "pipenv --python 3.12\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the forked github repo\n",
    "!git clone https://github.com/<user_name>/ml_privacy_meter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tania.carvalho/Desktop/repos/AISec-class/ml_privacy_meter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tania.carvalho/.local/share/virtualenvs/AISec-class-DqnUEjF1/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Change the directory to the cloned repo\n",
    "import sys\n",
    "sys.path.append('/content/ml_privacy_meter')\n",
    "\n",
    "%cd ml_privacy_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4af344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install datasets==2.21.0 transformers==4.44.2 torch==2.4.1 torchvision==0.19.1 torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43901c9",
   "metadata": {},
   "source": [
    "Delete all CUDA-related lines from requirements.txt if your machine does not support it\n",
    "```\n",
    "nvidia-cublas-cu11\n",
    "nvidia-cudnn-cu11\n",
    "nvidia-...\n",
    "triton\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6596a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import tarfile\n",
    "import zipfile\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from dataset import TabularDataset\n",
    "from audit import get_average_audit_results, audit_models, sample_auditing_dataset\n",
    "from get_signals import get_model_signals\n",
    "from models.utils import train_models, split_dataset_for_training\n",
    "from util import (\n",
    "    check_configs,\n",
    "    setup_log,\n",
    "    initialize_seeds,\n",
    "    create_directories\n",
    ")\n",
    "\n",
    "# Enable benchmark mode in cudnn to improve performance when input sizes are consistent\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config_yaml(config_dir: str, filename: str = \"config.yaml\"):\n",
    "    \"\"\"\n",
    "    Automatically writes a YAML file into a directory.\n",
    "    Creates the directory if it does not exist.\n",
    "    \"\"\"\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    filepath = os.path.join(config_dir, filename)\n",
    "\n",
    "    config = {\n",
    "        \"run\": {\n",
    "            \"random_seed\": 12345,\n",
    "            \"log_dir\": \"demo_locations\",\n",
    "            \"time_log\": True,\n",
    "            \"num_experiments\": 1,\n",
    "        },\n",
    "\n",
    "        \"audit\": {\n",
    "            \"privacy_game\": \"privacy_loss_model\",\n",
    "            \"algorithm\": \"RMIA\",\n",
    "            \"num_ref_models\": 1,\n",
    "            \"device\": \"cpu\",\n",
    "            \"report_log\": \"report_rmia\",\n",
    "            \"batch_size\": 5000,\n",
    "            # \"data_size\": 10000 \n",
    "        },\n",
    "\n",
    "        \"train\": {\n",
    "            \"model_name\": \"mlp\",\n",
    "            \"device\": \"cpu\",\n",
    "            \"batch_size\": 256,\n",
    "            \"optimizer\": \"SGD\",\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"weight_decay\": 0,\n",
    "            \"epochs\": 100,\n",
    "        },\n",
    "        \n",
    "        \"data\": {\n",
    "            \"dataset\": \"locations\",\n",
    "            \"data_dir\": \"data_locations\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c5ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'configs/locations_test.yaml'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_config_yaml(\"configs\", \"locations_test.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs\n",
    "configs = \"configs/locations.yaml\"\n",
    "with open(configs, \"rb\") as f:\n",
    "        configs = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Validate configurations\n",
    "check_configs(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b168e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate configurations\n",
    "check_configs(configs)\n",
    "\n",
    "# Initialize seeds for reproducibility\n",
    "initialize_seeds(configs[\"run\"][\"random_seed\"])\n",
    "\n",
    "# Create necessary directories\n",
    "log_dir = configs[\"run\"][\"log_dir\"]\n",
    "directories = {\n",
    "    \"log_dir\": log_dir,\n",
    "    \"report_dir\": f\"{log_dir}/report\",\n",
    "    \"signal_dir\": f\"{log_dir}/signals\",\n",
    "    \"data_dir\": f\"{configs[\"data\"][\"data_dir\"]}\",\n",
    "}\n",
    "create_directories(directories)\n",
    "\n",
    "# Set up logger\n",
    "logger = setup_log(\n",
    "    directories[\"report_dir\"], \"time_analysis\", configs[\"run\"][\"time_log\"]\n",
    ")\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a36d2",
   "metadata": {},
   "source": [
    "### Locations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cff1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/bg3_1x4507x5p5x4xjl3z78r0000gn/T/ipykernel_4437/1177567434.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Label'] = df.pop(0) # move label to last column\n"
     ]
    }
   ],
   "source": [
    "def download_file(url, compression, compressed_file, temp_dir_name):\n",
    "    urllib.request.urlretrieve(url, compressed_file)\n",
    "\n",
    "    if compression == 'tar':\n",
    "        with tarfile.open(compressed_file, 'r:gz') as tar:\n",
    "            tar.extractall(temp_dir_name, filter='fully_trusted')\n",
    "        os.remove(compressed_file)\n",
    "\n",
    "    elif compression == 'zip':\n",
    "        with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir_name)\n",
    "        os.remove(compressed_file)\n",
    "\n",
    "# Download dataset\n",
    "url = 'https://github.com/privacytrustlab/datasets/raw/refs/heads/master/dataset_location.tgz'\n",
    "temp_dir = 'locations_dir'\n",
    "download_file(url, 'tar', 'dataset_location.tgz', temp_dir)\n",
    "df = pd.read_csv(os.path.join(temp_dir, 'bangkok'), header=None)\n",
    "df['Label'] = df.pop(0) # move label to last column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25758c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:09:40,720 INFO     Save data to data_locations/locations.pkl\n",
      "2025-11-28 11:09:40,720 INFO     Save data to data_locations/locations.pkl\n",
      "2025-11-28 11:09:40,731 INFO     Save population data to data_locations/locations_population.pkl\n",
      "2025-11-28 11:09:40,731 INFO     Save population data to data_locations/locations_population.pkl\n"
     ]
    }
   ],
   "source": [
    "# Set up logger\n",
    "logger = setup_log(\n",
    "    directories[\"report_dir\"], \"time_analysis\", configs[\"run\"][\"time_log\"]\n",
    ")\n",
    "\n",
    "path = f\"{configs[\"data\"][\"data_dir\"]}/{configs[\"data\"][\"dataset\"]}\"\n",
    "\n",
    "df = df.to_numpy()\n",
    "y = df[:, -1]\n",
    "X = df[:, :-1].astype(np.float32)\n",
    "training_size = int(\n",
    "    len(y) * 0.75\n",
    ")  # Splitting to create a population dataset\n",
    "dataset = TabularDataset(X[:training_size], y[:training_size])\n",
    "population = TabularDataset(X[training_size:], y[training_size:])\n",
    "with open(f\"{path}.pkl\", \"wb\") as file:\n",
    "    pickle.dump(dataset, file)\n",
    "logger.info(f\"Save data to {path}.pkl\")\n",
    "with open(f\"{path}_population.pkl\", \"wb\") as file:\n",
    "    pickle.dump(population, file)\n",
    "logger.info(f\"Save population data to {path}_population.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb95ca",
   "metadata": {},
   "source": [
    "Update ouput shape with the tested dataset [number of features, number of classes] -- models/utils.py\n",
    "\n",
    "```\n",
    "INPUT_OUTPUT_SHAPE = {\n",
    "    \"cifar10\": [3, 10],\n",
    "    \"cifar100\": [3, 100],\n",
    "    \"purchase100\": [600, 100],\n",
    "    \"texas100\": [6169, 100],\n",
    "    \"heart-statlog\": [13, 2],\n",
    "    \"locations\": [446, 31]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83d9417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array: (3757, 446)\n",
      "Number of unique values in target column: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of array:\", dataset.data.shape)       # number of rows/columns\n",
    "print(\"Number of unique values in target column:\", len(np.unique(dataset.targets)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59e0ee",
   "metadata": {},
   "source": [
    "### Train models --- CNN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649496f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:09:53,679 INFO     Training 4 models\n",
      "2025-11-28 11:09:53,679 INFO     Training 4 models\n",
      "2025-11-28 11:09:53,687 INFO     --------------------------------------------------\n",
      "2025-11-28 11:09:53,687 INFO     --------------------------------------------------\n",
      "2025-11-28 11:09:53,689 INFO     Training model 0: Train size 1878, Test size 1879\n",
      "2025-11-28 11:09:53,689 INFO     Training model 0: Train size 1878, Test size 1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 3.4336 | Train Acc: 0.0367\n",
      "Test Loss: 3.4282 | Test Acc: 0.0282\n",
      "Epoch 1 took 17.33 seconds\n",
      "Epoch [2/100] | Train Loss: 3.4282 | Train Acc: 0.0389\n",
      "Test Loss: 3.4224 | Test Acc: 0.0314\n",
      "Epoch 2 took 0.04 seconds\n",
      "Epoch [3/100] | Train Loss: 3.4237 | Train Acc: 0.0367\n",
      "Test Loss: 3.4198 | Test Acc: 0.0367\n",
      "Epoch 3 took 0.02 seconds\n",
      "Epoch [4/100] | Train Loss: 3.4158 | Train Acc: 0.0426\n",
      "Test Loss: 3.4120 | Test Acc: 0.0399\n",
      "Epoch 4 took 0.02 seconds\n",
      "Epoch [5/100] | Train Loss: 3.4090 | Train Acc: 0.0501\n",
      "Test Loss: 3.4088 | Test Acc: 0.0442\n",
      "Epoch 5 took 0.01 seconds\n",
      "Epoch [6/100] | Train Loss: 3.4060 | Train Acc: 0.0522\n",
      "Test Loss: 3.4007 | Test Acc: 0.0474\n",
      "Epoch 6 took 0.02 seconds\n",
      "Epoch [7/100] | Train Loss: 3.3994 | Train Acc: 0.0564\n",
      "Test Loss: 3.3999 | Test Acc: 0.0495\n",
      "Epoch 7 took 0.01 seconds\n",
      "Epoch [8/100] | Train Loss: 3.3932 | Train Acc: 0.0575\n",
      "Test Loss: 3.3930 | Test Acc: 0.0479\n",
      "Epoch 8 took 0.02 seconds\n",
      "Epoch [9/100] | Train Loss: 3.3879 | Train Acc: 0.0612\n",
      "Test Loss: 3.3884 | Test Acc: 0.0527\n",
      "Epoch 9 took 0.01 seconds\n",
      "Epoch [10/100] | Train Loss: 3.3802 | Train Acc: 0.0650\n",
      "Test Loss: 3.3826 | Test Acc: 0.0564\n",
      "Epoch 10 took 0.01 seconds\n",
      "Epoch [11/100] | Train Loss: 3.3771 | Train Acc: 0.0687\n",
      "Test Loss: 3.3793 | Test Acc: 0.0596\n",
      "Epoch 11 took 0.01 seconds\n",
      "Epoch [12/100] | Train Loss: 3.3719 | Train Acc: 0.0756\n",
      "Test Loss: 3.3748 | Test Acc: 0.0617\n",
      "Epoch 12 took 0.01 seconds\n",
      "Epoch [13/100] | Train Loss: 3.3679 | Train Acc: 0.0788\n",
      "Test Loss: 3.3712 | Test Acc: 0.0644\n",
      "Epoch 13 took 0.01 seconds\n",
      "Epoch [14/100] | Train Loss: 3.3607 | Train Acc: 0.0799\n",
      "Test Loss: 3.3660 | Test Acc: 0.0671\n",
      "Epoch 14 took 0.02 seconds\n",
      "Epoch [15/100] | Train Loss: 3.3581 | Train Acc: 0.0825\n",
      "Test Loss: 3.3612 | Test Acc: 0.0681\n",
      "Epoch 15 took 0.01 seconds\n",
      "Epoch [16/100] | Train Loss: 3.3522 | Train Acc: 0.0868\n",
      "Test Loss: 3.3557 | Test Acc: 0.0708\n",
      "Epoch 16 took 0.01 seconds\n",
      "Epoch [17/100] | Train Loss: 3.3447 | Train Acc: 0.0900\n",
      "Test Loss: 3.3543 | Test Acc: 0.0745\n",
      "Epoch 17 took 0.01 seconds\n",
      "Epoch [18/100] | Train Loss: 3.3405 | Train Acc: 0.0927\n",
      "Test Loss: 3.3477 | Test Acc: 0.0798\n",
      "Epoch 18 took 0.01 seconds\n",
      "Epoch [19/100] | Train Loss: 3.3334 | Train Acc: 0.0953\n",
      "Test Loss: 3.3455 | Test Acc: 0.0836\n",
      "Epoch 19 took 0.01 seconds\n",
      "Epoch [20/100] | Train Loss: 3.3304 | Train Acc: 0.0964\n",
      "Test Loss: 3.3373 | Test Acc: 0.0846\n",
      "Epoch 20 took 0.01 seconds\n",
      "Epoch [21/100] | Train Loss: 3.3253 | Train Acc: 0.0969\n",
      "Test Loss: 3.3367 | Test Acc: 0.0862\n",
      "Epoch 21 took 0.01 seconds\n",
      "Epoch [22/100] | Train Loss: 3.3222 | Train Acc: 0.0980\n",
      "Test Loss: 3.3308 | Test Acc: 0.0862\n",
      "Epoch 22 took 0.01 seconds\n",
      "Epoch [23/100] | Train Loss: 3.3171 | Train Acc: 0.1001\n",
      "Test Loss: 3.3286 | Test Acc: 0.0862\n",
      "Epoch 23 took 0.01 seconds\n",
      "Epoch [24/100] | Train Loss: 3.3138 | Train Acc: 0.0996\n",
      "Test Loss: 3.3272 | Test Acc: 0.0867\n",
      "Epoch 24 took 0.01 seconds\n",
      "Epoch [25/100] | Train Loss: 3.3081 | Train Acc: 0.1001\n",
      "Test Loss: 3.3220 | Test Acc: 0.0878\n",
      "Epoch 25 took 0.01 seconds\n",
      "Epoch [26/100] | Train Loss: 3.3021 | Train Acc: 0.1022\n",
      "Test Loss: 3.3139 | Test Acc: 0.0894\n",
      "Epoch 26 took 0.01 seconds\n",
      "Epoch [27/100] | Train Loss: 3.2992 | Train Acc: 0.1022\n",
      "Test Loss: 3.3116 | Test Acc: 0.0905\n",
      "Epoch 27 took 0.01 seconds\n",
      "Epoch [28/100] | Train Loss: 3.2905 | Train Acc: 0.1017\n",
      "Test Loss: 3.3057 | Test Acc: 0.0905\n",
      "Epoch 28 took 0.01 seconds\n",
      "Epoch [29/100] | Train Loss: 3.2896 | Train Acc: 0.1028\n",
      "Test Loss: 3.3091 | Test Acc: 0.0931\n",
      "Epoch 29 took 0.01 seconds\n",
      "Epoch [30/100] | Train Loss: 3.2837 | Train Acc: 0.1028\n",
      "Test Loss: 3.2999 | Test Acc: 0.0931\n",
      "Epoch 30 took 0.01 seconds\n",
      "Epoch [31/100] | Train Loss: 3.2822 | Train Acc: 0.1038\n",
      "Test Loss: 3.2989 | Test Acc: 0.0937\n",
      "Epoch 31 took 0.01 seconds\n",
      "Epoch [32/100] | Train Loss: 3.2775 | Train Acc: 0.1049\n",
      "Test Loss: 3.2929 | Test Acc: 0.0931\n",
      "Epoch 32 took 0.01 seconds\n",
      "Epoch [33/100] | Train Loss: 3.2705 | Train Acc: 0.1054\n",
      "Test Loss: 3.2908 | Test Acc: 0.0937\n",
      "Epoch 33 took 0.01 seconds\n",
      "Epoch [34/100] | Train Loss: 3.2678 | Train Acc: 0.1054\n",
      "Test Loss: 3.2837 | Test Acc: 0.0937\n",
      "Epoch 34 took 0.01 seconds\n",
      "Epoch [35/100] | Train Loss: 3.2669 | Train Acc: 0.1054\n",
      "Test Loss: 3.2815 | Test Acc: 0.0942\n",
      "Epoch 35 took 0.01 seconds\n",
      "Epoch [36/100] | Train Loss: 3.2634 | Train Acc: 0.1054\n",
      "Test Loss: 3.2792 | Test Acc: 0.0942\n",
      "Epoch 36 took 0.01 seconds\n",
      "Epoch [37/100] | Train Loss: 3.2553 | Train Acc: 0.1065\n",
      "Test Loss: 3.2792 | Test Acc: 0.0953\n",
      "Epoch 37 took 0.01 seconds\n",
      "Epoch [38/100] | Train Loss: 3.2470 | Train Acc: 0.1065\n",
      "Test Loss: 3.2735 | Test Acc: 0.0958\n",
      "Epoch 38 took 0.01 seconds\n",
      "Epoch [39/100] | Train Loss: 3.2461 | Train Acc: 0.1076\n",
      "Test Loss: 3.2654 | Test Acc: 0.0958\n",
      "Epoch 39 took 0.01 seconds\n",
      "Epoch [40/100] | Train Loss: 3.2448 | Train Acc: 0.1070\n",
      "Test Loss: 3.2638 | Test Acc: 0.0963\n",
      "Epoch 40 took 0.01 seconds\n",
      "Epoch [41/100] | Train Loss: 3.2350 | Train Acc: 0.1076\n",
      "Test Loss: 3.2604 | Test Acc: 0.0969\n",
      "Epoch 41 took 0.01 seconds\n",
      "Epoch [42/100] | Train Loss: 3.2341 | Train Acc: 0.1086\n",
      "Test Loss: 3.2568 | Test Acc: 0.0974\n",
      "Epoch 42 took 0.01 seconds\n",
      "Epoch [43/100] | Train Loss: 3.2293 | Train Acc: 0.1102\n",
      "Test Loss: 3.2499 | Test Acc: 0.0974\n",
      "Epoch 43 took 0.01 seconds\n",
      "Epoch [44/100] | Train Loss: 3.2249 | Train Acc: 0.1124\n",
      "Test Loss: 3.2467 | Test Acc: 0.0979\n",
      "Epoch 44 took 0.01 seconds\n",
      "Epoch [45/100] | Train Loss: 3.2219 | Train Acc: 0.1134\n",
      "Test Loss: 3.2463 | Test Acc: 0.0985\n",
      "Epoch 45 took 0.01 seconds\n",
      "Epoch [46/100] | Train Loss: 3.2170 | Train Acc: 0.1140\n",
      "Test Loss: 3.2447 | Test Acc: 0.0990\n",
      "Epoch 46 took 0.01 seconds\n",
      "Epoch [47/100] | Train Loss: 3.2146 | Train Acc: 0.1140\n",
      "Test Loss: 3.2363 | Test Acc: 0.0990\n",
      "Epoch 47 took 0.01 seconds\n",
      "Epoch [48/100] | Train Loss: 3.2133 | Train Acc: 0.1145\n",
      "Test Loss: 3.2371 | Test Acc: 0.0990\n",
      "Epoch 48 took 0.01 seconds\n",
      "Epoch [49/100] | Train Loss: 3.2080 | Train Acc: 0.1155\n",
      "Test Loss: 3.2333 | Test Acc: 0.0995\n",
      "Epoch 49 took 0.01 seconds\n",
      "Epoch [50/100] | Train Loss: 3.2076 | Train Acc: 0.1166\n",
      "Test Loss: 3.2327 | Test Acc: 0.1006\n",
      "Epoch 50 took 0.01 seconds\n",
      "Epoch [51/100] | Train Loss: 3.1986 | Train Acc: 0.1177\n",
      "Test Loss: 3.2235 | Test Acc: 0.1011\n",
      "Epoch 51 took 0.01 seconds\n",
      "Epoch [52/100] | Train Loss: 3.1930 | Train Acc: 0.1187\n",
      "Test Loss: 3.2243 | Test Acc: 0.1016\n",
      "Epoch 52 took 0.01 seconds\n",
      "Epoch [53/100] | Train Loss: 3.1926 | Train Acc: 0.1203\n",
      "Test Loss: 3.2205 | Test Acc: 0.1032\n",
      "Epoch 53 took 0.01 seconds\n",
      "Epoch [54/100] | Train Loss: 3.1872 | Train Acc: 0.1214\n",
      "Test Loss: 3.2162 | Test Acc: 0.1054\n",
      "Epoch 54 took 0.01 seconds\n",
      "Epoch [55/100] | Train Loss: 3.1810 | Train Acc: 0.1230\n",
      "Test Loss: 3.2133 | Test Acc: 0.1059\n",
      "Epoch 55 took 0.01 seconds\n",
      "Epoch [56/100] | Train Loss: 3.1779 | Train Acc: 0.1257\n",
      "Test Loss: 3.2086 | Test Acc: 0.1059\n",
      "Epoch 56 took 0.01 seconds\n",
      "Epoch [57/100] | Train Loss: 3.1732 | Train Acc: 0.1257\n",
      "Test Loss: 3.2083 | Test Acc: 0.1059\n",
      "Epoch 57 took 0.01 seconds\n",
      "Epoch [58/100] | Train Loss: 3.1734 | Train Acc: 0.1257\n",
      "Test Loss: 3.2048 | Test Acc: 0.1080\n",
      "Epoch 58 took 0.01 seconds\n",
      "Epoch [59/100] | Train Loss: 3.1660 | Train Acc: 0.1267\n",
      "Test Loss: 3.1989 | Test Acc: 0.1091\n",
      "Epoch 59 took 0.24 seconds\n",
      "Epoch [60/100] | Train Loss: 3.1702 | Train Acc: 0.1283\n",
      "Test Loss: 3.1953 | Test Acc: 0.1091\n",
      "Epoch 60 took 0.01 seconds\n",
      "Epoch [61/100] | Train Loss: 3.1626 | Train Acc: 0.1289\n",
      "Test Loss: 3.1967 | Test Acc: 0.1112\n",
      "Epoch 61 took 0.01 seconds\n",
      "Epoch [62/100] | Train Loss: 3.1551 | Train Acc: 0.1315\n",
      "Test Loss: 3.1898 | Test Acc: 0.1123\n",
      "Epoch 62 took 0.01 seconds\n",
      "Epoch [63/100] | Train Loss: 3.1593 | Train Acc: 0.1294\n",
      "Test Loss: 3.1916 | Test Acc: 0.1128\n",
      "Epoch 63 took 0.01 seconds\n",
      "Epoch [64/100] | Train Loss: 3.1549 | Train Acc: 0.1310\n",
      "Test Loss: 3.1884 | Test Acc: 0.1150\n",
      "Epoch 64 took 0.01 seconds\n",
      "Epoch [65/100] | Train Loss: 3.1513 | Train Acc: 0.1331\n",
      "Test Loss: 3.1852 | Test Acc: 0.1171\n",
      "Epoch 65 took 0.01 seconds\n",
      "Epoch [66/100] | Train Loss: 3.1488 | Train Acc: 0.1337\n",
      "Test Loss: 3.1815 | Test Acc: 0.1187\n",
      "Epoch 66 took 0.01 seconds\n",
      "Epoch [67/100] | Train Loss: 3.1426 | Train Acc: 0.1347\n",
      "Test Loss: 3.1769 | Test Acc: 0.1181\n",
      "Epoch 67 took 0.01 seconds\n",
      "Epoch [68/100] | Train Loss: 3.1405 | Train Acc: 0.1358\n",
      "Test Loss: 3.1790 | Test Acc: 0.1192\n",
      "Epoch 68 took 0.01 seconds\n",
      "Epoch [69/100] | Train Loss: 3.1391 | Train Acc: 0.1379\n",
      "Test Loss: 3.1735 | Test Acc: 0.1203\n",
      "Epoch 69 took 0.01 seconds\n",
      "Epoch [70/100] | Train Loss: 3.1322 | Train Acc: 0.1390\n",
      "Test Loss: 3.1694 | Test Acc: 0.1203\n",
      "Epoch 70 took 0.01 seconds\n",
      "Epoch [71/100] | Train Loss: 3.1271 | Train Acc: 0.1395\n",
      "Test Loss: 3.1676 | Test Acc: 0.1203\n",
      "Epoch 71 took 0.01 seconds\n",
      "Epoch [72/100] | Train Loss: 3.1299 | Train Acc: 0.1406\n",
      "Test Loss: 3.1653 | Test Acc: 0.1219\n",
      "Epoch 72 took 0.01 seconds\n",
      "Epoch [73/100] | Train Loss: 3.1225 | Train Acc: 0.1422\n",
      "Test Loss: 3.1627 | Test Acc: 0.1224\n",
      "Epoch 73 took 0.01 seconds\n",
      "Epoch [74/100] | Train Loss: 3.1219 | Train Acc: 0.1416\n",
      "Test Loss: 3.1617 | Test Acc: 0.1240\n",
      "Epoch 74 took 0.01 seconds\n",
      "Epoch [75/100] | Train Loss: 3.1167 | Train Acc: 0.1459\n",
      "Test Loss: 3.1539 | Test Acc: 0.1256\n",
      "Epoch 75 took 0.01 seconds\n",
      "Epoch [76/100] | Train Loss: 3.1138 | Train Acc: 0.1464\n",
      "Test Loss: 3.1546 | Test Acc: 0.1256\n",
      "Epoch 76 took 0.01 seconds\n",
      "Epoch [77/100] | Train Loss: 3.1095 | Train Acc: 0.1470\n",
      "Test Loss: 3.1581 | Test Acc: 0.1261\n",
      "Epoch 77 took 0.01 seconds\n",
      "Epoch [78/100] | Train Loss: 3.1109 | Train Acc: 0.1486\n",
      "Test Loss: 3.1546 | Test Acc: 0.1277\n",
      "Epoch 78 took 0.01 seconds\n",
      "Epoch [79/100] | Train Loss: 3.1117 | Train Acc: 0.1496\n",
      "Test Loss: 3.1531 | Test Acc: 0.1293\n",
      "Epoch 79 took 0.01 seconds\n",
      "Epoch [80/100] | Train Loss: 3.1043 | Train Acc: 0.1507\n",
      "Test Loss: 3.1472 | Test Acc: 0.1309\n",
      "Epoch 80 took 0.01 seconds\n",
      "Epoch [81/100] | Train Loss: 3.1049 | Train Acc: 0.1528\n",
      "Test Loss: 3.1406 | Test Acc: 0.1315\n",
      "Epoch 81 took 0.01 seconds\n",
      "Epoch [82/100] | Train Loss: 3.1047 | Train Acc: 0.1550\n",
      "Test Loss: 3.1405 | Test Acc: 0.1325\n",
      "Epoch 82 took 0.01 seconds\n",
      "Epoch [83/100] | Train Loss: 3.1021 | Train Acc: 0.1560\n",
      "Test Loss: 3.1343 | Test Acc: 0.1330\n",
      "Epoch 83 took 0.01 seconds\n",
      "Epoch [84/100] | Train Loss: 3.1005 | Train Acc: 0.1560\n",
      "Test Loss: 3.1373 | Test Acc: 0.1336\n",
      "Epoch 84 took 0.01 seconds\n",
      "Epoch [85/100] | Train Loss: 3.0948 | Train Acc: 0.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:10:12,540 INFO     Train accuracy 0.17092651757188498, Train Loss 3.068082332611084\n",
      "2025-11-28 11:10:12,540 INFO     Train accuracy 0.17092651757188498, Train Loss 3.068082332611084\n",
      "2025-11-28 11:10:12,541 INFO     Test accuracy 0.14635444385311336, Test Loss 3.1098255813121796\n",
      "2025-11-28 11:10:12,541 INFO     Test accuracy 0.14635444385311336, Test Loss 3.1098255813121796\n",
      "2025-11-28 11:10:12,543 INFO     Training model 0 took 18.85512614250183 seconds\n",
      "2025-11-28 11:10:12,543 INFO     Training model 0 took 18.85512614250183 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.1362 | Test Acc: 0.1346\n",
      "Epoch 85 took 0.01 seconds\n",
      "Epoch [86/100] | Train Loss: 3.0931 | Train Acc: 0.1571\n",
      "Test Loss: 3.1325 | Test Acc: 0.1357\n",
      "Epoch 86 took 0.01 seconds\n",
      "Epoch [87/100] | Train Loss: 3.0905 | Train Acc: 0.1587\n",
      "Test Loss: 3.1342 | Test Acc: 0.1357\n",
      "Epoch 87 took 0.01 seconds\n",
      "Epoch [88/100] | Train Loss: 3.0904 | Train Acc: 0.1603\n",
      "Test Loss: 3.1274 | Test Acc: 0.1357\n",
      "Epoch 88 took 0.01 seconds\n",
      "Epoch [89/100] | Train Loss: 3.0889 | Train Acc: 0.1608\n",
      "Test Loss: 3.1312 | Test Acc: 0.1373\n",
      "Epoch 89 took 0.01 seconds\n",
      "Epoch [90/100] | Train Loss: 3.0876 | Train Acc: 0.1619\n",
      "Test Loss: 3.1198 | Test Acc: 0.1373\n",
      "Epoch 90 took 0.01 seconds\n",
      "Epoch [91/100] | Train Loss: 3.0845 | Train Acc: 0.1608\n",
      "Test Loss: 3.1262 | Test Acc: 0.1389\n",
      "Epoch 91 took 0.01 seconds\n",
      "Epoch [92/100] | Train Loss: 3.0833 | Train Acc: 0.1645\n",
      "Test Loss: 3.1247 | Test Acc: 0.1410\n",
      "Epoch 92 took 0.01 seconds\n",
      "Epoch [93/100] | Train Loss: 3.0818 | Train Acc: 0.1651\n",
      "Test Loss: 3.1251 | Test Acc: 0.1410\n",
      "Epoch 93 took 0.01 seconds\n",
      "Epoch [94/100] | Train Loss: 3.0812 | Train Acc: 0.1677\n",
      "Test Loss: 3.1261 | Test Acc: 0.1432\n",
      "Epoch 94 took 0.01 seconds\n",
      "Epoch [95/100] | Train Loss: 3.0721 | Train Acc: 0.1683\n",
      "Test Loss: 3.1158 | Test Acc: 0.1442\n",
      "Epoch 95 took 0.01 seconds\n",
      "Epoch [96/100] | Train Loss: 3.0750 | Train Acc: 0.1688\n",
      "Test Loss: 3.1171 | Test Acc: 0.1453\n",
      "Epoch 96 took 0.01 seconds\n",
      "Epoch [97/100] | Train Loss: 3.0709 | Train Acc: 0.1699\n",
      "Test Loss: 3.1150 | Test Acc: 0.1458\n",
      "Epoch 97 took 0.01 seconds\n",
      "Epoch [98/100] | Train Loss: 3.0743 | Train Acc: 0.1704\n",
      "Test Loss: 3.1143 | Test Acc: 0.1464\n",
      "Epoch 98 took 0.01 seconds\n",
      "Epoch [99/100] | Train Loss: 3.0723 | Train Acc: 0.1709\n",
      "Test Loss: 3.1140 | Test Acc: 0.1464\n",
      "Epoch 99 took 0.01 seconds\n",
      "Epoch [100/100] | Train Loss: 3.0674 | Train Acc: 0.1709\n",
      "Test Loss: 3.1169 | Test Acc: 0.1464\n",
      "Epoch 100 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:10:12,556 INFO     --------------------------------------------------\n",
      "2025-11-28 11:10:12,556 INFO     --------------------------------------------------\n",
      "2025-11-28 11:10:12,556 INFO     Training model 1: Train size 1879, Test size 1878\n",
      "2025-11-28 11:10:12,556 INFO     Training model 1: Train size 1879, Test size 1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 3.4464 | Train Acc: 0.0314\n",
      "Test Loss: 3.4461 | Test Acc: 0.0266\n",
      "Epoch 1 took 16.19 seconds\n",
      "Epoch [2/100] | Train Loss: 3.4399 | Train Acc: 0.0330\n",
      "Test Loss: 3.4403 | Test Acc: 0.0319\n",
      "Epoch 2 took 0.03 seconds\n",
      "Epoch [3/100] | Train Loss: 3.4329 | Train Acc: 0.0378\n",
      "Test Loss: 3.4342 | Test Acc: 0.0378\n",
      "Epoch 3 took 0.01 seconds\n",
      "Epoch [4/100] | Train Loss: 3.4268 | Train Acc: 0.0436\n",
      "Test Loss: 3.4263 | Test Acc: 0.0437\n",
      "Epoch 4 took 0.02 seconds\n",
      "Epoch [5/100] | Train Loss: 3.4185 | Train Acc: 0.0500\n",
      "Test Loss: 3.4240 | Test Acc: 0.0511\n",
      "Epoch 5 took 0.01 seconds\n",
      "Epoch [6/100] | Train Loss: 3.4133 | Train Acc: 0.0585\n",
      "Test Loss: 3.4178 | Test Acc: 0.0623\n",
      "Epoch 6 took 0.01 seconds\n",
      "Epoch [7/100] | Train Loss: 3.4053 | Train Acc: 0.0644\n",
      "Test Loss: 3.4111 | Test Acc: 0.0660\n",
      "Epoch 7 took 0.01 seconds\n",
      "Epoch [8/100] | Train Loss: 3.3990 | Train Acc: 0.0756\n",
      "Test Loss: 3.4068 | Test Acc: 0.0740\n",
      "Epoch 8 took 0.01 seconds\n",
      "Epoch [9/100] | Train Loss: 3.3926 | Train Acc: 0.0814\n",
      "Test Loss: 3.4004 | Test Acc: 0.0804\n",
      "Epoch 9 took 0.01 seconds\n",
      "Epoch [10/100] | Train Loss: 3.3862 | Train Acc: 0.0873\n",
      "Test Loss: 3.3960 | Test Acc: 0.0841\n",
      "Epoch 10 took 0.01 seconds\n",
      "Epoch [11/100] | Train Loss: 3.3781 | Train Acc: 0.0963\n",
      "Test Loss: 3.3920 | Test Acc: 0.0895\n",
      "Epoch 11 took 0.01 seconds\n",
      "Epoch [12/100] | Train Loss: 3.3729 | Train Acc: 0.1016\n",
      "Test Loss: 3.3877 | Test Acc: 0.0911\n",
      "Epoch 12 took 0.01 seconds\n",
      "Epoch [13/100] | Train Loss: 3.3687 | Train Acc: 0.1102\n",
      "Test Loss: 3.3792 | Test Acc: 0.1012\n",
      "Epoch 13 took 0.01 seconds\n",
      "Epoch [14/100] | Train Loss: 3.3640 | Train Acc: 0.1150\n",
      "Test Loss: 3.3768 | Test Acc: 0.1028\n",
      "Epoch 14 took 0.01 seconds\n",
      "Epoch [15/100] | Train Loss: 3.3557 | Train Acc: 0.1283\n",
      "Test Loss: 3.3714 | Test Acc: 0.1065\n",
      "Epoch 15 took 0.01 seconds\n",
      "Epoch [16/100] | Train Loss: 3.3478 | Train Acc: 0.1362\n",
      "Test Loss: 3.3671 | Test Acc: 0.1118\n",
      "Epoch 16 took 0.01 seconds\n",
      "Epoch [17/100] | Train Loss: 3.3416 | Train Acc: 0.1389\n",
      "Test Loss: 3.3624 | Test Acc: 0.1129\n",
      "Epoch 17 took 0.01 seconds\n",
      "Epoch [18/100] | Train Loss: 3.3399 | Train Acc: 0.1426\n",
      "Test Loss: 3.3588 | Test Acc: 0.1145\n",
      "Epoch 18 took 0.01 seconds\n",
      "Epoch [19/100] | Train Loss: 3.3295 | Train Acc: 0.1490\n",
      "Test Loss: 3.3556 | Test Acc: 0.1161\n",
      "Epoch 19 took 0.01 seconds\n",
      "Epoch [20/100] | Train Loss: 3.3267 | Train Acc: 0.1490\n",
      "Test Loss: 3.3479 | Test Acc: 0.1177\n",
      "Epoch 20 took 0.01 seconds\n",
      "Epoch [21/100] | Train Loss: 3.3189 | Train Acc: 0.1565\n",
      "Test Loss: 3.3471 | Test Acc: 0.1198\n",
      "Epoch 21 took 0.01 seconds\n",
      "Epoch [22/100] | Train Loss: 3.3136 | Train Acc: 0.1570\n",
      "Test Loss: 3.3428 | Test Acc: 0.1209\n",
      "Epoch 22 took 0.01 seconds\n",
      "Epoch [23/100] | Train Loss: 3.3099 | Train Acc: 0.1549\n",
      "Test Loss: 3.3395 | Test Acc: 0.1219\n",
      "Epoch 23 took 0.01 seconds\n",
      "Epoch [24/100] | Train Loss: 3.3047 | Train Acc: 0.1549\n",
      "Test Loss: 3.3327 | Test Acc: 0.1230\n",
      "Epoch 24 took 0.01 seconds\n",
      "Epoch [25/100] | Train Loss: 3.3019 | Train Acc: 0.1570\n",
      "Test Loss: 3.3311 | Test Acc: 0.1273\n",
      "Epoch 25 took 0.01 seconds\n",
      "Epoch [26/100] | Train Loss: 3.2951 | Train Acc: 0.1607\n",
      "Test Loss: 3.3247 | Test Acc: 0.1294\n",
      "Epoch 26 took 0.01 seconds\n",
      "Epoch [27/100] | Train Loss: 3.2888 | Train Acc: 0.1650\n",
      "Test Loss: 3.3193 | Test Acc: 0.1283\n",
      "Epoch 27 took 0.01 seconds\n",
      "Epoch [28/100] | Train Loss: 3.2837 | Train Acc: 0.1671\n",
      "Test Loss: 3.3187 | Test Acc: 0.1299\n",
      "Epoch 28 took 0.01 seconds\n",
      "Epoch [29/100] | Train Loss: 3.2753 | Train Acc: 0.1671\n",
      "Test Loss: 3.3129 | Test Acc: 0.1299\n",
      "Epoch 29 took 0.01 seconds\n",
      "Epoch [30/100] | Train Loss: 3.2745 | Train Acc: 0.1650\n",
      "Test Loss: 3.3066 | Test Acc: 0.1305\n",
      "Epoch 30 took 0.01 seconds\n",
      "Epoch [31/100] | Train Loss: 3.2718 | Train Acc: 0.1666\n",
      "Test Loss: 3.3084 | Test Acc: 0.1305\n",
      "Epoch 31 took 0.01 seconds\n",
      "Epoch [32/100] | Train Loss: 3.2619 | Train Acc: 0.1698\n",
      "Test Loss: 3.2989 | Test Acc: 0.1315\n",
      "Epoch 32 took 0.01 seconds\n",
      "Epoch [33/100] | Train Loss: 3.2579 | Train Acc: 0.1692\n",
      "Test Loss: 3.2996 | Test Acc: 0.1331\n",
      "Epoch 33 took 0.01 seconds\n",
      "Epoch [34/100] | Train Loss: 3.2582 | Train Acc: 0.1676\n",
      "Test Loss: 3.2944 | Test Acc: 0.1337\n",
      "Epoch 34 took 0.01 seconds\n",
      "Epoch [35/100] | Train Loss: 3.2509 | Train Acc: 0.1719\n",
      "Test Loss: 3.2941 | Test Acc: 0.1342\n",
      "Epoch 35 took 0.01 seconds\n",
      "Epoch [36/100] | Train Loss: 3.2420 | Train Acc: 0.1730\n",
      "Test Loss: 3.2854 | Test Acc: 0.1353\n",
      "Epoch 36 took 0.01 seconds\n",
      "Epoch [37/100] | Train Loss: 3.2384 | Train Acc: 0.1762\n",
      "Test Loss: 3.2837 | Test Acc: 0.1363\n",
      "Epoch 37 took 0.01 seconds\n",
      "Epoch [38/100] | Train Loss: 3.2347 | Train Acc: 0.1772\n",
      "Test Loss: 3.2857 | Test Acc: 0.1379\n",
      "Epoch 38 took 0.01 seconds\n",
      "Epoch [39/100] | Train Loss: 3.2302 | Train Acc: 0.1847\n",
      "Test Loss: 3.2783 | Test Acc: 0.1390\n",
      "Epoch 39 took 0.01 seconds\n",
      "Epoch [40/100] | Train Loss: 3.2250 | Train Acc: 0.1836\n",
      "Test Loss: 3.2736 | Test Acc: 0.1416\n",
      "Epoch 40 took 0.01 seconds\n",
      "Epoch [41/100] | Train Loss: 3.2243 | Train Acc: 0.1863\n",
      "Test Loss: 3.2694 | Test Acc: 0.1427\n",
      "Epoch 41 took 0.01 seconds\n",
      "Epoch [42/100] | Train Loss: 3.2154 | Train Acc: 0.1868\n",
      "Test Loss: 3.2651 | Test Acc: 0.1427\n",
      "Epoch 42 took 0.01 seconds\n",
      "Epoch [43/100] | Train Loss: 3.2161 | Train Acc: 0.1884\n",
      "Test Loss: 3.2615 | Test Acc: 0.1443\n",
      "Epoch 43 took 0.01 seconds\n",
      "Epoch [44/100] | Train Loss: 3.2081 | Train Acc: 0.1900\n",
      "Test Loss: 3.2556 | Test Acc: 0.1448\n",
      "Epoch 44 took 0.01 seconds\n",
      "Epoch [45/100] | Train Loss: 3.2082 | Train Acc: 0.1884\n",
      "Test Loss: 3.2550 | Test Acc: 0.1475\n",
      "Epoch 45 took 0.01 seconds\n",
      "Epoch [46/100] | Train Loss: 3.1979 | Train Acc: 0.1921\n",
      "Test Loss: 3.2521 | Test Acc: 0.1480\n",
      "Epoch 46 took 0.01 seconds\n",
      "Epoch [47/100] | Train Loss: 3.1951 | Train Acc: 0.1943\n",
      "Test Loss: 3.2496 | Test Acc: 0.1496\n",
      "Epoch 47 took 0.01 seconds\n",
      "Epoch [48/100] | Train Loss: 3.1957 | Train Acc: 0.1964\n",
      "Test Loss: 3.2458 | Test Acc: 0.1512\n",
      "Epoch 48 took 0.01 seconds\n",
      "Epoch [49/100] | Train Loss: 3.1805 | Train Acc: 0.2006\n",
      "Test Loss: 3.2406 | Test Acc: 0.1518\n",
      "Epoch 49 took 0.01 seconds\n",
      "Epoch [50/100] | Train Loss: 3.1826 | Train Acc: 0.1985\n",
      "Test Loss: 3.2431 | Test Acc: 0.1523\n",
      "Epoch 50 took 0.01 seconds\n",
      "Epoch [51/100] | Train Loss: 3.1789 | Train Acc: 0.2028\n",
      "Test Loss: 3.2350 | Test Acc: 0.1534\n",
      "Epoch 51 took 0.01 seconds\n",
      "Epoch [52/100] | Train Loss: 3.1737 | Train Acc: 0.2044\n",
      "Test Loss: 3.2335 | Test Acc: 0.1555\n",
      "Epoch 52 took 0.01 seconds\n",
      "Epoch [53/100] | Train Loss: 3.1741 | Train Acc: 0.2070\n",
      "Test Loss: 3.2331 | Test Acc: 0.1576\n",
      "Epoch 53 took 0.01 seconds\n",
      "Epoch [54/100] | Train Loss: 3.1719 | Train Acc: 0.2129\n",
      "Test Loss: 3.2262 | Test Acc: 0.1587\n",
      "Epoch 54 took 0.01 seconds\n",
      "Epoch [55/100] | Train Loss: 3.1628 | Train Acc: 0.2118\n",
      "Test Loss: 3.2243 | Test Acc: 0.1608\n",
      "Epoch 55 took 0.01 seconds\n",
      "Epoch [56/100] | Train Loss: 3.1573 | Train Acc: 0.2161\n",
      "Test Loss: 3.2200 | Test Acc: 0.1613\n",
      "Epoch 56 took 0.01 seconds\n",
      "Epoch [57/100] | Train Loss: 3.1570 | Train Acc: 0.2145\n",
      "Test Loss: 3.2191 | Test Acc: 0.1613\n",
      "Epoch 57 took 0.01 seconds\n",
      "Epoch [58/100] | Train Loss: 3.1493 | Train Acc: 0.2193\n",
      "Test Loss: 3.2182 | Test Acc: 0.1629\n",
      "Epoch 58 took 0.01 seconds\n",
      "Epoch [59/100] | Train Loss: 3.1482 | Train Acc: 0.2193\n",
      "Test Loss: 3.2107 | Test Acc: 0.1651\n",
      "Epoch 59 took 0.21 seconds\n",
      "Epoch [60/100] | Train Loss: 3.1410 | Train Acc: 0.2225\n",
      "Test Loss: 3.2133 | Test Acc: 0.1656\n",
      "Epoch 60 took 0.01 seconds\n",
      "Epoch [61/100] | Train Loss: 3.1422 | Train Acc: 0.2235\n",
      "Test Loss: 3.2086 | Test Acc: 0.1661\n",
      "Epoch 61 took 0.01 seconds\n",
      "Epoch [62/100] | Train Loss: 3.1361 | Train Acc: 0.2251\n",
      "Test Loss: 3.1991 | Test Acc: 0.1672\n",
      "Epoch 62 took 0.01 seconds\n",
      "Epoch [63/100] | Train Loss: 3.1326 | Train Acc: 0.2283\n",
      "Test Loss: 3.2060 | Test Acc: 0.1677\n",
      "Epoch 63 took 0.01 seconds\n",
      "Epoch [64/100] | Train Loss: 3.1264 | Train Acc: 0.2288\n",
      "Test Loss: 3.1969 | Test Acc: 0.1693\n",
      "Epoch 64 took 0.01 seconds\n",
      "Epoch [65/100] | Train Loss: 3.1228 | Train Acc: 0.2315\n",
      "Test Loss: 3.1951 | Test Acc: 0.1704\n",
      "Epoch 65 took 0.01 seconds\n",
      "Epoch [66/100] | Train Loss: 3.1264 | Train Acc: 0.2320\n",
      "Test Loss: 3.1889 | Test Acc: 0.1731\n",
      "Epoch 66 took 0.01 seconds\n",
      "Epoch [67/100] | Train Loss: 3.1225 | Train Acc: 0.2347\n",
      "Test Loss: 3.1910 | Test Acc: 0.1731\n",
      "Epoch 67 took 0.01 seconds\n",
      "Epoch [68/100] | Train Loss: 3.1187 | Train Acc: 0.2358\n",
      "Test Loss: 3.1906 | Test Acc: 0.1741\n",
      "Epoch 68 took 0.01 seconds\n",
      "Epoch [69/100] | Train Loss: 3.1135 | Train Acc: 0.2390\n",
      "Test Loss: 3.1853 | Test Acc: 0.1757\n",
      "Epoch 69 took 0.01 seconds\n",
      "Epoch [70/100] | Train Loss: 3.1065 | Train Acc: 0.2406\n",
      "Test Loss: 3.1829 | Test Acc: 0.1773\n",
      "Epoch 70 took 0.01 seconds\n",
      "Epoch [71/100] | Train Loss: 3.1032 | Train Acc: 0.2411\n",
      "Test Loss: 3.1805 | Test Acc: 0.1789\n",
      "Epoch 71 took 0.01 seconds\n",
      "Epoch [72/100] | Train Loss: 3.1072 | Train Acc: 0.2411\n",
      "Test Loss: 3.1755 | Test Acc: 0.1805\n",
      "Epoch 72 took 0.01 seconds\n",
      "Epoch [73/100] | Train Loss: 3.1002 | Train Acc: 0.2432\n",
      "Test Loss: 3.1696 | Test Acc: 0.1805\n",
      "Epoch 73 took 0.01 seconds\n",
      "Epoch [74/100] | Train Loss: 3.0961 | Train Acc: 0.2459\n",
      "Test Loss: 3.1722 | Test Acc: 0.1816\n",
      "Epoch 74 took 0.01 seconds\n",
      "Epoch [75/100] | Train Loss: 3.0913 | Train Acc: 0.2469\n",
      "Test Loss: 3.1663 | Test Acc: 0.1821\n",
      "Epoch 75 took 0.01 seconds\n",
      "Epoch [76/100] | Train Loss: 3.0881 | Train Acc: 0.2475\n",
      "Test Loss: 3.1665 | Test Acc: 0.1837\n",
      "Epoch 76 took 0.01 seconds\n",
      "Epoch [77/100] | Train Loss: 3.0904 | Train Acc: 0.2501\n",
      "Test Loss: 3.1648 | Test Acc: 0.1853\n",
      "Epoch 77 took 0.01 seconds\n",
      "Epoch [78/100] | Train Loss: 3.0826 | Train Acc: 0.2517\n",
      "Test Loss: 3.1576 | Test Acc: 0.1858\n",
      "Epoch 78 took 0.01 seconds\n",
      "Epoch [79/100] | Train Loss: 3.0823 | Train Acc: 0.2533\n",
      "Test Loss: 3.1604 | Test Acc: 0.1896\n",
      "Epoch 79 took 0.01 seconds\n",
      "Epoch [80/100] | Train Loss: 3.0831 | Train Acc: 0.2555\n",
      "Test Loss: 3.1556 | Test Acc: 0.1912\n",
      "Epoch 80 took 0.01 seconds\n",
      "Epoch [81/100] | Train Loss: 3.0732 | Train Acc: 0.2555\n",
      "Test Loss: 3.1601 | Test Acc: 0.1928\n",
      "Epoch 81 took 0.01 seconds\n",
      "Epoch [82/100] | Train Loss: 3.0788 | Train Acc: 0.2549\n",
      "Test Loss: 3.1456 | Test Acc: 0.1938\n",
      "Epoch 82 took 0.01 seconds\n",
      "Epoch [83/100] | Train Loss: 3.0727 | Train Acc: 0.2571\n",
      "Test Loss: 3.1523 | Test Acc: 0.1944\n",
      "Epoch 83 took 0.01 seconds\n",
      "Epoch [84/100] | Train Loss: 3.0672 | Train Acc: 0.2571\n",
      "Test Loss: 3.1492 | Test Acc: 0.1944\n",
      "Epoch 84 took 0.01 seconds\n",
      "Epoch [85/100] | Train Loss: 3.0702 | Train Acc: 0.2565\n",
      "Test Loss: 3.1425 | Test Acc: 0.1954\n",
      "Epoch 85 took 0.01 seconds\n",
      "Epoch [86/100] | Train Loss: 3.0673 | Train Acc: 0.2576\n",
      "Test Loss: 3.1475 | Test Acc: 0.1960\n",
      "Epoch 86 took 0.01 seconds\n",
      "Epoch [87/100] | Train Loss: 3.0669 | Train Acc: 0.2597\n",
      "Test Loss: 3.1442 | Test Acc: 0.1965\n",
      "Epoch 87 took 0.01 seconds\n",
      "Epoch [88/100] | Train Loss: 3.0588 | Train Acc: 0.2624\n",
      "Test Loss: 3.1394 | Test Acc: 0.1970\n",
      "Epoch 88 took 0.01 seconds\n",
      "Epoch [89/100] | Train Loss: 3.0617 | Train Acc: 0.2634\n",
      "Test Loss: 3.1376 | Test Acc: 0.1970\n",
      "Epoch 89 took 0.01 seconds\n",
      "Epoch [90/100] | Train Loss: 3.0502 | Train Acc: 0.2645\n",
      "Test Loss: 3.1428 | Test Acc: 0.1976\n",
      "Epoch 90 took 0.01 seconds\n",
      "Epoch [91/100] | Train Loss: 3.0581 | Train Acc: 0.2640\n",
      "Test Loss: 3.1323 | Test Acc: 0.1981\n",
      "Epoch 91 took 0.01 seconds\n",
      "Epoch [92/100] | Train Loss: 3.0526 | Train Acc: 0.2672\n",
      "Test Loss: 3.1347 | Test Acc: 0.1981\n",
      "Epoch 92 took 0.01 seconds\n",
      "Epoch [93/100] | Train Loss: 3.0509 | Train Acc: 0.2693\n",
      "Test Loss: 3.1328 | Test Acc: 0.1986\n",
      "Epoch 93 took 0.01 seconds\n",
      "Epoch [94/100] | Train Loss: 3.0497 | Train Acc: 0.2698\n",
      "Test Loss: 3.1307 | Test Acc: 0.1986\n",
      "Epoch 94 took 0.01 seconds\n",
      "Epoch [95/100] | Train Loss: 3.0489 | Train Acc: 0.2709\n",
      "Test Loss: 3.1309 | Test Acc: 0.2002\n",
      "Epoch 95 took 0.01 seconds\n",
      "Epoch [96/100] | Train Loss: 3.0409 | Train Acc: 0.2720\n",
      "Test Loss: 3.1249 | Test Acc: 0.2002\n",
      "Epoch 96 took 0.01 seconds\n",
      "Epoch [97/100] | Train Loss: 3.0386 | Train Acc: 0.2730\n",
      "Test Loss: 3.1309 | Test Acc: 0.2007\n",
      "Epoch 97 took 0.01 seconds\n",
      "Epoch [98/100] | Train Loss: 3.0498 | Train Acc: 0.2741\n",
      "Test Loss: 3.1268 | Test Acc: 0.2023\n",
      "Epoch 98 took 0.02 seconds\n",
      "Epoch [99/100] | Train Loss: 3.0432 | Train Acc: 0.2741\n",
      "Test Loss: 3.1266 | Test Acc: 0.2029\n",
      "Epoch 99 took 0.02 seconds\n",
      "Epoch [100/100] | Train Loss: 3.0386 | Train Acc: 0.2751\n",
      "Test Loss: 3.1224 | Test Acc: 0.2029\n",
      "Epoch 100 took 0.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:11:10,226 INFO     Train accuracy 0.27408195848855776, Train Loss 3.0407394468784332\n",
      "2025-11-28 11:11:10,226 INFO     Train accuracy 0.27408195848855776, Train Loss 3.0407394468784332\n",
      "2025-11-28 11:11:10,227 INFO     Test accuracy 0.20287539936102236, Test Loss 3.1274079382419586\n",
      "2025-11-28 11:11:10,227 INFO     Test accuracy 0.20287539936102236, Test Loss 3.1274079382419586\n",
      "2025-11-28 11:11:10,228 INFO     Training model 1 took 57.672659397125244 seconds\n",
      "2025-11-28 11:11:10,228 INFO     Training model 1 took 57.672659397125244 seconds\n",
      "2025-11-28 11:11:10,233 INFO     --------------------------------------------------\n",
      "2025-11-28 11:11:10,233 INFO     --------------------------------------------------\n",
      "2025-11-28 11:11:10,234 INFO     Training model 2: Train size 1878, Test size 1879\n",
      "2025-11-28 11:11:10,234 INFO     Training model 2: Train size 1878, Test size 1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 3.4382 | Train Acc: 0.0474\n",
      "Test Loss: 3.4358 | Test Acc: 0.0463\n",
      "Epoch 1 took 16.50 seconds\n",
      "Epoch [2/100] | Train Loss: 3.4335 | Train Acc: 0.0501\n",
      "Test Loss: 3.4298 | Test Acc: 0.0495\n",
      "Epoch 2 took 0.03 seconds\n",
      "Epoch [3/100] | Train Loss: 3.4257 | Train Acc: 0.0559\n",
      "Test Loss: 3.4228 | Test Acc: 0.0532\n",
      "Epoch 3 took 0.02 seconds\n",
      "Epoch [4/100] | Train Loss: 3.4212 | Train Acc: 0.0602\n",
      "Test Loss: 3.4203 | Test Acc: 0.0559\n",
      "Epoch 4 took 0.02 seconds\n",
      "Epoch [5/100] | Train Loss: 3.4130 | Train Acc: 0.0628\n",
      "Test Loss: 3.4137 | Test Acc: 0.0601\n",
      "Epoch 5 took 0.01 seconds\n",
      "Epoch [6/100] | Train Loss: 3.4082 | Train Acc: 0.0687\n",
      "Test Loss: 3.4091 | Test Acc: 0.0660\n",
      "Epoch 6 took 0.01 seconds\n",
      "Epoch [7/100] | Train Loss: 3.4021 | Train Acc: 0.0745\n",
      "Test Loss: 3.4019 | Test Acc: 0.0697\n",
      "Epoch 7 took 0.01 seconds\n",
      "Epoch [8/100] | Train Loss: 3.3940 | Train Acc: 0.0761\n",
      "Test Loss: 3.3955 | Test Acc: 0.0734\n",
      "Epoch 8 took 0.01 seconds\n",
      "Epoch [9/100] | Train Loss: 3.3874 | Train Acc: 0.0793\n",
      "Test Loss: 3.3921 | Test Acc: 0.0756\n",
      "Epoch 9 took 0.01 seconds\n",
      "Epoch [10/100] | Train Loss: 3.3833 | Train Acc: 0.0825\n",
      "Test Loss: 3.3870 | Test Acc: 0.0883\n",
      "Epoch 10 took 0.01 seconds\n",
      "Epoch [11/100] | Train Loss: 3.3786 | Train Acc: 0.0884\n",
      "Test Loss: 3.3831 | Test Acc: 0.0942\n",
      "Epoch 11 took 0.01 seconds\n",
      "Epoch [12/100] | Train Loss: 3.3748 | Train Acc: 0.0948\n",
      "Test Loss: 3.3766 | Test Acc: 0.0995\n",
      "Epoch 12 took 0.01 seconds\n",
      "Epoch [13/100] | Train Loss: 3.3670 | Train Acc: 0.0969\n",
      "Test Loss: 3.3748 | Test Acc: 0.1027\n",
      "Epoch 13 took 0.01 seconds\n",
      "Epoch [14/100] | Train Loss: 3.3637 | Train Acc: 0.1006\n",
      "Test Loss: 3.3687 | Test Acc: 0.1059\n",
      "Epoch 14 took 0.01 seconds\n",
      "Epoch [15/100] | Train Loss: 3.3563 | Train Acc: 0.1065\n",
      "Test Loss: 3.3631 | Test Acc: 0.1102\n",
      "Epoch 15 took 0.01 seconds\n",
      "Epoch [16/100] | Train Loss: 3.3501 | Train Acc: 0.1113\n",
      "Test Loss: 3.3573 | Test Acc: 0.1134\n",
      "Epoch 16 took 0.01 seconds\n",
      "Epoch [17/100] | Train Loss: 3.3434 | Train Acc: 0.1102\n",
      "Test Loss: 3.3531 | Test Acc: 0.1123\n",
      "Epoch 17 took 0.01 seconds\n",
      "Epoch [18/100] | Train Loss: 3.3371 | Train Acc: 0.1102\n",
      "Test Loss: 3.3485 | Test Acc: 0.1144\n",
      "Epoch 18 took 0.01 seconds\n",
      "Epoch [19/100] | Train Loss: 3.3342 | Train Acc: 0.1171\n",
      "Test Loss: 3.3442 | Test Acc: 0.1203\n",
      "Epoch 19 took 0.01 seconds\n",
      "Epoch [20/100] | Train Loss: 3.3311 | Train Acc: 0.1203\n",
      "Test Loss: 3.3443 | Test Acc: 0.1203\n",
      "Epoch 20 took 0.01 seconds\n",
      "Epoch [21/100] | Train Loss: 3.3267 | Train Acc: 0.1225\n",
      "Test Loss: 3.3382 | Test Acc: 0.1240\n",
      "Epoch 21 took 0.01 seconds\n",
      "Epoch [22/100] | Train Loss: 3.3199 | Train Acc: 0.1230\n",
      "Test Loss: 3.3326 | Test Acc: 0.1251\n",
      "Epoch 22 took 0.01 seconds\n",
      "Epoch [23/100] | Train Loss: 3.3154 | Train Acc: 0.1251\n",
      "Test Loss: 3.3270 | Test Acc: 0.1277\n",
      "Epoch 23 took 0.01 seconds\n",
      "Epoch [24/100] | Train Loss: 3.3116 | Train Acc: 0.1267\n",
      "Test Loss: 3.3243 | Test Acc: 0.1251\n",
      "Epoch 24 took 0.01 seconds\n",
      "Epoch [25/100] | Train Loss: 3.3041 | Train Acc: 0.1246\n",
      "Test Loss: 3.3189 | Test Acc: 0.1267\n",
      "Epoch 25 took 0.01 seconds\n",
      "Epoch [26/100] | Train Loss: 3.3006 | Train Acc: 0.1257\n",
      "Test Loss: 3.3204 | Test Acc: 0.1261\n",
      "Epoch 26 took 0.01 seconds\n",
      "Epoch [27/100] | Train Loss: 3.2940 | Train Acc: 0.1283\n",
      "Test Loss: 3.3115 | Test Acc: 0.1267\n",
      "Epoch 27 took 0.01 seconds\n",
      "Epoch [28/100] | Train Loss: 3.2889 | Train Acc: 0.1294\n",
      "Test Loss: 3.3065 | Test Acc: 0.1261\n",
      "Epoch 28 took 0.01 seconds\n",
      "Epoch [29/100] | Train Loss: 3.2842 | Train Acc: 0.1310\n",
      "Test Loss: 3.3014 | Test Acc: 0.1267\n",
      "Epoch 29 took 0.01 seconds\n",
      "Epoch [30/100] | Train Loss: 3.2820 | Train Acc: 0.1299\n",
      "Test Loss: 3.3007 | Test Acc: 0.1277\n",
      "Epoch 30 took 0.01 seconds\n",
      "Epoch [31/100] | Train Loss: 3.2782 | Train Acc: 0.1321\n",
      "Test Loss: 3.2972 | Test Acc: 0.1267\n",
      "Epoch 31 took 0.01 seconds\n",
      "Epoch [32/100] | Train Loss: 3.2730 | Train Acc: 0.1326\n",
      "Test Loss: 3.2944 | Test Acc: 0.1267\n",
      "Epoch 32 took 0.01 seconds\n",
      "Epoch [33/100] | Train Loss: 3.2693 | Train Acc: 0.1326\n",
      "Test Loss: 3.2885 | Test Acc: 0.1267\n",
      "Epoch 33 took 0.01 seconds\n",
      "Epoch [34/100] | Train Loss: 3.2606 | Train Acc: 0.1337\n",
      "Test Loss: 3.2855 | Test Acc: 0.1277\n",
      "Epoch 34 took 0.01 seconds\n",
      "Epoch [35/100] | Train Loss: 3.2635 | Train Acc: 0.1337\n",
      "Test Loss: 3.2836 | Test Acc: 0.1288\n",
      "Epoch 35 took 0.01 seconds\n",
      "Epoch [36/100] | Train Loss: 3.2549 | Train Acc: 0.1337\n",
      "Test Loss: 3.2758 | Test Acc: 0.1293\n",
      "Epoch 36 took 0.02 seconds\n",
      "Epoch [37/100] | Train Loss: 3.2477 | Train Acc: 0.1342\n",
      "Test Loss: 3.2742 | Test Acc: 0.1299\n",
      "Epoch 37 took 0.02 seconds\n",
      "Epoch [38/100] | Train Loss: 3.2496 | Train Acc: 0.1347\n",
      "Test Loss: 3.2716 | Test Acc: 0.1309\n",
      "Epoch 38 took 0.02 seconds\n",
      "Epoch [39/100] | Train Loss: 3.2437 | Train Acc: 0.1368\n",
      "Test Loss: 3.2657 | Test Acc: 0.1315\n",
      "Epoch 39 took 0.02 seconds\n",
      "Epoch [40/100] | Train Loss: 3.2383 | Train Acc: 0.1358\n",
      "Test Loss: 3.2604 | Test Acc: 0.1320\n",
      "Epoch 40 took 0.02 seconds\n",
      "Epoch [41/100] | Train Loss: 3.2358 | Train Acc: 0.1363\n",
      "Test Loss: 3.2601 | Test Acc: 0.1325\n",
      "Epoch 41 took 0.01 seconds\n",
      "Epoch [42/100] | Train Loss: 3.2299 | Train Acc: 0.1358\n",
      "Test Loss: 3.2560 | Test Acc: 0.1336\n",
      "Epoch 42 took 0.01 seconds\n",
      "Epoch [43/100] | Train Loss: 3.2260 | Train Acc: 0.1390\n",
      "Test Loss: 3.2527 | Test Acc: 0.1336\n",
      "Epoch 43 took 0.01 seconds\n",
      "Epoch [44/100] | Train Loss: 3.2210 | Train Acc: 0.1395\n",
      "Test Loss: 3.2494 | Test Acc: 0.1362\n",
      "Epoch 44 took 0.01 seconds\n",
      "Epoch [45/100] | Train Loss: 3.2163 | Train Acc: 0.1411\n",
      "Test Loss: 3.2523 | Test Acc: 0.1378\n",
      "Epoch 45 took 0.01 seconds\n",
      "Epoch [46/100] | Train Loss: 3.2169 | Train Acc: 0.1411\n",
      "Test Loss: 3.2463 | Test Acc: 0.1384\n",
      "Epoch 46 took 0.01 seconds\n",
      "Epoch [47/100] | Train Loss: 3.2104 | Train Acc: 0.1416\n",
      "Test Loss: 3.2387 | Test Acc: 0.1389\n",
      "Epoch 47 took 0.01 seconds\n",
      "Epoch [48/100] | Train Loss: 3.2087 | Train Acc: 0.1427\n",
      "Test Loss: 3.2325 | Test Acc: 0.1410\n",
      "Epoch 48 took 0.01 seconds\n",
      "Epoch [49/100] | Train Loss: 3.2039 | Train Acc: 0.1427\n",
      "Test Loss: 3.2331 | Test Acc: 0.1421\n",
      "Epoch 49 took 0.02 seconds\n",
      "Epoch [50/100] | Train Loss: 3.2015 | Train Acc: 0.1448\n",
      "Test Loss: 3.2302 | Test Acc: 0.1432\n",
      "Epoch 50 took 0.02 seconds\n",
      "Epoch [51/100] | Train Loss: 3.1926 | Train Acc: 0.1507\n",
      "Test Loss: 3.2224 | Test Acc: 0.1458\n",
      "Epoch 51 took 0.02 seconds\n",
      "Epoch [52/100] | Train Loss: 3.1906 | Train Acc: 0.1528\n",
      "Test Loss: 3.2221 | Test Acc: 0.1490\n",
      "Epoch 52 took 0.04 seconds\n",
      "Epoch [53/100] | Train Loss: 3.1809 | Train Acc: 0.1539\n",
      "Test Loss: 3.2227 | Test Acc: 0.1501\n",
      "Epoch 53 took 0.04 seconds\n",
      "Epoch [54/100] | Train Loss: 3.1805 | Train Acc: 0.1560\n",
      "Test Loss: 3.2152 | Test Acc: 0.1501\n",
      "Epoch 54 took 0.05 seconds\n",
      "Epoch [55/100] | Train Loss: 3.1788 | Train Acc: 0.1571\n",
      "Test Loss: 3.2198 | Test Acc: 0.1522\n",
      "Epoch 55 took 0.04 seconds\n",
      "Epoch [56/100] | Train Loss: 3.1752 | Train Acc: 0.1587\n",
      "Test Loss: 3.2141 | Test Acc: 0.1533\n",
      "Epoch 56 took 0.04 seconds\n",
      "Epoch [57/100] | Train Loss: 3.1768 | Train Acc: 0.1624\n",
      "Test Loss: 3.2070 | Test Acc: 0.1533\n",
      "Epoch 57 took 0.02 seconds\n",
      "Epoch [58/100] | Train Loss: 3.1717 | Train Acc: 0.1619\n",
      "Test Loss: 3.2039 | Test Acc: 0.1543\n",
      "Epoch 58 took 0.02 seconds\n",
      "Epoch [59/100] | Train Loss: 3.1588 | Train Acc: 0.1619\n",
      "Test Loss: 3.2011 | Test Acc: 0.1565\n",
      "Epoch 59 took 0.22 seconds\n",
      "Epoch [60/100] | Train Loss: 3.1644 | Train Acc: 0.1667\n",
      "Test Loss: 3.1972 | Test Acc: 0.1575\n",
      "Epoch 60 took 0.01 seconds\n",
      "Epoch [61/100] | Train Loss: 3.1586 | Train Acc: 0.1677\n",
      "Test Loss: 3.1920 | Test Acc: 0.1591\n",
      "Epoch 61 took 0.01 seconds\n",
      "Epoch [62/100] | Train Loss: 3.1561 | Train Acc: 0.1704\n",
      "Test Loss: 3.1907 | Test Acc: 0.1602\n",
      "Epoch 62 took 0.01 seconds\n",
      "Epoch [63/100] | Train Loss: 3.1524 | Train Acc: 0.1731\n",
      "Test Loss: 3.1929 | Test Acc: 0.1613\n",
      "Epoch 63 took 0.01 seconds\n",
      "Epoch [64/100] | Train Loss: 3.1479 | Train Acc: 0.1752\n",
      "Test Loss: 3.1867 | Test Acc: 0.1629\n",
      "Epoch 64 took 0.01 seconds\n",
      "Epoch [65/100] | Train Loss: 3.1487 | Train Acc: 0.1778\n",
      "Test Loss: 3.1863 | Test Acc: 0.1634\n",
      "Epoch 65 took 0.01 seconds\n",
      "Epoch [66/100] | Train Loss: 3.1438 | Train Acc: 0.1763\n",
      "Test Loss: 3.1783 | Test Acc: 0.1644\n",
      "Epoch 66 took 0.01 seconds\n",
      "Epoch [67/100] | Train Loss: 3.1372 | Train Acc: 0.1784\n",
      "Test Loss: 3.1824 | Test Acc: 0.1650\n",
      "Epoch 67 took 0.01 seconds\n",
      "Epoch [68/100] | Train Loss: 3.1338 | Train Acc: 0.1821\n",
      "Test Loss: 3.1775 | Test Acc: 0.1682\n",
      "Epoch 68 took 0.01 seconds\n",
      "Epoch [69/100] | Train Loss: 3.1387 | Train Acc: 0.1832\n",
      "Test Loss: 3.1734 | Test Acc: 0.1682\n",
      "Epoch 69 took 0.01 seconds\n",
      "Epoch [70/100] | Train Loss: 3.1314 | Train Acc: 0.1858\n",
      "Test Loss: 3.1761 | Test Acc: 0.1703\n",
      "Epoch 70 took 0.01 seconds\n",
      "Epoch [71/100] | Train Loss: 3.1280 | Train Acc: 0.1885\n",
      "Test Loss: 3.1714 | Test Acc: 0.1708\n",
      "Epoch 71 took 0.01 seconds\n",
      "Epoch [72/100] | Train Loss: 3.1223 | Train Acc: 0.1901\n",
      "Test Loss: 3.1692 | Test Acc: 0.1714\n",
      "Epoch 72 took 0.01 seconds\n",
      "Epoch [73/100] | Train Loss: 3.1182 | Train Acc: 0.1896\n",
      "Test Loss: 3.1688 | Test Acc: 0.1730\n",
      "Epoch 73 took 0.01 seconds\n",
      "Epoch [74/100] | Train Loss: 3.1143 | Train Acc: 0.1938\n",
      "Test Loss: 3.1643 | Test Acc: 0.1735\n",
      "Epoch 74 took 0.01 seconds\n",
      "Epoch [75/100] | Train Loss: 3.1146 | Train Acc: 0.1938\n",
      "Test Loss: 3.1603 | Test Acc: 0.1735\n",
      "Epoch 75 took 0.01 seconds\n",
      "Epoch [76/100] | Train Loss: 3.1175 | Train Acc: 0.1944\n",
      "Test Loss: 3.1552 | Test Acc: 0.1740\n",
      "Epoch 76 took 0.01 seconds\n",
      "Epoch [77/100] | Train Loss: 3.1090 | Train Acc: 0.1949\n",
      "Test Loss: 3.1542 | Test Acc: 0.1751\n",
      "Epoch 77 took 0.01 seconds\n",
      "Epoch [78/100] | Train Loss: 3.1109 | Train Acc: 0.1970\n",
      "Test Loss: 3.1577 | Test Acc: 0.1762\n",
      "Epoch 78 took 0.01 seconds\n",
      "Epoch [79/100] | Train Loss: 3.1073 | Train Acc: 0.1976\n",
      "Test Loss: 3.1541 | Test Acc: 0.1772\n",
      "Epoch 79 took 0.01 seconds\n",
      "Epoch [80/100] | Train Loss: 3.1006 | Train Acc: 0.1991\n",
      "Test Loss: 3.1489 | Test Acc: 0.1778\n",
      "Epoch 80 took 0.01 seconds\n",
      "Epoch [81/100] | Train Loss: 3.0973 | Train Acc: 0.2023\n",
      "Test Loss: 3.1482 | Test Acc: 0.1783\n",
      "Epoch 81 took 0.01 seconds\n",
      "Epoch [82/100] | Train Loss: 3.1016 | Train Acc: 0.2023\n",
      "Test Loss: 3.1472 | Test Acc: 0.1788\n",
      "Epoch 82 took 0.01 seconds\n",
      "Epoch [83/100] | Train Loss: 3.0903 | Train Acc: 0.2034\n",
      "Test Loss: 3.1428 | Test Acc: 0.1794\n",
      "Epoch 83 took 0.01 seconds\n",
      "Epoch [84/100] | Train Loss: 3.0978 | Train Acc: 0.2061\n",
      "Test Loss: 3.1372 | Test Acc: 0.1815\n",
      "Epoch 84 took 0.02 seconds\n",
      "Epoch [85/100] | Train Loss: 3.0908 | Train Acc: 0.2055\n",
      "Test Loss: 3.1377 | Test Acc: 0.1820\n",
      "Epoch 85 took 0.02 seconds\n",
      "Epoch [86/100] | Train Loss: 3.0882 | Train Acc: 0.2071\n",
      "Test Loss: 3.1394 | Test Acc: 0.1841\n",
      "Epoch 86 took 0.02 seconds\n",
      "Epoch [87/100] | Train Loss: 3.0893 | Train Acc: 0.2077\n",
      "Test Loss: 3.1358 | Test Acc: 0.1847\n",
      "Epoch 87 took 0.01 seconds\n",
      "Epoch [88/100] | Train Loss: 3.0869 | Train Acc: 0.2098\n",
      "Test Loss: 3.1315 | Test Acc: 0.1847\n",
      "Epoch 88 took 0.01 seconds\n",
      "Epoch [89/100] | Train Loss: 3.0817 | Train Acc: 0.2119\n",
      "Test Loss: 3.1322 | Test Acc: 0.1852\n",
      "Epoch 89 took 0.01 seconds\n",
      "Epoch [90/100] | Train Loss: 3.0782 | Train Acc: 0.2135\n",
      "Test Loss: 3.1285 | Test Acc: 0.1868\n",
      "Epoch 90 took 0.01 seconds\n",
      "Epoch [91/100] | Train Loss: 3.0834 | Train Acc: 0.2135\n",
      "Test Loss: 3.1260 | Test Acc: 0.1895\n",
      "Epoch 91 took 0.01 seconds\n",
      "Epoch [92/100] | Train Loss: 3.0805 | Train Acc: 0.2151\n",
      "Test Loss: 3.1307 | Test Acc: 0.1895\n",
      "Epoch 92 took 0.01 seconds\n",
      "Epoch [93/100] | Train Loss: 3.0730 | Train Acc: 0.2157\n",
      "Test Loss: 3.1259 | Test Acc: 0.1911\n",
      "Epoch 93 took 0.01 seconds\n",
      "Epoch [94/100] | Train Loss: 3.0720 | Train Acc: 0.2162\n",
      "Test Loss: 3.1255 | Test Acc: 0.1916\n",
      "Epoch 94 took 0.01 seconds\n",
      "Epoch [95/100] | Train Loss: 3.0758 | Train Acc: 0.2162\n",
      "Test Loss: 3.1138 | Test Acc: 0.1921\n",
      "Epoch 95 took 0.01 seconds\n",
      "Epoch [96/100] | Train Loss: 3.0696 | Train Acc: 0.2173\n",
      "Test Loss: 3.1249 | Test Acc: 0.1932\n",
      "Epoch 96 took 0.01 seconds\n",
      "Epoch [97/100] | Train Loss: 3.0709 | Train Acc: 0.2183\n",
      "Test Loss: 3.1244 | Test Acc: 0.1948\n",
      "Epoch 97 took 0.01 seconds\n",
      "Epoch [98/100] | Train Loss: 3.0662 | Train Acc: 0.2188\n",
      "Test Loss: 3.1180 | Test Acc: 0.1958\n",
      "Epoch 98 took 0.01 seconds\n",
      "Epoch [99/100] | Train Loss: 3.0615 | Train Acc: 0.2194\n",
      "Test Loss: 3.1141 | Test Acc: 0.1964\n",
      "Epoch 99 took 0.01 seconds\n",
      "Epoch [100/100] | Train Loss: 3.0604 | Train Acc: 0.2183\n",
      "Test Loss: 3.1151 | Test Acc: 0.1974\n",
      "Epoch 100 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:12:08,464 INFO     Train accuracy 0.21938232161874335, Train Loss 3.0644866228103638\n",
      "2025-11-28 11:12:08,464 INFO     Train accuracy 0.21938232161874335, Train Loss 3.0644866228103638\n",
      "2025-11-28 11:12:08,465 INFO     Test accuracy 0.1974454497072911, Test Loss 3.117405354976654\n",
      "2025-11-28 11:12:08,465 INFO     Test accuracy 0.1974454497072911, Test Loss 3.117405354976654\n",
      "2025-11-28 11:12:08,466 INFO     Training model 2 took 58.232645988464355 seconds\n",
      "2025-11-28 11:12:08,466 INFO     Training model 2 took 58.232645988464355 seconds\n",
      "2025-11-28 11:12:08,473 INFO     --------------------------------------------------\n",
      "2025-11-28 11:12:08,473 INFO     --------------------------------------------------\n",
      "2025-11-28 11:12:08,474 INFO     Training model 3: Train size 1879, Test size 1878\n",
      "2025-11-28 11:12:08,474 INFO     Training model 3: Train size 1879, Test size 1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimizer: SGD | Learning Rate: 0.1 | Weight Decay: 0\n",
      "Epoch [1/100] | Train Loss: 3.4575 | Train Acc: 0.0351\n",
      "Test Loss: 3.4486 | Test Acc: 0.0447\n",
      "Epoch 1 took 24.22 seconds\n",
      "Epoch [2/100] | Train Loss: 3.4509 | Train Acc: 0.0383\n",
      "Test Loss: 3.4448 | Test Acc: 0.0506\n",
      "Epoch 2 took 0.02 seconds\n",
      "Epoch [3/100] | Train Loss: 3.4448 | Train Acc: 0.0431\n",
      "Test Loss: 3.4358 | Test Acc: 0.0538\n",
      "Epoch 3 took 0.01 seconds\n",
      "Epoch [4/100] | Train Loss: 3.4365 | Train Acc: 0.0442\n",
      "Test Loss: 3.4300 | Test Acc: 0.0564\n",
      "Epoch 4 took 0.01 seconds\n",
      "Epoch [5/100] | Train Loss: 3.4292 | Train Acc: 0.0463\n",
      "Test Loss: 3.4241 | Test Acc: 0.0591\n",
      "Epoch 5 took 0.01 seconds\n",
      "Epoch [6/100] | Train Loss: 3.4238 | Train Acc: 0.0506\n",
      "Test Loss: 3.4203 | Test Acc: 0.0628\n",
      "Epoch 6 took 0.01 seconds\n",
      "Epoch [7/100] | Train Loss: 3.4166 | Train Acc: 0.0548\n",
      "Test Loss: 3.4140 | Test Acc: 0.0682\n",
      "Epoch 7 took 0.01 seconds\n",
      "Epoch [8/100] | Train Loss: 3.4089 | Train Acc: 0.0601\n",
      "Test Loss: 3.4087 | Test Acc: 0.0724\n",
      "Epoch 8 took 0.01 seconds\n",
      "Epoch [9/100] | Train Loss: 3.4030 | Train Acc: 0.0639\n",
      "Test Loss: 3.4017 | Test Acc: 0.0777\n",
      "Epoch 9 took 0.01 seconds\n",
      "Epoch [10/100] | Train Loss: 3.3962 | Train Acc: 0.0676\n",
      "Test Loss: 3.3965 | Test Acc: 0.0788\n",
      "Epoch 10 took 0.01 seconds\n",
      "Epoch [11/100] | Train Loss: 3.3903 | Train Acc: 0.0772\n",
      "Test Loss: 3.3919 | Test Acc: 0.0841\n",
      "Epoch 11 took 0.01 seconds\n",
      "Epoch [12/100] | Train Loss: 3.3851 | Train Acc: 0.0825\n",
      "Test Loss: 3.3856 | Test Acc: 0.0916\n",
      "Epoch 12 took 0.01 seconds\n",
      "Epoch [13/100] | Train Loss: 3.3788 | Train Acc: 0.0873\n",
      "Test Loss: 3.3829 | Test Acc: 0.1022\n",
      "Epoch 13 took 0.01 seconds\n",
      "Epoch [14/100] | Train Loss: 3.3732 | Train Acc: 0.0958\n",
      "Test Loss: 3.3769 | Test Acc: 0.1102\n",
      "Epoch 14 took 0.01 seconds\n",
      "Epoch [15/100] | Train Loss: 3.3654 | Train Acc: 0.1001\n",
      "Test Loss: 3.3723 | Test Acc: 0.1161\n",
      "Epoch 15 took 0.01 seconds\n",
      "Epoch [16/100] | Train Loss: 3.3601 | Train Acc: 0.1080\n",
      "Test Loss: 3.3675 | Test Acc: 0.1251\n",
      "Epoch 16 took 0.01 seconds\n",
      "Epoch [17/100] | Train Loss: 3.3546 | Train Acc: 0.1139\n",
      "Test Loss: 3.3627 | Test Acc: 0.1289\n",
      "Epoch 17 took 0.01 seconds\n",
      "Epoch [18/100] | Train Loss: 3.3471 | Train Acc: 0.1213\n",
      "Test Loss: 3.3564 | Test Acc: 0.1315\n",
      "Epoch 18 took 0.01 seconds\n",
      "Epoch [19/100] | Train Loss: 3.3434 | Train Acc: 0.1293\n",
      "Test Loss: 3.3531 | Test Acc: 0.1347\n",
      "Epoch 19 took 0.01 seconds\n",
      "Epoch [20/100] | Train Loss: 3.3365 | Train Acc: 0.1357\n",
      "Test Loss: 3.3478 | Test Acc: 0.1353\n",
      "Epoch 20 took 0.01 seconds\n",
      "Epoch [21/100] | Train Loss: 3.3343 | Train Acc: 0.1378\n",
      "Test Loss: 3.3441 | Test Acc: 0.1368\n",
      "Epoch 21 took 0.01 seconds\n",
      "Epoch [22/100] | Train Loss: 3.3286 | Train Acc: 0.1362\n",
      "Test Loss: 3.3412 | Test Acc: 0.1363\n",
      "Epoch 22 took 0.01 seconds\n",
      "Epoch [23/100] | Train Loss: 3.3216 | Train Acc: 0.1320\n",
      "Test Loss: 3.3361 | Test Acc: 0.1368\n",
      "Epoch 23 took 0.01 seconds\n",
      "Epoch [24/100] | Train Loss: 3.3161 | Train Acc: 0.1320\n",
      "Test Loss: 3.3278 | Test Acc: 0.1363\n",
      "Epoch 24 took 0.01 seconds\n",
      "Epoch [25/100] | Train Loss: 3.3084 | Train Acc: 0.1330\n",
      "Test Loss: 3.3239 | Test Acc: 0.1342\n",
      "Epoch 25 took 0.01 seconds\n",
      "Epoch [26/100] | Train Loss: 3.3084 | Train Acc: 0.1384\n",
      "Test Loss: 3.3196 | Test Acc: 0.1315\n",
      "Epoch 26 took 0.01 seconds\n",
      "Epoch [27/100] | Train Loss: 3.3022 | Train Acc: 0.1362\n",
      "Test Loss: 3.3174 | Test Acc: 0.1326\n",
      "Epoch 27 took 0.01 seconds\n",
      "Epoch [28/100] | Train Loss: 3.2953 | Train Acc: 0.1368\n",
      "Test Loss: 3.3132 | Test Acc: 0.1278\n",
      "Epoch 28 took 0.01 seconds\n",
      "Epoch [29/100] | Train Loss: 3.2938 | Train Acc: 0.1378\n",
      "Test Loss: 3.3069 | Test Acc: 0.1278\n",
      "Epoch 29 took 0.01 seconds\n",
      "Epoch [30/100] | Train Loss: 3.2860 | Train Acc: 0.1400\n",
      "Test Loss: 3.3031 | Test Acc: 0.1273\n",
      "Epoch 30 took 0.01 seconds\n",
      "Epoch [31/100] | Train Loss: 3.2811 | Train Acc: 0.1400\n",
      "Test Loss: 3.3001 | Test Acc: 0.1267\n",
      "Epoch 31 took 0.01 seconds\n",
      "Epoch [32/100] | Train Loss: 3.2755 | Train Acc: 0.1400\n",
      "Test Loss: 3.2967 | Test Acc: 0.1246\n",
      "Epoch 32 took 0.01 seconds\n",
      "Epoch [33/100] | Train Loss: 3.2720 | Train Acc: 0.1384\n",
      "Test Loss: 3.2943 | Test Acc: 0.1257\n",
      "Epoch 33 took 0.01 seconds\n",
      "Epoch [34/100] | Train Loss: 3.2704 | Train Acc: 0.1378\n",
      "Test Loss: 3.2880 | Test Acc: 0.1278\n",
      "Epoch 34 took 0.01 seconds\n",
      "Epoch [35/100] | Train Loss: 3.2613 | Train Acc: 0.1368\n",
      "Test Loss: 3.2858 | Test Acc: 0.1257\n",
      "Epoch 35 took 0.01 seconds\n",
      "Epoch [36/100] | Train Loss: 3.2597 | Train Acc: 0.1368\n",
      "Test Loss: 3.2786 | Test Acc: 0.1257\n",
      "Epoch 36 took 0.01 seconds\n",
      "Epoch [37/100] | Train Loss: 3.2545 | Train Acc: 0.1373\n",
      "Test Loss: 3.2732 | Test Acc: 0.1257\n",
      "Epoch 37 took 0.01 seconds\n",
      "Epoch [38/100] | Train Loss: 3.2515 | Train Acc: 0.1384\n",
      "Test Loss: 3.2727 | Test Acc: 0.1257\n",
      "Epoch 38 took 0.01 seconds\n",
      "Epoch [39/100] | Train Loss: 3.2434 | Train Acc: 0.1400\n",
      "Test Loss: 3.2680 | Test Acc: 0.1246\n",
      "Epoch 39 took 0.01 seconds\n",
      "Epoch [40/100] | Train Loss: 3.2405 | Train Acc: 0.1400\n",
      "Test Loss: 3.2661 | Test Acc: 0.1251\n",
      "Epoch 40 took 0.01 seconds\n",
      "Epoch [41/100] | Train Loss: 3.2337 | Train Acc: 0.1378\n",
      "Test Loss: 3.2624 | Test Acc: 0.1257\n",
      "Epoch 41 took 0.01 seconds\n",
      "Epoch [42/100] | Train Loss: 3.2323 | Train Acc: 0.1394\n",
      "Test Loss: 3.2575 | Test Acc: 0.1262\n",
      "Epoch 42 took 0.01 seconds\n",
      "Epoch [43/100] | Train Loss: 3.2290 | Train Acc: 0.1389\n",
      "Test Loss: 3.2555 | Test Acc: 0.1257\n",
      "Epoch 43 took 0.01 seconds\n",
      "Epoch [44/100] | Train Loss: 3.2211 | Train Acc: 0.1410\n",
      "Test Loss: 3.2514 | Test Acc: 0.1278\n",
      "Epoch 44 took 0.01 seconds\n",
      "Epoch [45/100] | Train Loss: 3.2184 | Train Acc: 0.1416\n",
      "Test Loss: 3.2459 | Test Acc: 0.1273\n",
      "Epoch 45 took 0.01 seconds\n",
      "Epoch [46/100] | Train Loss: 3.2167 | Train Acc: 0.1405\n",
      "Test Loss: 3.2436 | Test Acc: 0.1289\n",
      "Epoch 46 took 0.01 seconds\n",
      "Epoch [47/100] | Train Loss: 3.2078 | Train Acc: 0.1416\n",
      "Test Loss: 3.2356 | Test Acc: 0.1283\n",
      "Epoch 47 took 0.01 seconds\n",
      "Epoch [48/100] | Train Loss: 3.2051 | Train Acc: 0.1416\n",
      "Test Loss: 3.2331 | Test Acc: 0.1289\n",
      "Epoch 48 took 0.01 seconds\n",
      "Epoch [49/100] | Train Loss: 3.2039 | Train Acc: 0.1416\n",
      "Test Loss: 3.2325 | Test Acc: 0.1294\n",
      "Epoch 49 took 0.01 seconds\n",
      "Epoch [50/100] | Train Loss: 3.1942 | Train Acc: 0.1426\n",
      "Test Loss: 3.2278 | Test Acc: 0.1294\n",
      "Epoch 50 took 0.01 seconds\n",
      "Epoch [51/100] | Train Loss: 3.1963 | Train Acc: 0.1426\n",
      "Test Loss: 3.2225 | Test Acc: 0.1310\n",
      "Epoch 51 took 0.01 seconds\n",
      "Epoch [52/100] | Train Loss: 3.1839 | Train Acc: 0.1464\n",
      "Test Loss: 3.2208 | Test Acc: 0.1315\n",
      "Epoch 52 took 0.01 seconds\n",
      "Epoch [53/100] | Train Loss: 3.1877 | Train Acc: 0.1490\n",
      "Test Loss: 3.2212 | Test Acc: 0.1326\n",
      "Epoch 53 took 0.02 seconds\n",
      "Epoch [54/100] | Train Loss: 3.1810 | Train Acc: 0.1495\n",
      "Test Loss: 3.2128 | Test Acc: 0.1342\n",
      "Epoch 54 took 0.01 seconds\n",
      "Epoch [55/100] | Train Loss: 3.1762 | Train Acc: 0.1511\n",
      "Test Loss: 3.2138 | Test Acc: 0.1358\n",
      "Epoch 55 took 0.01 seconds\n",
      "Epoch [56/100] | Train Loss: 3.1781 | Train Acc: 0.1506\n",
      "Test Loss: 3.2044 | Test Acc: 0.1384\n",
      "Epoch 56 took 0.01 seconds\n",
      "Epoch [57/100] | Train Loss: 3.1716 | Train Acc: 0.1517\n",
      "Test Loss: 3.2004 | Test Acc: 0.1395\n",
      "Epoch 57 took 0.01 seconds\n",
      "Epoch [58/100] | Train Loss: 3.1673 | Train Acc: 0.1533\n",
      "Test Loss: 3.2060 | Test Acc: 0.1427\n",
      "Epoch 58 took 0.01 seconds\n",
      "Epoch [59/100] | Train Loss: 3.1630 | Train Acc: 0.1549\n",
      "Test Loss: 3.1946 | Test Acc: 0.1443\n",
      "Epoch 59 took 0.18 seconds\n",
      "Epoch [60/100] | Train Loss: 3.1565 | Train Acc: 0.1559\n",
      "Test Loss: 3.1986 | Test Acc: 0.1454\n",
      "Epoch 60 took 0.01 seconds\n",
      "Epoch [61/100] | Train Loss: 3.1563 | Train Acc: 0.1559\n",
      "Test Loss: 3.1935 | Test Acc: 0.1475\n",
      "Epoch 61 took 0.01 seconds\n",
      "Epoch [62/100] | Train Loss: 3.1509 | Train Acc: 0.1581\n",
      "Test Loss: 3.1870 | Test Acc: 0.1491\n",
      "Epoch 62 took 0.01 seconds\n",
      "Epoch [63/100] | Train Loss: 3.1520 | Train Acc: 0.1613\n",
      "Test Loss: 3.1879 | Test Acc: 0.1512\n",
      "Epoch 63 took 0.01 seconds\n",
      "Epoch [64/100] | Train Loss: 3.1472 | Train Acc: 0.1634\n",
      "Test Loss: 3.1828 | Test Acc: 0.1523\n",
      "Epoch 64 took 0.01 seconds\n",
      "Epoch [65/100] | Train Loss: 3.1429 | Train Acc: 0.1660\n",
      "Test Loss: 3.1839 | Test Acc: 0.1528\n",
      "Epoch 65 took 0.01 seconds\n",
      "Epoch [66/100] | Train Loss: 3.1419 | Train Acc: 0.1687\n",
      "Test Loss: 3.1727 | Test Acc: 0.1544\n",
      "Epoch 66 took 0.01 seconds\n",
      "Epoch [67/100] | Train Loss: 3.1353 | Train Acc: 0.1698\n",
      "Test Loss: 3.1743 | Test Acc: 0.1560\n",
      "Epoch 67 took 0.01 seconds\n",
      "Epoch [68/100] | Train Loss: 3.1307 | Train Acc: 0.1730\n",
      "Test Loss: 3.1678 | Test Acc: 0.1581\n",
      "Epoch 68 took 0.01 seconds\n",
      "Epoch [69/100] | Train Loss: 3.1330 | Train Acc: 0.1751\n",
      "Test Loss: 3.1641 | Test Acc: 0.1592\n",
      "Epoch 69 took 0.01 seconds\n",
      "Epoch [70/100] | Train Loss: 3.1194 | Train Acc: 0.1772\n",
      "Test Loss: 3.1677 | Test Acc: 0.1597\n",
      "Epoch 70 took 0.01 seconds\n",
      "Epoch [71/100] | Train Loss: 3.1248 | Train Acc: 0.1778\n",
      "Test Loss: 3.1620 | Test Acc: 0.1613\n",
      "Epoch 71 took 0.01 seconds\n",
      "Epoch [72/100] | Train Loss: 3.1181 | Train Acc: 0.1794\n",
      "Test Loss: 3.1634 | Test Acc: 0.1624\n",
      "Epoch 72 took 0.01 seconds\n",
      "Epoch [73/100] | Train Loss: 3.1155 | Train Acc: 0.1809\n",
      "Test Loss: 3.1608 | Test Acc: 0.1640\n",
      "Epoch 73 took 0.01 seconds\n",
      "Epoch [74/100] | Train Loss: 3.1153 | Train Acc: 0.1815\n",
      "Test Loss: 3.1615 | Test Acc: 0.1656\n",
      "Epoch 74 took 0.01 seconds\n",
      "Epoch [75/100] | Train Loss: 3.1087 | Train Acc: 0.1836\n",
      "Test Loss: 3.1556 | Test Acc: 0.1661\n",
      "Epoch 75 took 0.01 seconds\n",
      "Epoch [76/100] | Train Loss: 3.1158 | Train Acc: 0.1857\n",
      "Test Loss: 3.1561 | Test Acc: 0.1672\n",
      "Epoch 76 took 0.01 seconds\n",
      "Epoch [77/100] | Train Loss: 3.1078 | Train Acc: 0.1879\n",
      "Test Loss: 3.1515 | Test Acc: 0.1683\n",
      "Epoch 77 took 0.01 seconds\n",
      "Epoch [78/100] | Train Loss: 3.1001 | Train Acc: 0.1900\n",
      "Test Loss: 3.1462 | Test Acc: 0.1704\n",
      "Epoch 78 took 0.01 seconds\n",
      "Epoch [79/100] | Train Loss: 3.1013 | Train Acc: 0.1932\n",
      "Test Loss: 3.1411 | Test Acc: 0.1709\n",
      "Epoch 79 took 0.01 seconds\n",
      "Epoch [80/100] | Train Loss: 3.1014 | Train Acc: 0.1937\n",
      "Test Loss: 3.1462 | Test Acc: 0.1736\n",
      "Epoch 80 took 0.01 seconds\n",
      "Epoch [81/100] | Train Loss: 3.0931 | Train Acc: 0.1953\n",
      "Test Loss: 3.1426 | Test Acc: 0.1736\n",
      "Epoch 81 took 0.01 seconds\n",
      "Epoch [82/100] | Train Loss: 3.0867 | Train Acc: 0.1980\n",
      "Test Loss: 3.1343 | Test Acc: 0.1741\n",
      "Epoch 82 took 0.01 seconds\n",
      "Epoch [83/100] | Train Loss: 3.0914 | Train Acc: 0.1985\n",
      "Test Loss: 3.1365 | Test Acc: 0.1747\n",
      "Epoch 83 took 0.01 seconds\n",
      "Epoch [84/100] | Train Loss: 3.0869 | Train Acc: 0.2006\n",
      "Test Loss: 3.1297 | Test Acc: 0.1757\n",
      "Epoch 84 took 0.01 seconds\n",
      "Epoch [85/100] | Train Loss: 3.0807 | Train Acc: 0.2006\n",
      "Test Loss: 3.1289 | Test Acc: 0.1773\n",
      "Epoch 85 took 0.01 seconds\n",
      "Epoch [86/100] | Train Loss: 3.0852 | Train Acc: 0.2017\n",
      "Test Loss: 3.1295 | Test Acc: 0.1794\n",
      "Epoch 86 took 0.01 seconds\n",
      "Epoch [87/100] | Train Loss: 3.0807 | Train Acc: 0.2049\n",
      "Test Loss: 3.1279 | Test Acc: 0.1805\n",
      "Epoch 87 took 0.01 seconds\n",
      "Epoch [88/100] | Train Loss: 3.0785 | Train Acc: 0.2054\n",
      "Test Loss: 3.1257 | Test Acc: 0.1805\n",
      "Epoch 88 took 0.01 seconds\n",
      "Epoch [89/100] | Train Loss: 3.0754 | Train Acc: 0.2070\n",
      "Test Loss: 3.1266 | Test Acc: 0.1810\n",
      "Epoch 89 took 0.01 seconds\n",
      "Epoch [90/100] | Train Loss: 3.0758 | Train Acc: 0.2081\n",
      "Test Loss: 3.1247 | Test Acc: 0.1826\n",
      "Epoch 90 took 0.01 seconds\n",
      "Epoch [91/100] | Train Loss: 3.0741 | Train Acc: 0.2092\n",
      "Test Loss: 3.1179 | Test Acc: 0.1826\n",
      "Epoch 91 took 0.01 seconds\n",
      "Epoch [92/100] | Train Loss: 3.0704 | Train Acc: 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:13:14,126 INFO     Train accuracy 0.2192655667908462, Train Loss 3.063373327255249\n",
      "2025-11-28 11:13:14,126 INFO     Train accuracy 0.2192655667908462, Train Loss 3.063373327255249\n",
      "2025-11-28 11:13:14,128 INFO     Test accuracy 0.1900958466453674, Test Loss 3.109704554080963\n",
      "2025-11-28 11:13:14,128 INFO     Test accuracy 0.1900958466453674, Test Loss 3.109704554080963\n",
      "2025-11-28 11:13:14,130 INFO     Training model 3 took 65.65716886520386 seconds\n",
      "2025-11-28 11:13:14,130 INFO     Training model 3 took 65.65716886520386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.1233 | Test Acc: 0.1842\n",
      "Epoch 92 took 0.01 seconds\n",
      "Epoch [93/100] | Train Loss: 3.0714 | Train Acc: 0.2118\n",
      "Test Loss: 3.1214 | Test Acc: 0.1848\n",
      "Epoch 93 took 0.01 seconds\n",
      "Epoch [94/100] | Train Loss: 3.0732 | Train Acc: 0.2123\n",
      "Test Loss: 3.1119 | Test Acc: 0.1858\n",
      "Epoch 94 took 0.02 seconds\n",
      "Epoch [95/100] | Train Loss: 3.0656 | Train Acc: 0.2150\n",
      "Test Loss: 3.1135 | Test Acc: 0.1864\n",
      "Epoch 95 took 0.02 seconds\n",
      "Epoch [96/100] | Train Loss: 3.0605 | Train Acc: 0.2161\n",
      "Test Loss: 3.1160 | Test Acc: 0.1869\n",
      "Epoch 96 took 0.02 seconds\n",
      "Epoch [97/100] | Train Loss: 3.0667 | Train Acc: 0.2171\n",
      "Test Loss: 3.1080 | Test Acc: 0.1874\n",
      "Epoch 97 took 0.02 seconds\n",
      "Epoch [98/100] | Train Loss: 3.0622 | Train Acc: 0.2193\n",
      "Test Loss: 3.1128 | Test Acc: 0.1880\n",
      "Epoch 98 took 0.01 seconds\n",
      "Epoch [99/100] | Train Loss: 3.0529 | Train Acc: 0.2193\n",
      "Test Loss: 3.1121 | Test Acc: 0.1885\n",
      "Epoch 99 took 0.01 seconds\n",
      "Epoch [100/100] | Train Loss: 3.0553 | Train Acc: 0.2193\n",
      "Test Loss: 3.1086 | Test Acc: 0.1901\n",
      "Epoch 100 took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:13:54,161 INFO     Model loading/training took 240.5 seconds\n",
      "2025-11-28 11:13:54,161 INFO     Model loading/training took 240.5 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define experiment parameters\n",
    "num_experiments = configs[\"run\"][\"num_experiments\"]\n",
    "num_reference_models = configs[\"audit\"][\"num_ref_models\"]\n",
    "num_model_pairs = max(math.ceil(num_experiments / 2.0), num_reference_models + 1) # 2 model pairs = 4 models\n",
    "\n",
    "# train models\n",
    "baseline_time = time.time()\n",
    "\n",
    "# Split dataset for training two models per pair\n",
    "data_splits, memberships = split_dataset_for_training(\n",
    "    len(dataset), num_model_pairs\n",
    ")\n",
    "models_list = train_models(\n",
    "    log_dir, dataset, data_splits, memberships, configs, logger\n",
    ")\n",
    "logger.info(\n",
    "    \"Model loading/training took %0.1f seconds\", time.time() - baseline_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3853460",
   "metadata": {},
   "source": [
    "### Auditing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e7f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "auditing_dataset, auditing_membership = sample_auditing_dataset(\n",
    "        configs, dataset, logger, memberships\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69795c58",
   "metadata": {},
   "source": [
    "### Compute signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88aca9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:22:00,379 INFO     Signals loaded from disk successfully.\n",
      "2025-11-28 11:22:00,379 INFO     Signals loaded from disk successfully.\n",
      "2025-11-28 11:22:00,385 INFO     Signals loaded from disk successfully.\n",
      "2025-11-28 11:22:00,385 INFO     Signals loaded from disk successfully.\n",
      "2025-11-28 11:22:00,386 INFO     Preparing signals took 0.01481 seconds\n",
      "2025-11-28 11:22:00,386 INFO     Preparing signals took 0.01481 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_time = time.time()\n",
    "signals = get_model_signals(models_list, auditing_dataset, configs, logger)\n",
    "population_signals = get_model_signals(\n",
    "        models_list, population, configs, logger, is_population=True\n",
    "    )\n",
    "logger.info(\"Preparing signals took %0.5f seconds\", time.time() - baseline_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5494b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 11:22:07,522 INFO     Fine-tuning offline_a using paired model 1\n",
      "2025-11-28 11:22:07,522 INFO     Fine-tuning offline_a using paired model 1\n",
      "2025-11-28 11:22:07,535 INFO     offline_a=0.00: AUC 0.5654\n",
      "2025-11-28 11:22:07,535 INFO     offline_a=0.00: AUC 0.5654\n",
      "2025-11-28 11:22:07,545 INFO     offline_a=0.10: AUC 0.5657\n",
      "2025-11-28 11:22:07,545 INFO     offline_a=0.10: AUC 0.5657\n",
      "2025-11-28 11:22:07,552 INFO     offline_a=0.20: AUC 0.5662\n",
      "2025-11-28 11:22:07,552 INFO     offline_a=0.20: AUC 0.5662\n",
      "2025-11-28 11:22:07,560 INFO     offline_a=0.30: AUC 0.5666\n",
      "2025-11-28 11:22:07,560 INFO     offline_a=0.30: AUC 0.5666\n",
      "2025-11-28 11:22:07,566 INFO     offline_a=0.40: AUC 0.5673\n",
      "2025-11-28 11:22:07,566 INFO     offline_a=0.40: AUC 0.5673\n",
      "2025-11-28 11:22:07,572 INFO     offline_a=0.50: AUC 0.5681\n",
      "2025-11-28 11:22:07,572 INFO     offline_a=0.50: AUC 0.5681\n",
      "2025-11-28 11:22:07,579 INFO     offline_a=0.60: AUC 0.5694\n",
      "2025-11-28 11:22:07,579 INFO     offline_a=0.60: AUC 0.5694\n",
      "2025-11-28 11:22:07,584 INFO     offline_a=0.70: AUC 0.5714\n",
      "2025-11-28 11:22:07,584 INFO     offline_a=0.70: AUC 0.5714\n",
      "2025-11-28 11:22:07,591 INFO     offline_a=0.80: AUC 0.5748\n",
      "2025-11-28 11:22:07,591 INFO     offline_a=0.80: AUC 0.5748\n",
      "2025-11-28 11:22:07,596 INFO     offline_a=0.90: AUC 0.5825\n",
      "2025-11-28 11:22:07,596 INFO     offline_a=0.90: AUC 0.5825\n",
      "2025-11-28 11:22:07,601 INFO     offline_a=1.00: AUC 0.5930\n",
      "2025-11-28 11:22:07,601 INFO     offline_a=1.00: AUC 0.5930\n",
      "2025-11-28 11:22:07,602 INFO     The best offline_a is 1.0\n",
      "2025-11-28 11:22:07,602 INFO     The best offline_a is 1.0\n",
      "2025-11-28 11:22:07,609 INFO     Target Model 0: AUC 0.5783, TPR@0.1%FPR of 0.0000, TPR@0.0%FPR of 0.0000\n",
      "2025-11-28 11:22:07,609 INFO     Target Model 0: AUC 0.5783, TPR@0.1%FPR of 0.0000, TPR@0.0%FPR of 0.0000\n",
      "2025-11-28 11:22:10,806 INFO     Auditing the privacy risks of target model 0 costs 3.3 seconds\n",
      "2025-11-28 11:22:10,806 INFO     Auditing the privacy risks of target model 0 costs 3.3 seconds\n",
      "2025-11-28 11:22:10,807 INFO     Total runtime: 786.74462 seconds\n",
      "2025-11-28 11:22:10,807 INFO     Total runtime: 786.74462 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform the privacy audit\n",
    "baseline_time = time.time()\n",
    "target_model_indices = list(range(num_experiments))\n",
    "mia_score_list, membership_list = audit_models(\n",
    "        f\"{directories['report_dir']}/exp\",\n",
    "        target_model_indices,\n",
    "        signals,\n",
    "        population_signals,\n",
    "        auditing_membership,\n",
    "        num_reference_models,\n",
    "        logger,\n",
    "        configs,\n",
    "    )\n",
    "\n",
    "if len(target_model_indices) > 1:\n",
    "    logger.info(\n",
    "        \"Auditing privacy risk took %0.1f seconds\", time.time() - baseline_time\n",
    "    )\n",
    "\n",
    "# Get average audit results across all experiments\n",
    "if len(target_model_indices) > 1:\n",
    "    get_average_audit_results(\n",
    "        directories[\"report_dir\"], mia_score_list, membership_list, logger\n",
    "    )\n",
    "\n",
    "logger.info(\"Total runtime: %0.5f seconds\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae01024",
   "metadata": {},
   "source": [
    "Find the image in ml_privacy_meter/demo_locations/report/exp/ROC_0.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb961b",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae03a1",
   "metadata": {},
   "source": [
    "### 1. Use a different machine learning model (e.g. mlp)\n",
    "Interpret the new results. Diagnose why the model leaks private information.\n",
    "Does the model overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789509cb",
   "metadata": {},
   "source": [
    "### 2. Implement and evaluate defenses. \n",
    "Apply a defense strategy (e.g. dropout) to the target model, retrain it and compute the signals again. Analyze the impact of such strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d25de8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISec-class-DqnUEjF1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
